---
title: "ABG-VBG Analysis"
author: "Brian Locke, Anila Mehta"
format: html
editor: visual
---

This is a Quarto notebook - which is helpful for 'literate programming' - see here (basically, showing your work with statistical programming)

Here's some tips/tricks for quarto - <https://www.productive-r-workflow.com/quarto-tricks>

## Data Pre-processing

This code pulls in the master database (a STATA file) and does some initial cleaning - this will only need to be run once, and then the data can be accessed in the usual way.

```{r}
# Install necessary packages (if not already installed)
if (!requireNamespace("haven", quietly = TRUE)) install.packages("haven")
if (!requireNamespace("labelled", quietly = TRUE)) install.packages("labelled")
if (!requireNamespace("codebookr", quietly = TRUE)) install.packages("codebookr")

# Load libraries
library(haven)
library(labelled)
library(codebookr)
```

This code converts the data from a STATA format to rdata if the rdata file does not exist. If it does already exist, it just loads that.

```{r}
# Define file paths
data_dir_name <- "data"
rdata_file <- file.path(data_dir_name, "full_trinetx.rdata")
stata_file <- file.path(data_dir_name, "full_db.dta")

# Ensure the directory exists
if (!dir.exists(data_dir_name)) {
  dir.create(data_dir_name)
  message("Directory 'data' created.")
} else {
  message("Directory 'data' already exists.")
}

# Check if the RData file exists
if (file.exists(rdata_file)) {
  # Load the existing RData file
  load(rdata_file)
  message("Loaded existing dataset from 'full_trinetx.rdata'.")
} else {
  # Read Stata dataset
  message("RData file not found. Reading Stata dataset...")
  stata_data <- read_dta(stata_file)
  
  # Check variable labels
  message("Extracting variable labels...")
  var_label(stata_data)

  # Check value labels
  message("Extracting value labels...")
  sapply(stata_data, function(x) if (is.labelled(x)) val_labels(x))

  # Save the dataset in RData format
  save(stata_data, file = rdata_file)
  message("Dataset saved as 'full_trinetx.rdata'.")

  # Load the newly created RData file
  load(rdata_file)
  message("Loaded newly saved dataset from 'full_trinetx.rdata'.")
}

```

```{r}
#Creating subset_data
# Set a seed for reproducibility
set.seed(123)

# Calculate the number of rows to keep (5% of the total)
rows_to_keep <- round(nrow(stata_data) * 0.05)

# Randomly sample the rows to keep
subset_data <- stata_data[sample(nrow(stata_data), rows_to_keep), ]

# Check the dimensions of the new dataset
dim(subset_data)

```

```{r}
# Generate the codebook for the dataset
message("Generating codebook for the dataset...")
study_codebook <- codebookr::codebook(
  stata_data,
  title = "Full TrinetX",
  subtitle = "Dataset Documentation",
  description = "This dataset contains patient-level records from the TrinetX database. 
                 It has been processed and converted from the original Stata file."
)

# Save the codebook as a Word document
codebook_file <- file.path(data_dir_name, "codebookr.docx")
print(study_codebook, codebook_file)
message("Codebook saved as 'codebookr.docx' in the data directory.")

```

Here are a few references that might be helpful for learning R:

University of Utah Resource <https://uofudelphi-r-23-08-21.netlify.app/>

More in depth resource/book <https://r4ds.hadley.nz/>

and slightly more advanced: <https://rap4mads.eu/03-functional-programming.html>

style guide for how to name things <https://style.tidyverse.org/syntax.html>

**Some example data visualizations**

Summary Statistics:

```{r}
# Use base R's summary() function
summary(subset_data)
```

Raw Data

```{r}
# Install necessary package if not already installed
if (!requireNamespace("dplyr", quietly = TRUE)) install.packages("dplyr")

# Load the dplyr package
library(dplyr)

# Analyze the dataset structure using glimpse()
glimpse(subset_data)

```

More detailed - separated by character, date, and numeric datatypes

```{r}
# Install necessary package if not already installed
if (!requireNamespace("skimr", quietly = TRUE)) install.packages("skimr")

# Load the skimr package
library(skimr)

# Generate a detailed summary using skim()
skim(subset_data)
```

More in depth - interactive HTML

```{r}
# Install necessary package if not already installed
if (!requireNamespace("summarytools", quietly = TRUE)) install.packages("summarytools")

# Load the summarytools package
library(summarytools)

# Generate a data frame summary report
dfSummary(subset_data)
```

Some regression stuff:

```{r}
# Install necessary packages if not installed
if (!requireNamespace("tidyverse", quietly = TRUE)) install.packages("tidyverse")
if (!requireNamespace("performance", quietly = TRUE)) install.packages("performance")
if (!requireNamespace("ggeffects", quietly = TRUE)) install.packages("ggeffects")
if (!requireNamespace("sjPlot", quietly = TRUE)) install.packages("sjPlot")
if (!requireNamespace("gtsummary", quietly = TRUE)) install.packages("gtsummary")
if (!requireNamespace("vip", quietly = TRUE)) install.packages("vip")

#Missing package1
install.packages("gridExtra")
library(gridExtra)

# Load required libraries
library(tidyverse)      # Data manipulation & visualization
library(performance)    # Model assumption checks
library(ggeffects)      # Effect visualization
library(sjPlot)         # Grid plotting for ggplots
library(gtsummary)      # Regression table
library(vip)            # Variable importance

# Set theme for plots
theme_set(theme_bw())

# Get & Prepare Data 
# Assuming `stata_data_df` is the cleaned dataset
bmi_data <- subset_data |> 
  filter(!is.na(bmi), !is.na(age_at_encounter), !is.na(sex)) |>  # Remove missing values
  mutate(
    sex = as.factor(sex),                 # Convert sex to categorical
    age_at_encounter = as.numeric(age_at_encounter), 
    bmi = as.numeric(bmi)                 # Ensure BMI is numeric
  )

# Build the Model
bmi_model <- lm(bmi ~ sex + age_at_encounter, data = bmi_data)

# Check all model assumptions visually
bmi_model |> performance::check_model()

# Visualize predictions
bmi_model |> 
  ggeffects::ggpredict() |> 
  plot() |> 
  sjPlot::plot_grid()

# Get regression table with p-values
bmi_model |> 
  gtsummary::tbl_regression(exponentiate = FALSE, add_pairwise_contrasts = TRUE)

# Get variable importance
bmi_model |> vip::vip()

# Check model quality
bmi_model |> performance::performance()
```

BL 4/26/25 - these factor conversions seem to be working now (a few were labeld as "subset_data_df" that I changed to 'subset_data' only.

```{r}
# Install necessary packages if not installed
if (!requireNamespace("performance", quietly = TRUE)) install.packages("performance")

# Load required packages
library(performance)

# Assuming `stata_data_df` is your cleaned dataset
# Ensure variables are in the correct format
subset_data$sex <- as.factor(subset_data$sex)  # Convert sex to categorical variable
subset_data$age_at_encounter <- as.numeric(subset_data$age_at_encounter)  # Ensure age is numeric
subset_data$bmi <- as.numeric(subset_data$bmi)  # Ensure BMI is numeric

# Fit the linear regression model
bmi_model <- lm(curr_bmi ~ sex + age_at_encounter, data = subset_data)

# Check model assumptions
check_model(bmi_model)
```

Here are a few references that might be helpful for visualizations:

[https://grantmcdermott.com/tinyplot/](https://grantmcdermott.com/tinyplot/?utm_campaign=Data_Elixir&utm_source=Data_Elixir_522)

```{r}
#Checking the data since getting werid errors
str(subset_data[, c("sex", "race")])
table(subset_data$sex, useNA = "ifany")
table(subset_data$race, useNA = "ifany")
```

```{r}
#Table 1: Variable description for categorical variables 

library(dplyr)
library(tidyr)
library(labelled)  # For to_factor()

# Create the summary table
summary_table <- subset_data %>%
  transmute(
    sex = factor(ifelse(sex == 0, "Female", "Male")),  # Convert 'sex' to factor
    race = to_factor(race),  # Safely convert 'race' to factor using 'to_factor'
    osa = factor(ifelse(osa == 1, "Yes", "No")),
    asthma = factor(ifelse(asthma == 1, "Yes", "No")),
    copd = factor(ifelse(copd == 1, "Yes", "No")),
    chf = factor(ifelse(chf == 1, "Yes", "No"))
  ) %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Category") %>%
  group_by(Variable, Category) %>%
  summarise(Count = n(), .groups = "drop") %>%
  group_by(Variable) %>%
  mutate(Percent = round(Count / sum(Count) * 100, 1)) %>%
  arrange(Variable, desc(Count))

# View the resulting table
print(summary_table)

```

```{r}
# Recode sex as factor with labels
# Convert to numeric if needed
subset_data$sex <- as.numeric(as.character(subset_data$sex))

subset_data$sex_label <- factor(subset_data$sex,
                              levels = c(0, 1),
                              labels = c("Female", "Male"))

# Get counts
sex_counts <- table(subset_data$sex_label)

# Get percentages
sex_percent <- prop.table(sex_counts) * 100

# Combine into a data frame
sex_table <- data.frame(
  Sex = names(sex_counts),
  Count = as.vector(sex_counts),
  Percentage = round(sex_percent, 2)
)

print(sex_table)
```

```{r}
# Recode and calculate for 'sex'
subset_data$sex <- as.numeric(as.character(subset_data$sex))
subset_data$sex_label <- factor(subset_data$sex,
                                levels = c(0, 1),
                                labels = c("Female", "Male"))

sex_counts <- table(subset_data$sex_label)
sex_percent <- prop.table(sex_counts) * 100
sex_table <- data.frame(
  Sex = names(sex_counts),
  Count = as.vector(sex_counts),
  Percentage = round(sex_percent, 2)
)

print(sex_table)

# Repeat for 'race'
subset_data$race <- as.numeric(as.character(subset_data$race))
subset_data$race_label <- factor(subset_data$race,
                                 levels = c(0, 1, 2, 3, 4, 5),
                                 labels = c("White", "Black or African American", "Unknown", "Asian", "American Indian", "Pacific Islander"))

race_counts <- table(subset_data$race_label)
race_percent <- prop.table(race_counts) * 100
race_table <- data.frame(
  Race = names(race_counts),
  Count = as.vector(race_counts),
  Percentage = round(race_percent, 2)
)

print(race_table)

# Repeat for other categorical variables
# 'osa'
subset_data$osa_label <- factor(subset_data$osa, levels = c(0, 1), labels = c("No", "Yes"))
osa_counts <- table(subset_data$osa_label)
osa_percent <- prop.table(osa_counts) * 100
osa_table <- data.frame(
  OSA = names(osa_counts),
  Count = as.vector(osa_counts),
  Percentage = round(osa_percent, 2)
)

print(osa_table)

# 'asthma'
subset_data$asthma_label <- factor(subset_data$asthma, levels = c(0, 1), labels = c("No", "Yes"))
asthma_counts <- table(subset_data$asthma_label)
asthma_percent <- prop.table(asthma_counts) * 100
asthma_table <- data.frame(
  Asthma = names(asthma_counts),
  Count = as.vector(asthma_counts),
  Percentage = round(asthma_percent, 2)
)

print(asthma_table)

# 'copd'
subset_data$copd_label <- factor(subset_data$copd, levels = c(0, 1), labels = c("No", "Yes"))
copd_counts <- table(subset_data$copd_label)
copd_percent <- prop.table(copd_counts) * 100
copd_table <- data.frame(
  COPD = names(copd_counts),
  Count = as.vector(copd_counts),
  Percentage = round(copd_percent, 2)
)

print(copd_table)

# 'chf'
subset_data$chf_label <- factor(subset_data$chf, levels = c(0, 1), labels = c("No", "Yes"))
chf_counts <- table(subset_data$chf_label)
chf_percent <- prop.table(chf_counts) * 100
chf_table <- data.frame(
  CHF = names(chf_counts),
  Count = as.vector(chf_counts),
  Percentage = round(chf_percent, 2)
)

print(chf_table)

```

```{r}
#Continuous variables for Table 1

vars <- c("age_at_encounter", "curr_bmi", "vbg_co2", "paco2")

summary_table <- data.frame(
  Variable = vars,
  Mean = sapply(subset_data[vars], function(x) mean(x, na.rm = TRUE)),
  SD = sapply(subset_data[vars], function(x) sd(x, na.rm = TRUE)),
  Median = sapply(subset_data[vars], function(x) median(x, na.rm = TRUE)),
  Q1 = sapply(subset_data[vars], function(x) quantile(x, 0.25, na.rm = TRUE)),
  Q3 = sapply(subset_data[vars], function(x) quantile(x, 0.75, na.rm = TRUE)),
  Min = sapply(subset_data[vars], function(x) min(x, na.rm = TRUE)),
  Max = sapply(subset_data[vars], function(x) max(x, na.rm = TRUE))
)

print(summary_table)
```

```{r}
#Continuous variables for Table 1

vars <- c("age_at_encounter", "curr_bmi", "vbg_co2", "paco2")

summary_table <- data.frame(
  Variable = vars,
  Mean = sapply(subset_data[vars], function(x) mean(x, na.rm = TRUE)),
  SD = sapply(subset_data[vars], function(x) sd(x, na.rm = TRUE)),
  Median = sapply(subset_data[vars], function(x) median(x, na.rm = TRUE)),
  Q1 = sapply(subset_data[vars], function(x) quantile(x, 0.25, na.rm = TRUE)),
  Q3 = sapply(subset_data[vars], function(x) quantile(x, 0.75, na.rm = TRUE)),
  Min = sapply(subset_data[vars], function(x) min(x, na.rm = TRUE)),
  Max = sapply(subset_data[vars], function(x) max(x, na.rm = TRUE))
)

print(summary_table)

```

\[BL Edit 4/26/2025\] I broke this block up into smaller chunks to troubleshoot individually

```{r}
names(subset_data)
str(subset_data)
```

```{r}
subset_data <- subset_data %>%
  mutate(
    paco2 = as.numeric(paco2),
    hypercapnia = ifelse(paco2 > 45, 1, 0)
  )

with(subset_data, table(hypercapnia, niv_proc))
```

Previously, you did a recoding for the imv_proc, niv_proc, died, and hypercap_resp_failure variables... but they're actually already in 0 and 1 format.

So you can just start doing the regressions

```{r}
library(broom)
logit_intubated <- glm(imv_proc ~ hypercapnia, data = subset_data, family = binomial)
summary(logit_intubated)

tidy(logit_intubated,
     exponentiate = TRUE,   # turns log-odds → OR
     conf.int     = TRUE)   # adds 95 % CI

```

```{r}
logit_niv <- glm(niv_proc ~ hypercapnia, data = subset_data, family = binomial)
summary(logit_niv)

tidy(logit_niv,
     exponentiate = TRUE,   # turns log-odds → OR
     conf.int     = TRUE)   # adds 95 % CI
```

```{r}
logit_death <- glm(died ~ hypercapnia, data = subset_data, family = binomial)
summary(logit_death)
tidy(logit_death,
     exponentiate = TRUE,   # turns log-odds → OR
     conf.int     = TRUE)   # adds 95 % CI
```

```{r}
logit_icd <- glm(hypercap_resp_failure ~ hypercapnia, data = subset_data, family = binomial)
summary(logit_icd)
tidy(logit_icd,
     exponentiate = TRUE,   # turns log-odds → OR
     conf.int     = TRUE)   # adds 95 % CI
```

```{r}
if (!requireNamespace("modelsummary", quietly = TRUE)) install.packages("modelsummary")
library(modelsummary)

modelsummary(
  list("Intubated" = logit_intubated,
       "NIV"       = logit_niv,
       "Death"     = logit_death,
       "ICD Hyper" = logit_icd),
  exponentiate = TRUE,
  conf_level   = 0.95,
  estimate     = "{estimate}",
  statistic    = "({conf.low}, {conf.high})",
  coef_omit    = "(Intercept)",
  gof_omit     = ".*",                      # drop all goodness-of-fit rows
  fmt          = 2,                         # 2 decimal places everywhere
  output       = "gt"
) |>
  gt::tab_header(title = "Odds Ratios for Hypercapnia (>45 mmHg)'s association with...")

```
