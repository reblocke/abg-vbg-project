---
title: "ABG‑VBG Analysis"
author: "Brian Locke, Anila Mehta"
editor: visual
format:
  pdf:
    toc: true
    number-sections: true
    pdf-engine: lualatex
    mainfont: "TeX Gyre Termes"
    geometry: 
      - landscape
      - margin=0.8in
    fig-width: 11
    fig-height: 7
    df-print: kable
fontsize: 11pt
---

# TODO

-   [ ] Need to finish comment style and labeling throughout the new code.

-   [ ] I'd like to add timestamps (ie. how long execution took of each cell) to the outputs.

-   [ ] **VBG winsorization bug -** In your VBG IPW block you compute cut \<- quantile(w, c(0.01, 1), na.rm = TRUE) and then clamp to \[cut\[1\], cut\[2\]\]. Because cut\[2\] is the *maximum* weight, there is no upper‑tail trimming. This is correct (because it is inverse propensity of sampling weighting - so only those not sampled are up-weighted. This should be fixed.

-   [ ] **Mix of standardized and raw differences in balance plots.** The love plot warns that “Standardized mean differences and raw mean differences are present in the same plot.” This happens when bal.tab uses raw diffs for binary variables and SMD for continuous ones. Set binary = "std" (and, commonly, s.d.denom = "pooled") in your bal.tab() call so *all* displayed metrics are SMDs and the warning disappears. Evidence: the warning text appears right under the love plot code.  Where you compute balance, change:

```         
cobalt::bal.tab(..., un = TRUE, m.threshold = 0.1)
```

to:

```         
cobalt::bal.tab(..., un = TRUE, m.threshold = 0.1,
                binary = "std", s.d.denom = "pooled")
```

-   [ ] **Document still contains the “Calculated ABG (Farkas)” section. All the calculated sections should be removed - not being included in the final analysis.** You mentioned removing it; the PDF still shows the section and models. Evidence: heading and code for calc_abg and hypercapnia_calc. 

-   [ ] **High missingness in the 3‑level CO₂ categories.** pco2_cat_abg missing in 1,630/2,491; pco2_cat_vbg in 1,778/2,491; pco2_cat_calc in 2,200/2,491. This drives the complete‑case drop noted above and will also affect any categorical CO₂ models. Evidence: skim table. 

-   [ ] **Table title mismatch.** The gt title says *“Odds Ratios for VBG Hypercapnia (\>45 mmHg)’s association with..”* immediately above the Calculated‑ABG section. That label is misleading (looks like a copy/paste). Evidence: the title right before the calc‑ABG heading. 

-   [ ] The three category PaCO2s in the imputed version earlier should be changed to mirror the ones used earlier - hypocapnia, eucapnia, and hypercapnia

-   [ ] **ABG vs VBG IPW tuning asymmetry - these should be the same. Currently,** The VBG block shows different tuning prose (“changed trees and bag fraction”), implying divergence from the ABG settings; just document so readers don’t infer drift as a bias. Evidence: the VBG section text notes altered tuning. 

    **Unit tests to add for Data hygiene / preprocessing, Propensity (WeightIt + GBM), Outcome modeling (svyglm), Imputation (mice), Explainability (fastshap + shapviz)**

-   [ ] **Type locks** for key fields (sex, encounter_type, race_ethnicity, outcomes). Assert intended classes and ≥2 levels after coercion and *before* MI and modeling.

-   [ ] **Missingness invariants.** Assert the count of non‑missing rows for each endpoint × exposure before/after MI; fail fast if massive drops occur.

-   [ ] **Deterministic sanity pass.** With m=1 and maxit=1, check that predictors/blocks match expectations (no outcomes in predictors; treatment not imputed).

-   [ ] **Weight diagnostics.** Assert: (i) mean(w)=1, (ii) fraction of weights at each winsor cutoff \< 2%, (iii) effective sample size (ESS) \> 20% of N after trimming.

-   [ ] **Balance targets.** Assert max(\|SMD\|) \< 0.1 across imputations; fail with a concise table of offenders if violated. (Use binary="std".)

-   [ ] **Common support.** For each imputation, assert predicted propensity in \[ε, 1−ε\] (e.g., ε=.01) with \<1% violations.

-   [ ] **Coefficient extraction guard.** Your helper already checks for finite coef/vcov. Keep it. Add a check that the treatment column is present and non‑aliased (no 1‑level factor in any imputation).

-   [ ] **Alignment test.** Before running SHAP, verify setequal(colnames(X_used), gbm\$var.names) and that factor levels in X_used are a subset of training levels; stop with a helpful message otherwise.

-   [ ] **Seed escrow.** Echo seeds used for MI, GBM, and SHAP into the PDF.

-   [ ] **Regression calibration checks (new)**

-   [ ] **Rename the gt title** above the calc‑ABG section (or remove the section) to prevent confusion in review copies. 

-   [ ] **Unicode/encoding artifacts.** Headings and labels display “PCO�” and “95�% CI”, indicating the document wasn’t rendered with full Unicode support (or strings contain a non‑standard thin‑space). You can also see this in the y‑axis label text blocks. 

-   [ ] **Plots drop rows because of invalid scale limits or missing values.** Several figures print “Removed … rows …” warnings. In one place the axis is log10 with a **negative lower limit**, which produces NaNs. Fix: never set a log scale minimum ≤ 0.  

-   [ ] I'd like to restructure this workbook thusly, paying attention to make sure that any helper functions or variables are still present when required: Pre-processing, baseline (unimputed tables), unweighted binary regressions ABG and VBG, unweighted three-level regressions ABG and VBG, unweighted spline regressions ABG and VBG, explainability/checks of propensity modeling ABG and VBG, IPSW binary regressions ABG and VBG, IPSW three-level-regressions ABG and VBG, IPSW spline regressions ABG and VBG, explainability/checks of multiple imputation, then MICE+IPSW binary regression ABG and VBG, MICE+IPSW three ctageory regression ABG and VBG, MICE+IPSW spline ABG and VBG

-   [ ] **Shapley plots emit warnings. l**oess near‑singularities and pseudo‑inverse messages (often due to very flat x‑ranges or duplicated x). “aesthetics dropped: colour” (stat layer not using mapped colour), “label cannot be a \<element_blank\> object.”

-   [ ] **High apparent missingness in 3‑level CO₂ categories (complete‑case drop).** The three‑category sections trigger “Removed rows…” and show large sample loss. This is expected if many encounters lack PaCO₂/VBG CO₂ (and you haven’t switched those analyses over to MI or inverse‑probability‑of‑observation). Flag it in the text or impute/weight appropriately.  

## Data Pre-processing

This code pulls in the master database (a STATA file) and does some initial cleaning - this will only need to be run once, and then the data can be accessed in the usual way.

```{r setup-table-helpers}
#| code-block-title: "Table helper functions"
# put this in your first R chunk
if (!requireNamespace("kableExtra", quietly = TRUE)) install.packages("kableExtra")
library(kableExtra)
library(gtsummary)
library(purrr)        # functional programming

# globally tighten gtsummary/gt tables (smaller font + tighter padding)
gtsummary::theme_gtsummary_compact()

# helper: turn any gtsummary table into a PDF-safe, auto-scaling LaTeX table
to_pdf_table <- function(tbl, font_size = 8, landscape = FALSE,
                         label_col_width = NULL) {
  kbl <- gtsummary::as_kable(
    tbl,
    format    = "latex",
    booktabs  = TRUE,
    longtable = TRUE # allows multipage tables; repeats header with kableExtra option below
  )

  # optional: set a fixed width for the first (label) column to encourage wrapping
  if (!is.null(label_col_width)) {
    kbl <- kableExtra::column_spec(kbl, 1, width = label_col_width)
  }

  kbl <- kableExtra::kable_styling(
    kbl,
    latex_options = c("repeat_header", "hold_position", "scale_down"),
    font_size     = font_size
  )

  if (landscape) kbl <- kableExtra::landscape(kbl) # needs pdflscape (enabled above)
  kbl
}
```

```{r setup-packages}
#| code-block-title: "Load and install required packages"
# Consolidated package management ------------------------------------------------
required_pkgs <- c(
  "WeightIt", "broom", "cobalt", "codebookr", "dplyr", "flextable", "parallel",
  "gbm", "ggplot2", "gt", "gtsummary", "haven", "labelled", "scales",
  "modelsummary", "officer", "patchwork", "rms", "survey", "tibble", "lubridate", "sensitivitymw"
)

# Install any missing packages (with dependencies)
missing_pkgs <- setdiff(required_pkgs, rownames(installed.packages()))
if (length(missing_pkgs)) {
  install.packages(missing_pkgs, dependencies = TRUE)
}

# Load (or attach) all required packages
invisible(lapply(required_pkgs, require, character.only = TRUE))

# ensure predictable, writable figure path + robust PNG device
knitr::opts_chunk$set(
  fig.path = "figs/",   # short local dir for figures
  dev      = "png",
  dpi      = 144
)
dir.create("figs", showWarnings = FALSE, recursive = TRUE)
# on macOS and some setups this prevents device headaches
options(bitmapType = "cairo")

if (!requireNamespace("shapviz", quietly = TRUE) ||
    packageVersion("shapviz") < "0.2.0") {
  install.packages("shapviz")  # or: remotes::install_github("ModelOriented/shapviz")
}

if (interactive() && !requireNamespace("fastshap", quietly = TRUE)) {
  options(repos = c(CRAN = "https://cran.rstudio.com/"))
  install.packages("fastshap")
}

if (interactive() && !requireNamespace("fastshap", quietly = TRUE)) {
  options(repos = c(CRAN = "https://cran.rstudio.com/"))
  install.packages("DALEX")
}

if (interactive() && !requireNamespace("fastshap", quietly = TRUE)) {
  options(repos = c(CRAN = "https://cran.rstudio.com/"))
  install.packages("shapviz")
}
```

```{r gt-pdf-helper}
#| code-block-title: "GT PDF styling helper"
# Make gt tables robust in PDF: full width, caption, small font
gt_pdf <- function(x, title = NULL, subtitle = NULL) {
  out <- x |>
    gt::tab_options(
      table.width              = gt::pct(100),
      table.align              = "left",
      table.font.size          = gt::px(9),
      data_row.padding         = gt::px(1),
      column_labels.font.size  = gt::px(9),
      heading.title.font.size  = gt::px(10),
      heading.subtitle.font.size = gt::px(9)
    ) |>
    gt::opt_align_table_header(align = "left")
  if (!is.null(title))    out <- out |> gt::tab_caption(title)
  if (!is.null(subtitle)) out <- out |> gt::tab_source_note(subtitle)
  out
}
```

Converts the data from a STATA format to rdata if the rdata file does not exist. If it does already exist, it just loads that.

```{r load-trinetx-data}
#| code-block-title: "Load TriNetX data (Stata or RData)"
# data_dir_name <- '/Users/blocke/Box Sync/Residency Personal Files/Scholarly Work/Locke Research Projects/abg-vbg-project/data' # 'data/' this is changed from just
data_dir_name <- '/Users/reblocke/Research/abg-vbg-project/data'

rdata_file <- file.path(data_dir_name, "full_trinetx.rdata")
stata_file <- file.path(data_dir_name, "full_db.dta")

if (!dir.exists(data_dir_name)) {
  dir.create(data_dir_name)
  message("Directory 'data' created.")
} else {
  message("Directory 'data' already exists.")
}

if (file.exists(rdata_file)) {
  load(rdata_file)
  message("Loaded existing dataset from 'full_trinetx.rdata'.")
} else {
  message("RData file not found. Reading Stata dataset...")
  stata_data <- read_dta(stata_file)
  
  message("Extracting variable labels...")
  var_label(stata_data)

  message("Extracting value labels...")
  sapply(stata_data, function(x) if (is.labelled(x)) val_labels(x))

  save(stata_data, file = rdata_file)
  message("Dataset saved as 'full_trinetx.rdata'.")

  load(rdata_file)
  message("Loaded newly saved dataset from 'full_trinetx.rdata'.")
}
```

Creating subset_data

```{r sample-subset-data}
#| code-block-title: "Sample analysis subset"
set.seed(123)
rows_to_keep <- round(nrow(stata_data) * 0.01) #1 for real run
subset_data <- stata_data[sample(nrow(stata_data), rows_to_keep), ]

subset_data <- subset_data %>%
  filter(encounter_type != 1)

table(subset_data$encounter_type)

dim(subset_data)
```

Generating Codebook for the Full Dataset

```{r codebook-export-full}
#| code-block-title: "Generate codebook for full dataset"
message("Generating codebook for the dataset...")
study_codebook <- codebookr::codebook(
  stata_data,
  title = "Full TrinetX",
  subtitle = "Dataset Documentation",
  description = "This dataset contains patient-level records from the TrinetX database. 
                 It has been processed and converted from the original Stata file."
)
codebook_file <- file.path(data_dir_name, "codebookr.docx")
print(study_codebook, codebook_file)
message("Codebook saved as 'codebookr.docx' in the data directory.")
```

New Variable - Death at 60 days

```{r derive-death-60d}
#| code-block-title: "Derive death_60d and timing variables"
subset_data <- subset_data %>%
  mutate(
    ## 1. Did the patient die?
    died = if_else(!is.na(death_date), 1L, 0L),

    ## 2. Absolute death date (if death_date is an offset)
    death_abs = if_else(!is.na(death_date),
                        encounter_date + death_date,
                        as.Date(NA)),

    ## 3. Year month (YM) for encounter and death
    enc_ym   = floor_date(encounter_date, unit = "month"),
    death_ym = floor_date(death_abs      , unit = "month"),

    ## 4. Reference censoring date: 1 Jun 2024
    ref_ym = ymd("2024-06-01"),

    ## 5. Months from encounter to death or censoring
    months_death_or_cens = case_when(
      !is.na(death_ym) ~ interval(enc_ym, death_ym) %/% months(1),
      TRUE             ~ interval(enc_ym, ref_ym)   %/% months(1)
    ),

    ## 6. Remove impossible values
    months_death_or_cens = if_else(
      months_death_or_cens < 0 | months_death_or_cens > 16,
      NA_integer_, months_death_or_cens
    ),

    ## 7. Death within one or two months
    died_1mo = if_else(died == 1 & months_death_or_cens <  1, 1L, 0L),
    died_2mo = if_else(died == 1 & months_death_or_cens <= 1, 1L, 0L),

    ## 8. Month of death (missing if censored)
    death_time = if_else(died == 1, months_death_or_cens, NA_integer_),

    ## 9. Death within 60 days (new variable)
    death_60d = if_else(died == 1 & death_abs <= (encounter_date + days(60)), 1L, 0L)
  ) %>%
  select(-enc_ym, -death_ym)

subset_data <- subset_data %>%
  mutate(
    death_60d = if_else(died == 1 & death_abs <= (encounter_date + days(60)), 1L, 0L)
  )

```

```{r death-60d-summary}
#| code-block-title: "Summarize death_60d"
table(subset_data$death_60d, useNA = "ifany")
prop.table(table(subset_data$death_60d, useNA = "ifany"))
summary(subset_data$death_60d)
```

## Baseline Tables

Table 1A and 1B:

```{r derive-table1-cohorts}
#| code-block-title: "Derive ABG/VBG cohort variables for Table 1"
# Robust derivation of analysis variables + helper for Table 1 production
# ---------------------------------------------------------------------------

# helper: label binary 0/1 → "No"/"Yes"
bin_lab <- function(x) factor(x, levels = c(0, 1), labels = c("No", "Yes"))

subset_data <- subset_data %>% 
  mutate(
    ## ensure 0/1 numerics (avoids factor‑level coercion)
    across(c(has_abg, has_vbg, hypercap_on_abg, hypercap_on_vbg),
           ~ as.numeric(as.character(.))),
    
    ## derive ABG / VBG hypercapnia groups
    abg_group
    = case_when(
      has_abg == 0                         ~ "No ABG",
      has_abg == 1 & hypercap_on_abg == 0  ~ "ABG_NoHypercapnia",
      has_abg == 1 & hypercap_on_abg == 1  ~ "ABG_Hypercapnia",
      TRUE                                 ~ "Missing"
    ),
    vbg_group = case_when(
      has_vbg == 0                         ~ "No VBG",
      has_vbg == 1 & hypercap_on_vbg == 0  ~ "VBG_NoHypercapnia",
      has_vbg == 1 & hypercap_on_vbg == 1  ~ "VBG_Hypercapnia",
      TRUE                                 ~ "Missing"
    ),
    
    ## factorise groups with explicit NA/Missing level
    abg_group = factor(
      abg_group,
      levels = c("No ABG", "ABG_NoHypercapnia", "ABG_Hypercapnia", "Missing")
    ),
    vbg_group = factor(
      vbg_group,
      levels = c("No VBG", "VBG_NoHypercapnia", "VBG_Hypercapnia", "Missing")
    ),
    
    ## labelled covariates
    sex_label      = factor(sex, levels = c(0, 1), labels = c("Female", "Male")),
    race_ethnicity_label     = factor(
      race_ethnicity,
      levels = c(0, 1, 2, 3, 4, 5, 6),
      labels = c("White", "Black or African American", "Hispanic",
                 "Asian", "American Indian", "Pacific Islander", "Unknown")
    ), location_label     = factor(
      location,
      levels = c(0, 1, 2, 3),
      labels = c("South", "Northeast" ,"Midwest", "West")
    ), encounter_type_label = factor(
      encounter_type,
      levels = c(2, 3),
      labels = c("Emergency", "Inpatient")
    ),
    osa_label      = bin_lab(osa),
    asthma_label   = bin_lab(asthma),
    copd_label     = bin_lab(copd),
    chf_label      = bin_lab(chf),
    nmd_label      = bin_lab(nmd),
    phtn_label     = bin_lab(phtn),
    ckd_label      = bin_lab(ckd),
    diabetes_label = bin_lab(dm)
  )

# variables to summarise
vars <- c(
  "age_at_encounter", "curr_bmi", "sex_label", "race_ethnicity_label", "location_label",
  "osa_label", "asthma_label", "copd_label", "chf_label", "nmd_label",
  "phtn_label", "ckd_label", "diabetes_label", "encounter_type_label", "vbg_co2", "paco2"
)

# Table 1 constructor
make_table1 <- function(data, group_var, caption = "") {
  group_sym <- rlang::sym(group_var)

  data %>% 
    filter(!is.na(!!group_sym),                   # drop explicit NA
           !!group_sym != "Missing") %>%          # drop “Missing” cohort
    droplevels() %>%                              # trim empty factor levels
    select(all_of(c(group_var, vars))) %>% 
    gtsummary::tbl_summary(
      by   = !!group_sym,
      type = list(sex_label ~ "categorical"),
      statistic = list(
        gtsummary::all_continuous()  ~ "{mean} ± {sd}; {N_miss}/{N_obs} missing ({p_miss}%)",
        gtsummary::all_categorical() ~ "{n} ({p}%)"
      ),
      digits   = list(gtsummary::all_continuous() ~ 1),
      missing  = "no"                               # no gtsummary missing column/row
    ) %>% 
    gtsummary::modify_header(label = "**Variable**") %>% 
    gtsummary::modify_caption(caption)
}

# build tables
table1A <- make_table1(subset_data, "abg_group", caption = "Table 1A: ABG cohorts")
table1B <- make_table1(subset_data, "vbg_group", caption = "Table 1B: VBG cohorts")

table1A
table1B
```

Generating Word Doc for Table 1A & 1B

```{r export-table1a-table1b-word}
#| code-block-title: "Export Table 1A/1B to Word"
ft_table1A <- as_flex_table(table1A)
ft_table1B <- as_flex_table(table1B)

doc <- read_docx() %>%
  body_add_par("Table 1A. Baseline Characteristics by ABG Group", style = "heading 1") %>%
  body_add_flextable(ft_table1A) %>%
  body_add_par("Table 1B. Baseline Characteristics by VBG Group", style = "heading 1") %>%
  body_add_flextable(ft_table1B)

print(doc, target = "Table1_ABG_VBG.docx")

```

### Table 1 (Overall ABG/VBG status)

NEW Table 1

```{r table1-everyone-abg-vbg}
#| code-block-title: "Table 1: Everyone and ABG/VBG status"
# Status factors (column labels are taken from factor levels)
subset_data <- subset_data %>%
  mutate(
    abg_status = factor(has_abg, levels = c(0, 1),
                        labels = c("Did not get ABG", "Did get ABG")),
    vbg_status = factor(has_vbg, levels = c(0, 1),
                        labels = c("Did not get VBG", "Did get VBG"))
  )

# ABG table with "Everyone" column first
tbl1_abg <- subset_data %>%
  select(all_of(vars), abg_status) %>%
  gtsummary::tbl_summary(
    by = abg_status,
    type = list(sex_label ~ "categorical"),
    statistic = list(
      gtsummary::all_continuous()  ~ "{mean} ± {sd}; {N_miss}/{N_obs} missing ({p_miss}%)",
      gtsummary::all_categorical() ~ "{n} ({p}%)"
    ),
    digits   = list(gtsummary::all_continuous() ~ 1),
    missing  = "no"
  ) %>%
  gtsummary::add_overall(last = FALSE, col_label = "Everyone") %>%
  gtsummary::modify_header(label = "**Variable**")

# VBG table (no "Everyone" here)
tbl1_vbg <- subset_data %>%
  select(all_of(vars), vbg_status) %>%
  gtsummary::tbl_summary(
    by = vbg_status,
    type = list(sex_label ~ "categorical"),
    statistic = list(
      gtsummary::all_continuous()  ~ "{mean} ± {sd}; {N_miss}/{N_obs} missing ({p_miss}%)",
      gtsummary::all_categorical() ~ "{n} ({p}%)"
    ),
    digits   = list(gtsummary::all_continuous() ~ 1),
    missing  = "no"
  ) %>%
  gtsummary::modify_header(label = "**Variable**")

library(gtsummary)

tbl1 <- tbl_merge(
  tbls = list(tbl1_abg, tbl1_vbg)
) %>%
  modify_caption("**Table 1. Baseline summary: Everyone, ABG status, and VBG status**")

tbl1
```

### Table 2 (Hypercapnia within cohorts)

NEW Table 2

```{r table2-hypercapnia-cohorts}
#| code-block-title: "Table 2: Hypercapnia within cohorts"
# Hypercapnia factors within measured cohorts
subset_data <- subset_data %>%
  mutate(
    hyper_abg = factor(hypercap_on_abg, levels = c(1, 0),
                       labels = c("Got ABG & Hypercapnia", "Got ABG & No hypercapnia")),
    hyper_vbg = factor(hypercap_on_vbg, levels = c(1, 0),
                       labels = c("Got VBG & Hypercapnia", "Got VBG & No hypercapnia"))
  )

# ABG cohort (has_abg == 1)
tbl2_abg <- subset_data %>%
  filter(has_abg == 1) %>%
  select(all_of(vars), hyper_abg) %>%
  gtsummary::tbl_summary(
    by = hyper_abg,
    type = list(sex_label ~ "categorical"),
    statistic = list(
      gtsummary::all_continuous()  ~ "{mean} ± {sd}; {N_miss}/{N_obs} missing ({p_miss}%)",
      gtsummary::all_categorical() ~ "{n} ({p}%)"
    ),
    digits   = list(gtsummary::all_continuous() ~ 1),
    missing  = "no"
  ) %>%
  gtsummary::modify_header(
    label  = "**Variable**",
    stat_1 = "**Got ABG & Hypercapnia**",
    stat_2 = "**Got ABG & No hypercapnia**"
  )

# VBG cohort (has_vbg == 1)
tbl2_vbg <- subset_data %>%
  filter(has_vbg == 1) %>%
  select(all_of(vars), hyper_vbg) %>%
  gtsummary::tbl_summary(
    by = hyper_vbg,
    type = list(sex_label ~ "categorical"),
    statistic = list(
      gtsummary::all_continuous()  ~ "{mean} ± {sd}; {N_miss}/{N_obs} missing ({p_miss}%)",
      gtsummary::all_categorical() ~ "{n} ({p}%)"
    ),
    digits   = list(gtsummary::all_continuous() ~ 1),
    missing  = "no"
  ) %>%
  gtsummary::modify_header(
    label  = "**Variable**",
    stat_1 = "**Got VBG & Hypercapnia**",
    stat_2 = "**Got VBG & No hypercapnia**"
  )

# Merge side-by-side (no spanners; 4 requested columns)
table2 <- gtsummary::tbl_merge(
  tbls = list(tbl2_abg, tbl2_vbg),
  tab_spanner = c(NULL, NULL)
) %>%
  gtsummary::modify_caption("**Table 2. Baseline summary by hypercapnia within ABG and VBG cohorts**")

table2
```

Generating Word Docs for New Table 1 and 2

```{r export-table1-table2-word}
#| code-block-title: "Export merged Table 1 and Table 2 to Word"
library(gtsummary)
library(flextable)
library(officer)

# gtsummary objects (example: table1, table2)
ft1 <- as_flex_table(tbl1)
ft2 <- as_flex_table(table2)

doc <- read_docx() %>%
  body_add_par("Table 1", style = "heading 1") %>%
  body_add_flextable(ft1) %>%
  body_add_par("Table 2", style = "heading 1") %>%
  body_add_flextable(ft2)

print(doc, target = "Tables.docx")

```

## Unweighted Binary Logistic Regressions

**Unweighted, Hypercapnia (binary yes/no) Simple (1 predictor) Regressions:**

Unweighted, ABG Group: hypercapnia treated as a binary (yes/no) predictor

### ABG: Binary hypercapnia models

```{r abg-binary-logit-models}
#| code-block-title: "Unweighted ABG binary logistic models"
logit_intubated_abg <- glm(imv_proc ~ hypercap_on_abg, data = subset_data, family = binomial)
summary(logit_intubated_abg)

tidy(logit_intubated_abg,
     exponentiate = TRUE,   # turns log-odds → OR
     conf.int     = TRUE)   # adds 95 % CI

logit_niv_abg <- glm(niv_proc ~ hypercap_on_abg, data = subset_data, family = binomial)
summary(logit_niv_abg)

tidy(logit_niv_abg,
     exponentiate = TRUE,   # turns log-odds → OR
     conf.int     = TRUE)   # adds 95 % CI

logit_death_abg <- glm(death_60d ~ hypercap_on_abg, data = subset_data, family = binomial)
summary(logit_death_abg)
tidy(logit_death_abg,
     exponentiate = TRUE,   # turns log-odds → OR
     conf.int     = TRUE)   # adds 95 % CI

logit_icd_abg <- glm(hypercap_resp_failure ~ hypercap_on_abg, data = subset_data, family = binomial)
summary(logit_icd_abg)
tidy(logit_icd_abg,
     exponentiate = TRUE,   # turns log-odds → OR
     conf.int     = TRUE)   # adds 95 % CI

```

Display the regression coefficients for the binary (hypercapnia yes/no) predictor logistic regressions

```{r abg-binary-or-table}
#| code-block-title: "Odds ratios: ABG binary hypercapnia"
modelsummary(
  list("Intubated" = logit_intubated_abg,
       "NIV"       = logit_niv_abg,
       "Death"     = logit_death_abg,
       "ICD Hyper" = logit_icd_abg),
  exponentiate = TRUE,
  conf_level   = 0.95,
  estimate     = "{estimate}",
  statistic    = "({conf.low}, {conf.high})",
  coef_omit    = "(Intercept)",
  gof_omit     = ".*",                      # drop all goodness-of-fit rows
  fmt          = 2,                         # 2 decimal places everywhere
  output       = "gt"
) |>
  gt_pdf(title = "Odds Ratios for ABG Hypercapnia (>45 mmHg)'s association with...")
```

Unweighted VBG Group

### VBG: Binary hypercapnia models

```{r vbg-binary-logit-models}
#| code-block-title: "Unweighted VBG binary logistic models"
logit_intubated_vbg <- glm(imv_proc ~ hypercap_on_vbg, data = subset_data, family = binomial)
summary(logit_intubated_vbg)
tidy(logit_intubated_vbg,
     exponentiate = TRUE,   # turns log-odds → OR
     conf.int     = TRUE)   # adds 95 % CI

logit_niv_vbg <- glm(niv_proc ~ hypercap_on_vbg, data = subset_data, family = binomial)
summary(logit_niv_vbg)
tidy(logit_niv_vbg,
     exponentiate = TRUE,   # turns log-odds → OR
     conf.int     = TRUE)   # adds 95 % CI

logit_death_vbg <- glm(death_60d ~ hypercap_on_vbg, data = subset_data, family = binomial)
summary(logit_death_vbg)
tidy(logit_death_vbg,
     exponentiate = TRUE,   # turns log-odds → OR
     conf.int     = TRUE)   # adds 95 % CI

logit_icd_vbg <- glm(hypercap_resp_failure ~ hypercap_on_vbg, data = subset_data, family = binomial)
summary(logit_icd_vbg)
tidy(logit_icd_vbg,
     exponentiate = TRUE,   # turns log-odds → OR
      conf.int     = TRUE)   # adds 95 % CI
```

Display model coefficients for binary hypercapnia on VBG logistic regression

```{r vbg-binary-or-table}
#| code-block-title: "Odds ratios: VBG binary hypercapnia"
modelsummary(
  list("Intubated" = logit_intubated_vbg,
       "NIV"       = logit_niv_vbg,
       "Death"     = logit_death_vbg,
       "ICD Hyper" = logit_icd_vbg),
  exponentiate = TRUE,
  conf_level   = 0.95,
  estimate     = "{estimate}",
  statistic    = "({conf.low}, {conf.high})",
  coef_omit    = "(Intercept)",
  gof_omit     = ".*",                      # drop all goodness-of-fit rows
  fmt          = 2,                         # 2 decimal places everywhere
  output       = "gt"
) |>
  gt_pdf(title = "Odds Ratios for VBG Hypercapnia (>45 mmHg)'s association with...")
```

Calculated ABG from VBG Using Farkas equation - binary predictor

### Calculated ABG (Farkas) binary hypercapnia models

```{r calc-abg-farkas-derive}
#| code-block-title: "Derive calculated ABG (Farkas) hypercapnia"
subset_data <- subset_data %>%
  mutate(
    calc_abg = vbg_co2 - (0.22 * (93 - vbg_o2sat))
  )
subset_data <- subset_data %>%
  mutate(
    hypercapnia_calc = ifelse(calc_abg > 45, 1, 0)
  )
with(subset_data, table(hypercapnia_calc,niv_proc))
```

```{r calc-abg-binary-logit-models}
#| code-block-title: "Unweighted calculated ABG binary logistic models"
logit_intubated_calc <- glm(imv_proc ~ hypercapnia_calc, data = subset_data, family = binomial)
summary(logit_intubated_calc)

tidy(logit_intubated_calc,
     exponentiate = TRUE,   # turns log-odds → OR
     conf.int     = TRUE)   # adds 95 % CI

logit_niv_calc <- glm(niv_proc ~ hypercapnia_calc, data = subset_data, family = binomial)
summary(logit_niv_calc)

tidy(logit_niv_calc,
     exponentiate = TRUE,   # turns log-odds → OR
     conf.int     = TRUE)   # adds 95 % CI

logit_death_calc <- glm(death_60d ~ hypercapnia_calc, data = subset_data, family = binomial)
summary(logit_death_calc)

tidy(logit_death_calc,
     exponentiate = TRUE,   # turns log-odds → OR
     conf.int     = TRUE)   # adds 95 % CI

logit_icd_calc <- glm(hypercap_resp_failure ~ hypercapnia_calc, data = subset_data, family = binomial)
summary(logit_icd_calc)

tidy(logit_icd_calc,
     exponentiate = TRUE,   # turns log-odds → OR
      conf.int     = TRUE)   # adds 95 % CI
```

Display regression coefficients for binary Farkas adjustment (hypercapnia yes/no as predictor)

```{r calc-abg-binary-or-table}
#| code-block-title: "Odds ratios: calculated ABG binary hypercapnia"
modelsummary(
  list("Intubated" = logit_intubated_calc,
       "NIV"       = logit_niv_calc,
       "Death"     = logit_death_calc,
       "ICD Hyper" = logit_icd_calc),
  exponentiate = TRUE,
  conf_level   = 0.95,
  estimate     = "{estimate}",
  statistic    = "({conf.low}, {conf.high})",
  coef_omit    = "(Intercept)",
  gof_omit     = ".*",                      # drop all goodness-of-fit rows
  fmt          = 2,                         # 2 decimal places everywhere
  output       = "gt"
) |>
  gt_pdf(title = "Odds Ratios for Calculated Hypercapnia (>45 mmHg)'s association with...")
```

### Combined OR visualizations (binary hypercapnia)

Odds Ratio Graph of all 3 simple, binary-predictor logistic regressions

```{r or-data-binary-unweighted}
#| code-block-title: "Assemble OR data (binary hypercapnia)"
tidy_with_labels <- function(model, group_label, outcome_label) {
  tidy(model, exponentiate = TRUE, conf.int = TRUE) %>%
    filter(term == "hypercap_on_abg" | term == "hypercap_on_vbg" | term == "hypercapnia_calc") %>%
    mutate(
      group = group_label,
      outcome = outcome_label
    )
}

# --- ABG Models ---
abg_intub <- tidy_with_labels(glm(imv_proc ~ hypercap_on_abg, data = subset_data, family = binomial), "ABG", "Intubation")
abg_niv   <- tidy_with_labels(glm(niv_proc ~ hypercap_on_abg, data = subset_data, family = binomial), "ABG", "NIV")
abg_death <- tidy_with_labels(glm(death_60d ~ hypercap_on_abg, data = subset_data, family = binomial), "ABG", "Death")
abg_icd   <- tidy_with_labels(glm(hypercap_resp_failure ~ hypercap_on_abg, data = subset_data, family = binomial), "ABG", "ICD Code")

# --- VBG Models ---
vbg_intub <- tidy_with_labels(glm(imv_proc ~ hypercap_on_vbg, data = subset_data, family = binomial), "VBG", "Intubation")
vbg_niv   <- tidy_with_labels(glm(niv_proc ~ hypercap_on_vbg, data = subset_data, family = binomial), "VBG", "NIV")
vbg_death <- tidy_with_labels(glm(death_60d ~ hypercap_on_vbg, data = subset_data, family = binomial), "VBG", "Death")
vbg_icd   <- tidy_with_labels(glm(hypercap_resp_failure ~ hypercap_on_vbg, data = subset_data, family = binomial), "VBG", "ICD Code")

# --- Calculated ABG Models ---
calc_intub <- tidy_with_labels(glm(imv_proc ~ hypercapnia_calc, data = subset_data, family = binomial), "Calculated ABG", "Intubation")
calc_niv   <- tidy_with_labels(glm(niv_proc ~ hypercapnia_calc, data = subset_data, family = binomial), "Calculated ABG", "NIV")
calc_death <- tidy_with_labels(glm(death_60d ~ hypercapnia_calc, data = subset_data, family = binomial), "Calculated ABG", "Death")
calc_icd   <- tidy_with_labels(glm(hypercap_resp_failure ~ hypercapnia_calc, data = subset_data, family = binomial), "Calculated ABG", "ICD Code")

# --- Combine all model results ---
combined_or_df <- bind_rows(
  abg_intub, abg_niv, abg_death, abg_icd,
  vbg_intub, vbg_niv, vbg_death, vbg_icd,
  calc_intub, calc_niv, calc_death, calc_icd
)
```

```{r or-plot-binary-initial}
#| code-block-title: "Plot ORs (binary hypercapnia, initial)"
ggplot(combined_or_df, aes(x = outcome, y = estimate, ymin = conf.low, ymax = conf.high, color = group)) +
  geom_pointrange(position = position_dodge(width = 0.5), size = 0.6) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "gray40") +
  coord_flip() +
  labs(
    title = "Unweighted, Unadjusted OR of Outcomes when Hypercapnia Present ABG, VBG, Farkas-VBG ",
    x = "Outcome",
    y = "Odds Ratio (95% CI)",
    color = "Group"
  ) +
  scale_y_log10(limits = c(-0.5, 15)) +  # optional log scale for better spacing
  theme_minimal(base_size = 10)

combined_or_df$group <- factor(combined_or_df$group,
  levels = c("ABG", "VBG", "Calculated ABG"))
```

```{r or-plot-binary-logscale}
#| code-block-title: "Plot ORs (binary hypercapnia, log scale)"
# ── prerequisites ───────────────────────────────────────────────────────────────

# order groups before plotting
combined_or_df$group <- factor(
  combined_or_df$group,
  levels = c("ABG", "VBG", "Calculated ABG")
)

# ── plot ────────────────────────────────────────────────────────────────────────
ggplot(
  combined_or_df,
  aes(
    x      = outcome,
    y      = estimate,
    ymin   = conf.low,
    ymax   = conf.high,
    color  = group
  )
) +
  geom_pointrange(
    position = position_dodge(width = 0.6),
    size     = 0.6
  ) +
  geom_hline(yintercept = 1, linetype = "dashed", colour = "grey40") +
  ## NOTE:  scale_y_log10 applies to the axis that *becomes horizontal* after coord_flip()
  scale_y_log10(
    breaks = c(0.25, 0.5, 1, 2, 4, 8, 16),
    limits = c(0.25, 16),
    labels = number_format(accuracy = 0.01)
  ) +
  coord_flip() +
  labs(
    title  = "Odds Ratio of Outcomes When Hypercapnia Present (ABG, VBG, Calc‑ABG)",
    x      = "Outcome",
    y      = "Odds Ratio (log scale, 95 % CI)",
    color  = "Blood‑gas type",
    caption = paste(
      "Odds ratios are computed *within* each blood‑gas cohort.",
      "Numerator = patients who received that blood‑gas and **had** hypercapnia;",
      "denominator = patients who received the same blood‑gas and **did not** have hypercapnia.",
      "Because the underlying cohorts differ (ABG, VBG, Calculated ABG),",
      "denominators are not identical across groups.",
      sep = "\n"
    )
  ) +
  theme_minimal(base_size = 10) +
  theme(plot.caption = element_text(hjust = 0))
```

### Three-level PCO₂ categories (unweighted)

Now doing 3 groups instead of binary (above, normal and below)

```{r or-data-three-level-unweighted}
#| code-block-title: "Assemble OR data (three-level PCO2 categories)"
subset_data <- subset_data %>%
  mutate(
    pco2_cat_abg = case_when(
      !is.na(paco2) & paco2 < 35 ~ "Below normal",
      !is.na(paco2) & paco2 > 45 ~ "Above normal",
      !is.na(paco2)              ~ "Normal"
    ),
    pco2_cat_vbg = case_when(
      !is.na(vbg_co2) & vbg_co2 < 40 ~ "Below normal",
      !is.na(vbg_co2) & vbg_co2 > 50 ~ "Above normal",
      !is.na(vbg_co2)                ~ "Normal"
    ),
    pco2_cat_calc = case_when(
      !is.na(calc_abg) & calc_abg < 35 ~ "Below normal",
      !is.na(calc_abg) & calc_abg > 45 ~ "Above normal",
      !is.na(calc_abg)                 ~ "Normal"
    )
  ) %>%
  mutate(
    across(starts_with("pco2_cat"),
           ~factor(.x, levels = c("Normal", "Below normal", "Above normal")))
  )

library(broom)
library(dplyr)

run_logit <- function(data, outcome, exposure, group_name) {
  f <- as.formula(paste(outcome, "~", exposure))
  glm(f, data = data, family = binomial) %>%
    tidy(exponentiate = TRUE, conf.int = TRUE) %>%
    filter(term != "(Intercept)") %>%
    mutate(
      outcome = outcome,
      group   = group_name
    )
}

outcomes <- c("imv_proc", "niv_proc", "death_60d", "hypercap_resp_failure")

results <- bind_rows(
  lapply(outcomes, function(o) run_logit(subset_data, o, "pco2_cat_abg", "ABG")),
  lapply(outcomes, function(o) run_logit(subset_data, o, "pco2_cat_vbg", "VBG")),
  lapply(outcomes, function(o) run_logit(subset_data, o, "pco2_cat_calc", "Calculated ABG"))
)

combined_or_df <- results %>%
  mutate(
    exposure = recode(term,
                      "pco2_cat_abgBelow normal"   = "Below normal",
                      "pco2_cat_abgAbove normal"   = "Above normal",
                      "pco2_cat_vbgBelow normal"   = "Below normal",
                      "pco2_cat_vbgAbove normal"   = "Above normal",
                      "pco2_cat_calcBelow normal"  = "Below normal",
                      "pco2_cat_calcAbove normal"  = "Above normal"),
    outcome = recode(outcome,
                     imv_proc = "Intubation",
                     niv_proc = "NIV",
                     death_60d = "Death (60d)",
                     hypercap_resp_failure = "Hypercapnic RF")
  ) %>%
  select(outcome, group, exposure, estimate, conf.low, conf.high)

```

```{r or-plot-three-level-unweighted}
#| code-block-title: "Plot ORs (three-level PCO2 categories)"
library(scales)

combined_or_df$group <- factor(
  combined_or_df$group,
  levels = c("ABG", "VBG", "Calculated ABG")
)

ggplot(
  combined_or_df,
  aes(
    x      = outcome,
    y      = estimate,
    ymin   = conf.low,
    ymax   = conf.high,
    color  = group,
    shape  = exposure
  )
) +
  geom_pointrange(
    position = position_dodge(width = 0.7),
    size     = 0.6
  ) +
  geom_hline(yintercept = 1, linetype = "dashed", colour = "grey40") +
  scale_y_log10(
    breaks = c(0.25, 0.5, 1, 2, 4, 8, 16),
    limits = c(0.25, 16),
    labels = number_format(accuracy = 0.01)
  ) +
  coord_flip() +
  labs(
    title  = "Odds Ratios of Outcomes by PCO2 Category (ABG, VBG, Calc-ABG)",
    x      = "Outcome",
    y      = "Odds Ratio (log scale, 95% CI)",
    color  = "Blood-gas type",
    shape  = "PCO2 category",
    caption = paste(
      "Odds ratios are computed within each blood-gas cohort.",
      "Reference = patients in the normal PCO2 range.",
      "Below normal: <35 mmHg. Above normal: >45 mmHg (ABG, Calc-ABG) or >50 mmHg (VBG).",
      "Because the underlying cohorts differ (ABG, VBG, Calculated ABG), denominators are not identical across groups.",
      sep = "\n"
    )
  ) +
  theme_minimal(base_size = 10) +
  theme(plot.caption = element_text(hjust = 0))

```

## Restricted Cubic Spline Regressions (Unweighted)

```{r rcs-abg-data-prep}
#| code-block-title: "Prepare ABG data for unweighted RCS"
# ABG spline dataset
subset_data_abg <- subset_data %>%
  select(paco2, imv_proc, niv_proc, death_60d, hypercap_resp_failure) %>%
  filter(!is.na(paco2))

dd_abg <- datadist(subset_data_abg)
options(datadist = "dd_abg")

```

Unweighted, Restricted Cubic Spline Regression - ABG by PaCO2

```{r rcs-abg-unweighted-models}
#| code-block-title: "Unweighted ABG restricted cubic spline models"
fit_imv <- lrm(imv_proc ~ rcs(paco2, 4), data = subset_data_abg)
pred_imv <- as.data.frame(Predict(fit_imv, paco2, fun = plogis))

plot_imv <- ggplot(pred_imv, aes(x = paco2, y = yhat)) +
  geom_line(color = "blue", size = 1.2) +
  geom_ribbon(aes(ymin = lower, ymax = upper), fill = "blue", alpha = 0.2) +
  labs(title = "Probability of Intubation by PaCO₂",
       x = "PaCO₂ (mmHg)", y = "Predicted Probability") +
  theme_minimal()

fit_niv <- lrm(niv_proc ~ rcs(paco2, 4), data = subset_data_abg)
pred_niv <- as.data.frame(Predict(fit_niv, paco2, fun = plogis))

plot_niv <- ggplot(pred_niv, aes(x = paco2, y = yhat)) +
  geom_line(color = "green", size = 1.2) +
  geom_ribbon(aes(ymin = lower, ymax = upper), fill = "green", alpha = 0.2) +
  labs(title = "Probability of NIV by PaCO₂",
       x = "PaCO₂ (mmHg)", y = "Predicted Probability") +
  theme_minimal()

fit_death <- lrm(death_60d ~ rcs(paco2, 4), data = subset_data_abg)
pred_death <- as.data.frame(Predict(fit_death, paco2, fun = plogis))

plot_death <- ggplot(pred_death, aes(x = paco2, y = yhat)) +
  geom_line(color = "red", size = 1.2) +
  geom_ribbon(aes(ymin = lower, ymax = upper), fill = "red", alpha = 0.2) +
  labs(title = "Probability of Death by PaCO₂",
       x = "PaCO₂ (mmHg)", y = "Predicted Probability") +
  theme_minimal()

fit_hcrf <- lrm(hypercap_resp_failure ~ rcs(paco2, 4), data = subset_data_abg)
pred_hcrf <- as.data.frame(Predict(fit_hcrf, paco2, fun = plogis))

plot_hcrf <- ggplot(pred_hcrf, aes(x = paco2, y = yhat)) +
  geom_line(color = "purple", size = 1.2) +
  geom_ribbon(aes(ymin = lower, ymax = upper), fill = "purple", alpha = 0.2) +
  labs(title = "Probability of Hypercapnic Respiratory Failure by PaCO₂",
       x = "PaCO₂ (mmHg)", y = "Predicted Probability") +
  theme_minimal()

(plot_imv | plot_niv) / (plot_death | plot_hcrf)

```

Unweighted, Restricted Cubic Spline - VBG

```{r rcs-vbg-data-prep}
#| code-block-title: "Prepare VBG data for unweighted RCS"
# --- VBG dataset ---
subset_data_vbg <- subset_data %>%
  dplyr::select(vbg_co2, imv_proc, niv_proc, death_60d, hypercap_resp_failure) %>%
  dplyr::filter(!is.na(vbg_co2) & complete.cases(.))

dd_vbg <- datadist(subset_data_vbg)   # create datadist for VBG
# activate when doing VBG models:
options(datadist = "dd_vbg")
```

```{r rcs-vbg-unweighted-models}
#| code-block-title: "Unweighted VBG restricted cubic spline models"
subset_data_vbg <- subset_data %>%
  select(vbg_co2, imv_proc, niv_proc, death_60d, hypercap_resp_failure) %>%
  filter(!is.na(vbg_co2) & complete.cases(.))

dd <- datadist(subset_data_vbg)
options(datadist = "dd")

fit_imv_vbg <- lrm(imv_proc ~ rcs(vbg_co2, 4), data = subset_data_vbg)
fit_niv_vbg <- lrm(niv_proc ~ rcs(vbg_co2, 4), data = subset_data_vbg)
fit_death_vbg <- lrm(death_60d ~ rcs(vbg_co2, 4), data = subset_data_vbg)
fit_hcrf_vbg <- lrm(hypercap_resp_failure ~ rcs(vbg_co2, 4), data = subset_data_vbg)

pred_imv_vbg <- as.data.frame(Predict(fit_imv_vbg, vbg_co2, fun = plogis))
pred_niv_vbg <- as.data.frame(Predict(fit_niv_vbg, vbg_co2, fun = plogis))
pred_death_vbg <- as.data.frame(Predict(fit_death_vbg, vbg_co2, fun = plogis))
pred_hcrf_vbg <- as.data.frame(Predict(fit_hcrf_vbg, vbg_co2, fun = plogis))

plot_imv_vbg <- ggplot(pred_imv_vbg, aes(x = vbg_co2, y = yhat)) +
  geom_line(color = "blue") +
  geom_ribbon(aes(ymin = lower, ymax = upper), fill = "blue", alpha = 0.2) +
  labs(title = "IMV", x = "VBG CO₂ (mmHg)", y = "Predicted Probability") +
  theme_minimal()

plot_niv_vbg <- ggplot(pred_niv_vbg, aes(x = vbg_co2, y = yhat)) +
  geom_line(color = "green") +
  geom_ribbon(aes(ymin = lower, ymax = upper), fill = "green", alpha = 0.2) +
  labs(title = "NIV", x = "VBG CO₂ (mmHg)", y = "Predicted Probability") +
  theme_minimal()

plot_death_vbg <- ggplot(pred_death_vbg, aes(x = vbg_co2, y = yhat)) +
  geom_line(color = "red") +
  geom_ribbon(aes(ymin = lower, ymax = upper), fill = "red", alpha = 0.2) +
  labs(title = "Death", x = "VBG CO₂ (mmHg)", y = "Predicted Probability") +
  theme_minimal()

plot_hcrf_vbg <- ggplot(pred_hcrf_vbg, aes(x = vbg_co2, y = yhat)) +
  geom_line(color = "purple") +
  geom_ribbon(aes(ymin = lower, ymax = upper), fill = "purple", alpha = 0.2) +
  labs(title = "Hypercapnic RF", x = "VBG CO₂ (mmHg)", y = "Predicted Probability") +
  theme_minimal()

((plot_imv_vbg | plot_niv_vbg) /
 (plot_death_vbg | plot_hcrf_vbg)) +
 plot_annotation(title = "Predicted Probability by VBG CO₂ (RCS Models)")

```

Unweighted, Restricted Cubic Spline Logistic Regressio - Calculated VBG to ABG (Farkas VBG Adjustment)

```{r rcs-calc-abg-unweighted-models}
#| code-block-title: "Unweighted calculated ABG restricted cubic spline models"
subset_data_calc <- subset_data %>%
  select(calc_abg, imv_proc, niv_proc, death_60d, hypercap_resp_failure) %>%
  filter(!is.na(calc_abg) & complete.cases(.))

dd <- datadist(subset_data_calc)
options(datadist = "dd")

fit_imv_abg   <- lrm(imv_proc ~ rcs(calc_abg, 4), data = subset_data_calc)
fit_niv_abg   <- lrm(niv_proc ~ rcs(calc_abg, 4), data = subset_data_calc)
fit_death_abg  <- lrm(death_60d ~ rcs(calc_abg, 4), data = subset_data_calc)
fit_hcrf_abg   <- lrm(hypercap_resp_failure ~ rcs(calc_abg, 4), data = subset_data_calc)

pred_imv_abg   <- as.data.frame(Predict(fit_imv_abg, calc_abg, fun = plogis))
pred_niv_abg   <- as.data.frame(Predict(fit_niv_abg, calc_abg, fun = plogis))
pred_death_abg <- as.data.frame(Predict(fit_death_abg, calc_abg, fun = plogis))
pred_hcrf_abg  <- as.data.frame(Predict(fit_hcrf_abg, calc_abg, fun = plogis))

plot_imv_abg <- ggplot(pred_imv_abg, aes(x = calc_abg, y = yhat)) +
  geom_line(color = "blue") +
  geom_ribbon(aes(ymin = lower, ymax = upper), fill = "blue", alpha = 0.2) +
  labs(title = "IMV", x = "Calculated ABG CO₂ (mmHg)", y = "Predicted Probability") +
  theme_minimal()

plot_niv_abg <- ggplot(pred_niv_abg, aes(x = calc_abg, y = yhat)) +
  geom_line(color = "green") +
  geom_ribbon(aes(ymin = lower, ymax = upper), fill = "green", alpha = 0.2) +
  labs(title = "NIV", x = "Calculated ABG CO₂ (mmHg)", y = "Predicted Probability") +
  theme_minimal()

plot_death_abg <- ggplot(pred_death_abg, aes(x = calc_abg, y = yhat)) +
  geom_line(color = "red") +
  geom_ribbon(aes(ymin = lower, ymax = upper), fill = "red", alpha = 0.2) +
  labs(title = "Death", x = "Calculated ABG CO₂ (mmHg)", y = "Predicted Probability") +
  theme_minimal()

plot_hcrf_abg <- ggplot(pred_hcrf_abg, aes(x = calc_abg, y = yhat)) +
  geom_line(color = "purple") +
  geom_ribbon(aes(ymin = lower, ymax = upper), fill = "purple", alpha = 0.2) +
  labs(title = "Hypercapnic RF", x = "Calculated ABG CO₂ (mmHg)", y = "Predicted Probability") +
  theme_minimal()

((plot_imv_abg | plot_niv_abg) /
 (plot_death_abg | plot_hcrf_abg)) +
plot_annotation(title = "Predicted Probability by Calculated ABG CO₂ (RCS Models)")
```

## Inverse Propensity Weighting

IPW done using Gradient Boosting Methods (GBM) - a type of decision-tree based machine learning. "***Random forests and GBM are designed to automatically include relevant interactions for variables included in the model.*** As such, using a GBM to estimate the PS model, can reduce model misspecification, since ***the analyst is not required to identify relevant interactions or nonlinearities."*** from this citation: PMID: [39947224](https://pubmed.ncbi.nlm.nih.gov/39947224/)<https://pmc.ncbi.nlm.nih.gov/articles/PMC11825193/>

Current propensity score uses **age_at_encounter + sex + race_ethnicity** (remember - have to specify to use this as a factor variable) **+ curr_bmi + copd + asthma + osa + chf + acute_nmd + phtn + location (as a factor variable)**

Note: for all these, I suggested new GBM adjustments that accomplish the following:

1.  Smaller GBM & stopping rule → faster fit, avoids over‑fitting, lighter tails (which lead to extreme weights that are problematic).

2.  bal.tab() documents balance; aim is to adjust spec until standard mean difference (SMD) \< 0.1.

3.  Weight stabilization (divide by mean) mitigates a few huge weights. I also winsorized, which is a way to avoid very extreme weights (ie you set \<1st percentile to the 1st percentile value, and \>99th percentile to 99th percentile.

4.  Uses robust variance estimation (e.g. allows the variances to change by PaCO2) for IP‑weighted GLM; works with splines via rcs(). This is a bit nuanced but I think good to change even though it adds complexity

5.  Deterministic seed ensures result replication.

### ABG IPW weighting and diagnostics

```{r encode-encounter-type}
#| code-block-title: "Encode encounter type factor"
subset_data$encounter_type <- factor(subset_data$encounter_type,
                                     levels = c(2, 3),
                                     labels = c("Emergency", "Inpatient"))
```

\*\*Removed lactate from weights, decreased n.trees, increased bagging

```{r ipw-abg-weighting}
#| code-block-title: "ABG GBM propensity and weighting"
# ── 1. fit GBM propensity model, ABG ───────────────────────────────────────────────
set.seed(42)

weight_model <- weightit(
  has_abg ~ age_at_encounter + sex + factor(race_ethnicity) + curr_bmi + copd + asthma + osa + chf + acute_nmd + phtn + ckd + dm + factor(location) + factor (encounter_type) + temp_new + sbp + dbp + hr + spo2 + sodium + serum_cr + serum_hco3 + serum_cl + serum_k + wbc + plt + bnp + serum_phos + serum_ca,
  data        = subset_data,
  method      = "gbm",
  estimand    = "ATE",
  missing    = "ind",
  include.obj = TRUE,        # ← REQUIRED for importance/SHAP
  n.trees     = 1500,        #decreased trees from 3000 to 1500
  interaction.depth = 3,
  shrinkage   = 0.01,
  bag.fraction= 0.8,   #increased bagging 0.6 to 0.8 - less overfit extremes 
  cv.folds    = 5,
  stop.method = "es.mean",
  n.cores     = parallel::detectCores()
)
w_abg <- weight_model  # Canonical alias so later code can use `w_abg`

# ── 2. Winsorise / stabilise weights (two‑sided) ─────────────────────────────
w <- weight_model$weights            # original GBM weights
w <- w / mean(w)                     # stabilise
cut <- quantile(w, c(0.01, 1), na.rm = TRUE)
w   <- pmin(pmax(w, cut[1]), cut[2]) # two‑tail Winsorisation
w <- w / mean(w)                     # re‑stabilise so E[w]=1

# overwrite inside the object and attach to data
weight_model$weights <- w
subset_data$w_abg    <- w

# ── 3. balance diagnostics (only raw vs. IPW) ────────────────────────────────
bal  <- bal.tab(weight_model, un = TRUE, m.threshold = 0.1)

love.plot(
  bal,
  stats        = "m",          # standardized mean differences only
  abs          = TRUE,
  var.order    = "unadjusted",
  sample.names = c("Raw", "IPW")
)

# ── 4. survey design with the same weights ───────────────────────────────────
design <- svydesign(ids = ~1, weights = ~w_abg, data = subset_data)

# ── 5. outcome models (examples) ─────────────────────────────────────────────
fit_niv   <- svyglm(niv_proc   ~ has_abg, design = design, family = quasibinomial())
fit_imv   <- svyglm(imv_proc   ~ has_abg, design = design, family = quasibinomial())
fit_death <- svyglm(death_60d       ~ has_abg, design = design, family = quasibinomial())
fit_icd   <- svyglm(hypercap_resp_failure ~ has_abg, design = design, family = quasibinomial())

# quick effect estimates
lapply(list(IMV = fit_imv, NIV = fit_niv, Death = fit_death, ICD = fit_icd), function(m) {
  c(OR  = exp(coef(m)[2]),
    LCL = exp(confint(m)[2,1]),
    UCL = exp(confint(m)[2,2]))
})
```

**Inverse Propensity-Weighted Logistic Regressions with CO2 predictor represented as a restricted cubic spline.**

### ABG IPW spline models

```{r ipw-abg-rcs-models}
#| code-block-title: "ABG IPW spline models"
# set.seed(42)  # reproducible GBM fit
# 
# # ── 1. inverse‑probability weights for receiving an ABG ───────────────────────
# 
# # done in the last block, so not needed
# 

# ── 2. analysis sample: rows with a measured PaCO₂ ────────────────────────────
subset_data_abg <- subset_data %>%
  filter(!is.na(paco2)) %>%                    # implies has_abg == 1
  select(paco2, imv_proc, niv_proc, death_60d,
         hypercap_resp_failure, w_abg) %>%
  filter(complete.cases(.))


# ── 3. weighted logistic spline models with robust SEs ───────────────────────
dd <- datadist(subset_data_abg); options(datadist = "dd")

fitfun <- function(formula)
  svyglm(
    formula,
    design = svydesign(ids = ~1, weights = ~w_abg, data = subset_data_abg),
    family = quasibinomial()
  )

fit_imv_abg   <- fitfun(imv_proc              ~ rcs(paco2, 4))
fit_niv_abg   <- fitfun(niv_proc              ~ rcs(paco2, 4))
fit_death_abg <- fitfun(death_60d                  ~ rcs(paco2, 4))
fit_hcrf_abg  <- fitfun(hypercap_resp_failure ~ rcs(paco2, 4))

# ── 4. prediction helper ─────────────────────────────────────────────────────
mkpred <- function(fit, data_ref) {
  # 1. Grid of PaCO₂ values
  newd <- data.frame(
    paco2 = seq(min(data_ref$paco2, na.rm = TRUE),
                max(data_ref$paco2, na.rm = TRUE),
                length.out = 200)
  )

  # 2. Design (model) matrix for the new data
  mm <- model.matrix(delete.response(terms(fit)),  # drop outcome
                     data = newd)

  # 3. Linear predictor and its standard error
  eta  <- mm %*% coef(fit)                        # β'x
  vcov <- vcov(fit)                               # robust VCOV from svyglm
  se   <- sqrt(rowSums((mm %*% vcov) * mm))       # √diag(X Σ Xᵀ)

  # 4. Transform to probability scale
  transform(
    newd,
    yhat  = plogis(eta),
    lower = plogis(eta - 1.96 * se),
    upper = plogis(eta + 1.96 * se)
  )
}

pred_imv_abg   <- mkpred(fit_imv_abg,   subset_data_abg)
pred_niv_abg   <- mkpred(fit_niv_abg,   subset_data_abg)
pred_death_abg <- mkpred(fit_death_abg, subset_data_abg)
pred_hcrf_abg  <- mkpred(fit_hcrf_abg,  subset_data_abg)

# ── 5. plotting ──────────────────────────────────────────────────────────────
xlab <- expression(paste("ABG CO"[2], " (mmHg)"))

plt <- function(dat, title)
  ggplot(dat, aes(paco2, yhat)) +
    geom_line() +
    geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.2) +
    scale_y_continuous(limits = c(0, 1), labels = percent_format(accuracy = 1)) +
    labs(title = title, x = xlab, y = "Predicted probability") +
    theme_minimal()

(patchwork::wrap_plots(
    plt(pred_imv_abg,   "IMV"),
    plt(pred_niv_abg,   "NIV"),
    plt(pred_death_abg, "Death"),
    plt(pred_hcrf_abg,  "Hypercapnic RF"),
    ncol = 2
  )
) +
  plot_annotation(
    title = expression(
      paste("Propensity‑weighted predicted probability by ABG CO"[2],
            " (restricted cubic spline)")
    )
)
```

Restricting plots bewtween 0.02 and 0.98

### ABG IPW spline models (2–98th percentile)

```{r ipw-abg-rcs-trimmed}
#| code-block-title: "ABG IPW spline models (2–98% range)"

subset_data_abg <- subset_data %>%
  filter(!is.na(paco2)) %>%                    # implies has_abg == 1
  select(paco2, imv_proc, niv_proc, death_60d,
         hypercap_resp_failure, w_abg) %>%
  filter(complete.cases(.))


# ── 3. weighted logistic spline models with robust SEs ───────────────────────
dd <- datadist(subset_data_abg); options(datadist = "dd")

fitfun <- function(formula)
  svyglm(
    formula,
    design = svydesign(ids = ~1, weights = ~w_abg, data = subset_data_abg),
    family = quasibinomial()
  )

fit_imv_abg   <- fitfun(imv_proc              ~ rcs(paco2, 4))
fit_niv_abg   <- fitfun(niv_proc              ~ rcs(paco2, 4))
fit_death_abg <- fitfun(death_60d                  ~ rcs(paco2, 4))
fit_hcrf_abg  <- fitfun(hypercap_resp_failure ~ rcs(paco2, 4))

# ── 4. prediction helper ─────────────────────────────────────────────────────
mkpred <- function(fit, data_ref) {
  # 1. Grid of PaCO₂ values restricted to 2nd–98th percentile
  q <- quantile(data_ref$paco2, probs = c(0.02, 0.98), na.rm = TRUE)
  newd <- data.frame(
    paco2 = seq(q[1], q[2], length.out = 200)
  )

  # 2. Design (model) matrix for the new data
  mm <- model.matrix(delete.response(terms(fit)), data = newd)

  # 3. Linear predictor and its standard error
  eta  <- mm %*% coef(fit)
  vcov <- vcov(fit)
  se   <- sqrt(rowSums((mm %*% vcov) * mm))

  # 4. Transform to probability scale
  transform(
    newd,
    yhat  = plogis(eta),
    lower = plogis(eta - 1.96 * se),
    upper = plogis(eta + 1.96 * se)
  )
}

pred_imv_abg   <- mkpred(fit_imv_abg,   subset_data_abg)
pred_niv_abg   <- mkpred(fit_niv_abg,   subset_data_abg)
pred_death_abg <- mkpred(fit_death_abg, subset_data_abg)
pred_hcrf_abg  <- mkpred(fit_hcrf_abg,  subset_data_abg)

# ── 5. plotting ──────────────────────────────────────────────────────────────
xlab <- expression(paste("ABG CO"[2], " (mmHg)"))

plt <- function(dat, title)
  ggplot(dat, aes(paco2, yhat)) +
    geom_line() +
    geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.2) +
    scale_y_continuous(limits = c(0, 1), labels = percent_format(accuracy = 1)) +
    labs(title = title, x = xlab, y = "Predicted probability") +
    theme_minimal()

(patchwork::wrap_plots(
    plt(pred_imv_abg,   "IMV"),
    plt(pred_niv_abg,   "NIV"),
    plt(pred_death_abg, "Death"),
    plt(pred_hcrf_abg,  "Hypercapnic RF"),
    ncol = 2
  )
) +
  plot_annotation(
    title = expression(
      paste("Propensity‑weighted predicted probability by ABG CO"[2],
            " (restricted cubic spline)")
    )
)
```

VBG - changed trees and bag fraction

### VBG IPW weighting and spline models

```{r ipw-vbg-workflow}
#| code-block-title: "VBG IPW weighting and spline models"
#  Inverse-propensity weighting & outcome modelling for **VBG** cohort
#    – mirrored 1-to-1 to the validated ABG workflow

set.seed(42)

# 1. IPW for VBG ---------------------------------------------------------------
w_vbg <- weightit(
  has_vbg ~ age_at_encounter + sex + factor(race_ethnicity) + curr_bmi +
    copd + asthma + osa + chf + acute_nmd + phtn + ckd + dm +
    factor(location) + factor(encounter_type) + temp_new + sbp + dbp + hr + spo2 + sodium + serum_cr + serum_hco3 + serum_cl +
    serum_k + wbc + plt + bnp + serum_phos + serum_ca,
  data        = subset_data,
  method      = "gbm",
  estimand    = "ATE",
  missing    = "ind",
  include.obj = TRUE,        # ← REQUIRED for importance/SHAP
  n.trees     = 1500,
  interaction.depth = 3,
  shrinkage   = 0.01,
  bag.fraction= 0.8,
  cv.folds    = 5,
  stop.method = "es.mean",
  n.cores     = parallel::detectCores()
)

# Stabilise & winsorise weights
w <- w_vbg$weights
w <- w / mean(w)
cut <- quantile(w, c(0.01, 1), na.rm = TRUE)
w   <- pmin(pmax(w, cut[1]), cut[2])
w <- w / mean(w)

w_vbg$weights   <- w
subset_data$w_vbg <- w

v_bal <- bal.tab(w_vbg, un = TRUE, m.threshold = 0.1)

love.plot(
  v_bal,
  stats        = "m",          # standardized mean differences only
  abs          = TRUE,
  var.order    = "unadjusted",
  sample.names = c("Raw", "IPW")
)

# 2. Analysis set (VBG only) ---------------------------------------------------
subset_data_vbg <- subset_data %>%
  filter(!is.na(vbg_co2)) %>%
  select(vbg_co2, imv_proc, niv_proc, death_60d, 
         hypercap_resp_failure, w_vbg) %>%
  filter(complete.cases(.))

# 3. Weighted spline models ----------------------------------------------------
dd_vbg <- datadist(subset_data_vbg)
options(datadist = "dd_vbg")

fitfun <- function(formula)
  svyglm(
    formula,
    design = svydesign(ids = ~1, weights = ~w_vbg, data = subset_data_vbg),
    family = quasibinomial()
  )

fit_imv_vbg   <- fitfun(imv_proc              ~ rcs(vbg_co2, 4))
fit_niv_vbg   <- fitfun(niv_proc              ~ rcs(vbg_co2, 4))
fit_death_vbg <- fitfun(death_60d             ~ rcs(vbg_co2, 4))
fit_hcrf_vbg  <- fitfun(hypercap_resp_failure ~ rcs(vbg_co2, 4))

# 4. Prediction helper ---------------------------------------------------------
mkpred <- function(fit, data_ref) {
  newd <- data.frame(
    vbg_co2 = seq(min(data_ref$vbg_co2, na.rm = TRUE),
                  max(data_ref$vbg_co2, na.rm = TRUE),
                  length.out = 200)
  )
  mm   <- model.matrix(delete.response(terms(fit)), newd)
  eta  <- mm %*% coef(fit)
  vcov <- vcov(fit)
  se   <- sqrt(rowSums((mm %*% vcov) * mm))
  transform(
    newd,
    yhat  = plogis(eta),
    lower = plogis(eta - 1.96 * se),
    upper = plogis(eta + 1.96 * se)
  )
}

pred_imv_vbg   <- mkpred(fit_imv_vbg,   subset_data_vbg)
pred_niv_vbg   <- mkpred(fit_niv_vbg,   subset_data_vbg)
pred_death_vbg <- mkpred(fit_death_vbg, subset_data_vbg)
pred_hcrf_vbg  <- mkpred(fit_hcrf_vbg,  subset_data_vbg)

# 5. Plotting (gray scheme) ----------------------------------------------------
xlab <- expression(paste("VBG CO"[2], " (mmHg)"))

plt <- function(dat, title)
  ggplot(dat, aes(vbg_co2, yhat)) +
    geom_line() +
    geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.2) +
    scale_y_continuous(limits = c(0, 1), labels = percent_format(accuracy = 1)) +
    labs(title = title, x = xlab, y = "Predicted probability") +
    theme_minimal()

(patchwork::wrap_plots(
    plt(pred_imv_vbg,   "IMV"),
    plt(pred_niv_vbg,   "NIV"),
    plt(pred_death_vbg, "Death"),
    plt(pred_hcrf_vbg,  "Hypercapnic RF"),
    ncol = 2
  )
) +
  plot_annotation(
    title = expression(
      paste("Propensity‑weighted predicted probability by VBG CO"[2],
            " (restricted cubic spline)")
    )
)

```

Calculated VBG to ABG / Farkas

### Calculated ABG IPW weighting and spline models

```{r ipw-calc-abg-workflow}
#| code-block-title: "Calculated ABG IPW weighting and spline models"
#  Propensity‑weighted spline models for **Calculated ABG CO₂**
#    (weights still derive from propensity to receive a VBG)

# ── 1. define the new treatment variable --------------------------------------
subset_data <- subset_data %>%
  mutate(
    has_vbg_co2_o2_sat = if_else(
      !is.na(vbg_co2)  & vbg_co2  != 0 &
      !is.na(vbg_o2sat) & vbg_o2sat != 0,
      1, 0
    )
  )

# quick sanity check
# table(subset_data$has_vbg_co2_o2_sat, useNA = "ifany")

# ── 2. fit the GBM propensity model -------------------------------------------
set.seed(42)

w_vbg_calc <- weightit(
  has_vbg_co2_o2_sat ~ age_at_encounter + sex + factor(race_ethnicity) + curr_bmi + copd + asthma + osa + chf + acute_nmd + phtn + ckd + dm + factor(location) + factor(encounter_type) + temp_new + sbp + dbp + hr + spo2 + sodium + serum_cr + serum_hco3 + serum_cl + serum_lac + serum_k + wbc + plt + bnp + serum_phos + serum_ca,
  data        = subset_data,
  method      = "gbm",
  estimand    = "ATE",
  missing    = "ind",
  include.obj = TRUE,
  n.trees     = 3000,
  interaction.depth = 3,
  shrinkage   = 0.01,
  bag.fraction= 0.6,
  cv.folds    = 5,
  stop.method = "es.mean",
  n.cores     = parallel::detectCores()
)

# ── 3. (optional) stabilise + two‑sided Winsorisation --------------------------
w <- w_vbg_calc$weights
w <- w / mean(w)

cut <- quantile(w, c(0.01, 1), na.rm = TRUE)
w   <- pmin(pmax(w, cut[1]), cut[2])
w   <- w / mean(w)

subset_data$w_vbg_calc <- w          # attach to data frame
w_vbg_calc$weights     <- w          # overwrite inside object for diagnostics

v_calc_bal <- bal.tab(w_vbg_calc, un = TRUE, m.threshold = 0.1)   # inspect balance

love.plot(
  v_calc_bal,
  stats        = "m",          # standardized mean differences only
  abs          = TRUE,
  var.order    = "unadjusted",
  sample.names = c("Raw", "IPW")
)

# 2. Analysis sample: rows with a calculated ABG CO₂ ---------------------------
subset_data_calc <- subset_data %>%
  filter(!is.na(calc_abg)) %>%                       # implies has_vbg == 1
  select(calc_abg, imv_proc, niv_proc, death_60d,
         hypercap_resp_failure, w_vbg_calc) %>%
  filter(complete.cases(.)) 

# 3. Weighted logistic spline models with robust SEs ---------------------------
dd <- datadist(subset_data_calc); options(datadist = "dd")

fitfun <- function(formula)
  svyglm(
    formula,
    design = svydesign(ids = ~1, weights = ~w_vbg_calc, data = subset_data_calc),
    family = quasibinomial()
  )

fit_imv_calc   <- fitfun(imv_proc              ~ rcs(calc_abg, 4))
fit_niv_calc   <- fitfun(niv_proc              ~ rcs(calc_abg, 4))
fit_death_calc <- fitfun(death_60d                  ~ rcs(calc_abg, 4))
fit_hcrf_calc  <- fitfun(hypercap_resp_failure ~ rcs(calc_abg, 4))

# 4. Prediction helper ---------------------------------------------------------
mkpred <- function(fit, data_ref) {
  newd <- data.frame(
    calc_abg = seq(min(data_ref$calc_abg, na.rm = TRUE),
                   max(data_ref$calc_abg, na.rm = TRUE),
                   length.out = 200)
  )
  mm   <- model.matrix(delete.response(terms(fit)), newd)
  eta  <- mm %*% coef(fit)
  vcov <- vcov(fit)
  se   <- sqrt(rowSums((mm %*% vcov) * mm))
  transform(
    newd,
    yhat  = plogis(eta),
    lower = plogis(eta - 1.96 * se),
    upper = plogis(eta + 1.96 * se)
  )
}

pred_imv_calc   <- mkpred(fit_imv_calc,   subset_data_calc)
pred_niv_calc   <- mkpred(fit_niv_calc,   subset_data_calc)
pred_death_calc <- mkpred(fit_death_calc, subset_data_calc)
pred_hcrf_calc  <- mkpred(fit_hcrf_calc,  subset_data_calc)

# 5. Plotting -------------------------------------------------------------------
xlab <- expression(paste("Calculated ABG CO"[2], " (mmHg)"))

plt <- function(dat, title)
  ggplot(dat, aes(calc_abg, yhat)) +
    geom_line() +
    geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.2) +
    scale_y_continuous(limits = c(0, 1), labels = percent_format(accuracy = 1))  +
    labs(title = title, x = xlab, y = "Predicted probability") +
    theme_minimal()

(patchwork::wrap_plots(
    plt(pred_imv_calc,   "IMV"),
    plt(pred_niv_calc,   "NIV"),
    plt(pred_death_calc, "Death"),
    plt(pred_hcrf_calc,  "Hypercapnic RF"),
    ncol = 2
  )
) +
  plot_annotation(
    title = expression(
      paste("Propensity‑weighted predicted probability by Calculated ABG CO"[2],
            " (restricted cubic spline)")
    )
)
```

Superimposing ABG and VBG weighted restricted cubic splines

### Overlay: ABG vs VBG IPW spline predictions

```{r rcs-overlay-abg-vbg}
#| code-block-title: "Overlay ABG vs VBG IPW spline predictions"
library(dplyr)
library(ggplot2)
library(patchwork)
library(scales)
library(rms)

# ABG spline fits (unweighted, rms::lrm)
fit_imv_abg   <- lrm(imv_proc              ~ rcs(paco2, 4), data = subset_data_abg)
fit_niv_abg   <- lrm(niv_proc              ~ rcs(paco2, 4), data = subset_data_abg)
fit_death_abg <- lrm(death_60d             ~ rcs(paco2, 4), data = subset_data_abg)
fit_hcrf_abg  <- lrm(hypercap_resp_failure ~ rcs(paco2, 4), data = subset_data_abg)

# VBG spline fits (mirror pattern)
fit_imv_vbg   <- lrm(imv_proc              ~ rcs(vbg_co2, 4), data = subset_data_vbg)
fit_niv_vbg   <- lrm(niv_proc              ~ rcs(vbg_co2, 4), data = subset_data_vbg)
fit_death_vbg <- lrm(death_60d             ~ rcs(vbg_co2, 4), data = subset_data_vbg)
fit_hcrf_vbg  <- lrm(hypercap_resp_failure ~ rcs(vbg_co2, 4), data = subset_data_vbg)

library(rms)  # ensure lrm() and Predict() are available

# Helper to make predictions with standardized columns: co2, yhat, lower, upper, group
mkpred <- function(fit, data_ref, xvar, group_label, n = 200) {
  stopifnot(is.character(xvar), length(xvar) == 1, xvar %in% names(data_ref))
  xseq <- seq(min(data_ref[[xvar]], na.rm = TRUE),
              max(data_ref[[xvar]], na.rm = TRUE),
              length.out = n)

  if (inherits(fit, "lrm")) {
    # Predict() needs a datadist object visible by name set in options(datadist=)
    dd <- rms::datadist(data_ref)
    old <- options(datadist = "dd")
    on.exit(options(old), add = TRUE)
    assign("dd", dd, envir = .GlobalEnv)

    # IMPORTANT: name the model argument 'object', not 'fit'
    args <- c(list(object = fit, fun = plogis),
              stats::setNames(list(xseq), xvar))
    p <- do.call(rms::Predict, args)
    out <- as.data.frame(p)
    # standardize column names used by plotting code
    names(out)[names(out) == xvar] <- "co2"
    out$group <- group_label
    out[, c("co2", "yhat", "lower", "upper", "group")]
  } else {
    # glm/svyglm path
    newd <- stats::setNames(data.frame(xseq), xvar)
    X    <- stats::model.matrix(stats::delete.response(stats::terms(fit)), newd)
    beta <- stats::coef(fit)
    eta  <- drop(X %*% beta)
    V    <- stats::vcov(fit)
    se   <- sqrt(rowSums((X %*% V) * X))
    data.frame(
      co2    = xseq,
      yhat   = plogis(eta),
      lower  = plogis(eta - 1.96 * se),
      upper  = plogis(eta + 1.96 * se),
      group  = group_label,
      check.names = FALSE
    )
  }
}

# ── Generate predictions ───────────────────────────────────────────────
# VBG
pred_imv_vbg   <- mkpred(fit_imv_vbg,   subset_data_vbg, "vbg_co2", "VBG")
pred_niv_vbg   <- mkpred(fit_niv_vbg,   subset_data_vbg, "vbg_co2", "VBG")
pred_death_vbg <- mkpred(fit_death_vbg, subset_data_vbg, "vbg_co2", "VBG")
pred_hcrf_vbg  <- mkpred(fit_hcrf_vbg,  subset_data_vbg, "vbg_co2", "VBG")

# ABG
pred_imv_abg   <- mkpred(fit_imv_abg,   subset_data_abg, "paco2", "ABG")
pred_niv_abg   <- mkpred(fit_niv_abg,   subset_data_abg, "paco2", "ABG")
pred_death_abg <- mkpred(fit_death_abg, subset_data_abg, "paco2", "ABG")
pred_hcrf_abg  <- mkpred(fit_hcrf_abg,  subset_data_abg, "paco2", "ABG")

# Combine
pred_imv   <- bind_rows(pred_imv_vbg,   pred_imv_abg)
pred_niv   <- bind_rows(pred_niv_vbg,   pred_niv_abg)
pred_death <- bind_rows(pred_death_vbg, pred_death_abg)
pred_hcrf  <- bind_rows(pred_hcrf_vbg,  pred_hcrf_abg)

# ── Plotting function in grayscale with distinguishable ribbons ─────────────
plt_gray <- function(dat, title) {
  ggplot(dat, aes(x = co2, y = yhat, linetype = group)) +
    geom_line(color = "black", linewidth = 1) +
    geom_ribbon(aes(ymin = lower, ymax = upper, fill = group),
                alpha = 0.3, color = NA) +
    scale_fill_manual(values = c("ABG" = "gray90", "VBG" = "gray20")) +  # different gray shades
    scale_linetype_manual(values = c("ABG" = "solid", "VBG" = "dashed")) +
    scale_y_continuous(limits = c(0, 1),
                       labels = scales::percent_format(accuracy = 1)) +
    labs(title = title,
         x = expression(CO[2]~"(mmHg)"),
         y = "Predicted probability",
         fill = "Group",
         linetype = "Group") +
    theme_minimal() +
    theme(legend.position = "bottom")
}

# ── Patchwork layout with gray shades ──────────────────────────────────────
(patchwork::wrap_plots(
    plt_gray(pred_imv,   "IMV"),
    plt_gray(pred_niv,   "NIV"),
    plt_gray(pred_death, "Death"),
    plt_gray(pred_hcrf,  "Hypercapnic RF"),
    ncol = 2
  )
) +
  plot_annotation(
    title = expression(
      paste("Propensity-weighted predicted probability by ABG vs VBG CO"[2],
            " (restricted cubic splines, gray scheme)")
    )
  )
```

Restricting the plot to 0.02 to 0.99 (since this puts it at about 100mmHg for CO2)

### Overlay: ABG vs VBG IPW spline predictions (2–98th percentile)

```{r rcs-overlay-abg-vbg-trimmed}
#| code-block-title: "Overlay ABG vs VBG IPW spline predictions (2–98% range)"
library(dplyr)
library(ggplot2)
library(patchwork)
library(scales)
library(rms)

# ABG spline fits (unweighted, rms::lrm)
fit_imv_abg   <- lrm(imv_proc              ~ rcs(paco2, 4), data = subset_data_abg)
fit_niv_abg   <- lrm(niv_proc              ~ rcs(paco2, 4), data = subset_data_abg)
fit_death_abg <- lrm(death_60d             ~ rcs(paco2, 4), data = subset_data_abg)
fit_hcrf_abg  <- lrm(hypercap_resp_failure ~ rcs(paco2, 4), data = subset_data_abg)

# VBG spline fits (mirror pattern)
fit_imv_vbg   <- lrm(imv_proc              ~ rcs(vbg_co2, 4), data = subset_data_vbg)
fit_niv_vbg   <- lrm(niv_proc              ~ rcs(vbg_co2, 4), data = subset_data_vbg)
fit_death_vbg <- lrm(death_60d             ~ rcs(vbg_co2, 4), data = subset_data_vbg)
fit_hcrf_vbg  <- lrm(hypercap_resp_failure ~ rcs(vbg_co2, 4), data = subset_data_vbg)

library(rms)  # ensure lrm() and Predict() are available

# Helper to make predictions with standardized columns: co2, yhat, lower, upper, group
mkpred <- function(fit, data_ref, xvar, group_label, n = 200) {
  stopifnot(is.character(xvar), length(xvar) == 1, xvar %in% names(data_ref))
  
  # Restrict to 2nd and 98th percentiles
  rng <- quantile(data_ref[[xvar]], probs = c(0.02, 0.98), na.rm = TRUE)
  xseq <- seq(rng[1], rng[2], length.out = n)
  
  if (inherits(fit, "lrm")) {
    dd <- rms::datadist(data_ref)
    old <- options(datadist = "dd")
    on.exit(options(old), add = TRUE)
    assign("dd", dd, envir = .GlobalEnv)

    args <- c(list(object = fit, fun = plogis),
              stats::setNames(list(xseq), xvar))
    p <- do.call(rms::Predict, args)
    out <- as.data.frame(p)
    names(out)[names(out) == xvar] <- "co2"
    out$group <- group_label
    out[, c("co2", "yhat", "lower", "upper", "group")]
  } else {
    newd <- stats::setNames(data.frame(xseq), xvar)
    X    <- stats::model.matrix(stats::delete.response(stats::terms(fit)), newd)
    beta <- stats::coef(fit)
    eta  <- drop(X %*% beta)
    V    <- stats::vcov(fit)
    se   <- sqrt(rowSums((X %*% V) * X))
    data.frame(
      co2    = xseq,
      yhat   = plogis(eta),
      lower  = plogis(eta - 1.96 * se),
      upper  = plogis(eta + 1.96 * se),
      group  = group_label,
      check.names = FALSE
    )
  }
}

# ── Generate predictions ───────────────────────────────────────────────
# VBG
pred_imv_vbg   <- mkpred(fit_imv_vbg,   subset_data_vbg, "vbg_co2", "VBG")
pred_niv_vbg   <- mkpred(fit_niv_vbg,   subset_data_vbg, "vbg_co2", "VBG")
pred_death_vbg <- mkpred(fit_death_vbg, subset_data_vbg, "vbg_co2", "VBG")
pred_hcrf_vbg  <- mkpred(fit_hcrf_vbg,  subset_data_vbg, "vbg_co2", "VBG")

# ABG
pred_imv_abg   <- mkpred(fit_imv_abg,   subset_data_abg, "paco2", "ABG")
pred_niv_abg   <- mkpred(fit_niv_abg,   subset_data_abg, "paco2", "ABG")
pred_death_abg <- mkpred(fit_death_abg, subset_data_abg, "paco2", "ABG")
pred_hcrf_abg  <- mkpred(fit_hcrf_abg,  subset_data_abg, "paco2", "ABG")

# Combine
pred_imv   <- bind_rows(pred_imv_vbg,   pred_imv_abg)
pred_niv   <- bind_rows(pred_niv_vbg,   pred_niv_abg)
pred_death <- bind_rows(pred_death_vbg, pred_death_abg)
pred_hcrf  <- bind_rows(pred_hcrf_vbg,  pred_hcrf_abg)

# ── Plotting function in grayscale with distinguishable ribbons ─────────────
plt_gray <- function(dat, title) {
  ggplot(dat, aes(x = co2, y = yhat, linetype = group)) +
    geom_line(color = "black", linewidth = 1) +
    geom_ribbon(aes(ymin = lower, ymax = upper, fill = group),
                alpha = 0.3, color = NA) +
    scale_fill_manual(values = c("ABG" = "gray90", "VBG" = "gray20")) +  # different gray shades
    scale_linetype_manual(values = c("ABG" = "solid", "VBG" = "dashed")) +
    scale_y_continuous(limits = c(0, 1),
                       labels = scales::percent_format(accuracy = 1)) +
    labs(title = title,
         x = expression(CO[2]~"(mmHg)"),
         y = "Predicted probability",
         fill = "Group",
         linetype = "Group") +
    theme_minimal() +
    theme(legend.position = "bottom")
}

# ── Patchwork layout with gray shades ──────────────────────────────────────
(patchwork::wrap_plots(
    plt_gray(pred_imv,   "IMV"),
    plt_gray(pred_niv,   "NIV"),
    plt_gray(pred_death, "Death"),
    plt_gray(pred_hcrf,  "Hypercapnic RF"),
    ncol = 2
  )
) +
  plot_annotation(
    title = expression(
      paste("Propensity-weighted predicted probability by ABG vs VBG CO"[2],
            " (restricted cubic splines, gray scheme)")
    )
  )
```

## Explainability (propensity models)

Feature importance: *global* contribution of a feature to the model's predictive performance on the training distribution. Quick global triage---*which variables the model leaned on to fit propensity*. Good for model debugging, feature pruning, and tracking drift across refits (qualitatively).

SHAP: a *local*, signed attribution for that subject: "by how much did feature j push this person's log‑odds of receiving the test up or down vs baseline?, then global shap is mean absolute SHAP across subjects---i.e., the **typical magnitude** of a feature's contribution to predictions in your population. Good for auditability and **directional insight**---*who is assigned higher/lower propensity by which features*, spot proxies, and communicate fairness/operational drivers. Aggregate with mean \|SHAP\| for a **global ranking with direction available** when needed.

TODO: **Can label y-axis in plots: contribution to the log odds of receiving an ABG or VBG for the SHAP values.**

### ABG explainability

For the top SHAP‑ranked predictors we computed partial‑ and accumulated‑local‑effects (ALE) to estimate the marginal change in predicted risk across clinically relevant ranges, robust to covariate correlation. We complemented this with SHAP dependence plots (colored by plausible interactions) and fitted transparent spline‑logistic models to identify turn‑points ('knees') where marginal log‑odds slope changed.

```{r explainability_abg_fast_only}
#| code-block-title: "ABG propensity explainability setup"
#| label: explainability_abg_fast_only
#| message: false
#| warning: false

# --- deps ----------------------------------------------------------------------
library(WeightIt)
library(gbm)
library(dplyr)
library(ggplot2)
library(fastshap)

# --- 0) Canonicalize object name ----------------------------------------------
# Your 9-26.qmd labeled the ABG propensity object `weight_model`.
if (!exists("w_abg", inherits = TRUE) && exists("weight_model", inherits = TRUE)) {
  w_abg <- weight_model
}
stopifnot(exists("w_abg", inherits = TRUE))

# --- 1) Ensure the WeightIt object stores the GBM + covariate matrix -----------
ensure_gbm_obj <- function(W) {
  stopifnot(inherits(W, "weightit"))
  has_obj <- !is.null(W$obj) || !is.null(W$info$obj) || !is.null(W$info$model.obj)
  has_cov <- !is.null(W$covs)
  if (has_obj && has_cov) return(W)

  cl <- as.list(W$call); cl[[1]] <- WeightIt::weightit
  if (!is.null(cl[["missing."]])) { cl$missing <- cl[["missing."]]; cl[["missing."]] <- NULL }
  if (is.null(cl$missing))        cl$missing <- "ind"
  cl$include.obj <- TRUE
  if (is.null(cl$method))         cl$method <- "gbm"
  if (is.language(cl$formula)) cl$formula <- eval(cl$formula, envir = .GlobalEnv)
  if (is.language(cl$data))    cl$data    <- eval(cl$data,    envir = .GlobalEnv)
  do.call(WeightIt::weightit, cl[-1])
}
w_abg <- ensure_gbm_obj(w_abg)

# --- 2) Helpers: design alignment, importance, fast SHAP (logit scale) ---------
prep_design <- function(W) {
  stopifnot(inherits(W, "weightit"))
  gbm_fit <- if (!is.null(W$obj)) W$obj else if (!is.null(W$info$obj)) W$info$obj else W$info$model.obj
  stopifnot(inherits(gbm_fit, "gbm"))
  stopifnot(!is.null(W$covs))

  X <- W$covs
  if (inherits(X, "tbl"))    X <- as.data.frame(X)
  if (inherits(X, "Matrix")) X <- as.matrix(X)
  X <- as.data.frame(X, stringsAsFactors = FALSE)

  # conservative coercion: only numeric-like strings → numeric
  for (nm in names(X)) {
    if (is.factor(X[[nm]])) X[[nm]] <- as.character(X[[nm]])
    if (is.character(X[[nm]])) {
      ok <- grepl("^[-+]?[0-9.]+$", X[[nm]] %||% "")
      if (all(ok | is.na(X[[nm]]))) suppressWarnings(X[[nm]] <- as.numeric(X[[nm]]))
    }
  }

  vars <- gbm_fit$var.names
  miss <- setdiff(vars, colnames(X))
  if (length(miss)) for (nm in miss) X[[nm]] <- 0
  X <- X[, vars, drop = FALSE]

  best_tree <- if (!is.null(W$info$best.tree)) W$info$best.tree else gbm_fit$n.trees
  list(X = X, gbm_fit = gbm_fit, best_tree = best_tree)
}

extract_gbm_importance <- function(W, top_n = 25) {
  mats <- prep_design(W)
  as.data.frame(summary(mats$gbm_fit, n.trees = mats$best_tree, plotit = FALSE)) |>
    arrange(desc(rel.inf)) |>
    slice_head(n = top_n)
}

plot_gbm_importance <- function(imp_df, title = "GBM variable importance (relative influence)") {
  ggplot(imp_df, aes(x = rel.inf, y = reorder(var, rel.inf))) +
    geom_col(width = 0.85) +
    labs(x = "Relative influence (sum = 100)", y = NULL, title = title) +
    theme_minimal(base_size = 11)
}

# --- 3) Run: ABG selection model — importance + fast SHAP ----------------------
imp_abg   <- extract_gbm_importance(w_abg, top_n = 25)
p_imp_abg <- plot_gbm_importance(imp_abg, "ABG selection model — GBM relative influence")
p_imp_abg
```

```{r abg-shap-compute}
#| code-block-title: "ABG propensity SHAP computation and importance"
# --- Build shapviz object robustly -------------------------------------------
library(shapviz)

# Align newdata's factor levels to the GBM's training levels
align_levels_to_gbm <- function(newdata, gbm_fit) {
  out <- as.data.frame(newdata, stringsAsFactors = FALSE)
  if (!is.null(gbm_fit$var.levels)) {
    for (nm in intersect(names(gbm_fit$var.levels), names(out))) {
      lev <- unique(as.character(gbm_fit$var.levels[[nm]]))
      out[[nm]] <- factor(as.character(out[[nm]]), levels = lev)
    }
  }
  out
}

# fast SHAP on LOGIT scale; prunes zero‑variance features; subsamples rows
compute_shap_fast <- function(W, top_k = 30, nsim = 64, frac_rows = 0.50,
                              max_rows = 100000, seed = 123) {
  mats <- prep_design(W); X <- mats$X; gbm_fit <- mats$gbm_fit; best_tree <- mats$best_tree

  imp <- as.data.frame(summary(gbm_fit, n.trees = best_tree, plotit = FALSE))
  top_feats <- head(imp$var, min(top_k, nrow(imp)))
  top_feats <- intersect(top_feats, colnames(X))

  # drop constant features (avoid flat SHAP/plots)
  nzv <- sapply(X[, top_feats, drop = FALSE], function(z) sd(z, na.rm = TRUE) > 0)
  top_feats <- top_feats[nzv]
  if (!length(top_feats)) stop("All candidate features are near-constant in this subset.")

  n <- nrow(X); target_n <- min(n, max_rows, ceiling(frac_rows * n))
  set.seed(seed)
  Xsub <- if (target_n < n) X[sample.int(n, target_n), , drop = FALSE] else X

  # SHAP on logit scale for contrast/stability
  pfun <- function(object, newdata) {
    newd <- align_levels_to_gbm(newdata, object)
    predict(object, newdata = newd, n.trees = best_tree, type = "link")
  }

  fs_formals <- names(formals(fastshap::explain))
  args <- list(object = gbm_fit, X = Xsub, pred_wrapper = pfun, nsim = nsim, adjust = TRUE)
  if ("feature_names" %in% fs_formals) args$feature_names <- top_feats

  set.seed(seed)
  S <- do.call(fastshap::explain, args)  # matrix or data.frame of SHAP

  list(shap = S, X = Xsub, top_feats = top_feats, imp = imp)
}

t0 <- Sys.time()
sh_abg_fast <- compute_shap_fast(w_abg, top_k = 100, nsim = 32, frac_rows = 0.25, max_rows = 100000)
t1 <- Sys.time(); message(sprintf("[compute_shap_fast] %.2f s", as.numeric(difftime(t1, t0, units="secs"))))

# 1) Take SHAP and design from your fast SHAP object
S <- as.matrix(sh_abg_fast$shap)   # n x p SHAP matrix
X <- as.data.frame(sh_abg_fast$X)  # matching rows, p columns

# 2) Make X numeric-only (handles factors / labelled types safely)
for (nm in names(X)) {
  if (inherits(X[[nm]], "haven_labelled")) {
    X[[nm]] <- labelled::to_factor(X[[nm]])
  }
  if (is.factor(X[[nm]]))   X[[nm]] <- as.character(X[[nm]])
  if (is.character(X[[nm]])) suppressWarnings(X[[nm]] <- as.numeric(X[[nm]]))
}

# 3) Align names/order between S and X (and give S names if missing)
if (is.null(colnames(S))) colnames(S) <- colnames(X)
S <- S[, intersect(colnames(S), colnames(X)), drop = FALSE]
X <- X[, colnames(S), drop = FALSE]

# 4) Construct shapviz object: PASS S POSITIONALLY (no name) to avoid dispatch bug
sv <- shapviz(S, X = as.matrix(X))

# --- Examples ---------------------------------------------------------------
# Bar plot of top 30 (global |SHAP|)
ord  <- order(colMeans(abs(S), na.rm = TRUE), decreasing = TRUE)
topK <- colnames(S)[ord[1:min(30, ncol(S))]]
sv_importance(sv, kind = "bar", v = topK)
```

```{r abg-shap-beeswarm}
#| code-block-title: "ABG propensity SHAP beeswarm"
library(shapviz)

S <- as.matrix(sh_abg_fast$shap)   # n x p SHAP values
X <- as.data.frame(sh_abg_fast$X)  # same rows, p columns (features)

# Build shapviz object
sv <- shapviz(S, X = as.matrix(X))

# Beeswarm-style SHAP summary (like Python SHAP)
sv_importance(sv, kind = "beeswarm", max_display = 25)              # overall

```

```{r shap_dependence_abg}
#| code-block-title: "ABG propensity SHAP dependence"
#| label: shap_dependence_abg
#| message: false
#| warning: false
# Primary = top feature; color by next feature
imp_order <- colnames(S)[ord]
sv_dependence(sv, v = imp_order[1], color_var = imp_order[2], smooth = TRUE)
```

```{r shap_grid_top5}
#| code-block-title: "ABG propensity SHAP top-5 grid"
#| label: shap_grid_top5
#| fig-width: 8
#| fig-height: 8
#| warning: false
#| message: false

# --- Compact 5x5 SHAP dependence grid with shared axes and a single small legend ----
library(shapviz)
library(ggplot2)
library(patchwork)
library(grid)   # for unit()

# If needed, recover S and X_sv from 'sv'
if (!exists("S"))  S  <- sv$S
if (!exists("X_sv")) X_sv <- as.data.frame(sv$X)
stopifnot(is.matrix(S), is.data.frame(X_sv))

# 1) Top-5 by global mean |SHAP|
ranked <- colnames(S)[order(colMeans(abs(S), na.rm = TRUE), decreasing = TRUE)]
top5   <- head(ranked, 5)

# 2) Shared y-range across all top-5 features
y_rng <- range(unlist(lapply(top5, function(v) S[, v])), finite = TRUE)

# 3) Small theme helpers
theme_axes_compact <- function(show_y = FALSE, show_x = FALSE, base = 8) {
  theme_minimal(base_size = base) +
    theme(
      axis.title.y   = if (show_y) element_text(size = base) else element_blank(),
      axis.text.y    = if (show_y) element_text(size = base - 1) else element_blank(),
      axis.ticks.y   = if (show_y) element_line(linewidth = 0.2) else element_blank(),
      axis.title.x   = if (show_x) element_text(size = base) else element_blank(),
      axis.text.x    = if (show_x) element_text(size = base - 1) else element_blank(),
      plot.title     = element_text(size = base, hjust = 0),
      legend.title   = element_text(size = base - 1),
      legend.text    = element_text(size = base - 2),
      legend.key.height = unit(22, "pt"),
      legend.key.width  = unit(3,  "pt"),
      legend.margin     = margin(0, 0, 0, 0, "pt"),
      legend.box.margin = margin(0, 0, 0, 0, "pt")
    )
}

# 4) One cell builder
cell_plot <- function(v_row, v_col, i, j, n) {
  show_y <- (j == 1)          # y-axis only on first column
  show_x <- (i == n)          # x-axis only on bottom row

  if (identical(v_row, v_col)) {
    # diagonal: unshaded scatter (no legend)
    df <- data.frame(
      x    = as.numeric(X_sv[[v_row]]),
      shap = as.numeric(S[, v_row])
    )
    df <- df[is.finite(df$x) & is.finite(df$shap), , drop = FALSE]

    ggplot(df, aes(x = x, y = shap)) +
      geom_point(alpha = 0.30, size = 0.45, na.rm = TRUE) +
      scale_y_continuous(limits = y_rng) +
      labs(title = v_row, x = v_row, y = "SHAP") +
      theme_axes_compact(show_y = show_y, show_x = show_x, base = 8) +
      theme(legend.position = "none")
  } else {
    # off-diagonal: color by partner feature
    p <- shapviz::sv_dependence(sv, v = v_row, color_var = v_col, size = 0.4) +
      scale_y_continuous(limits = y_rng) +
      labs(title = paste0(v_row, " | color: ", v_col),
           x = v_row, y = "SHAP")

    # keep a single, small legend on the top-right panel only
    keep_legend <- (i == 1 && j == length(top5))
    p +
      theme_axes_compact(show_y = show_y, show_x = show_x, base = 8) +
      guides(colour = guide_colorbar(
        barheight    = unit(24, "pt"),
        barwidth     = unit(3,  "pt"),
        title.position = "top",
        title.hjust    = 0.5,
        label.position = "right"
      )) +
      theme(legend.position = if (keep_legend) "right" else "none")
  }
}

# 5) Build grid row-wise
n <- length(top5)
plots <- vector("list", n * n)
idx <- 1
for (i in seq_len(n)) {
  for (j in seq_len(n)) {
    vr <- top5[i]; vc <- top5[j]
    plots[[idx]] <- cell_plot(vr, vc, i, j, n)
    idx <- idx + 1
  }
}

# 6) Draw: 5 columns, shared layout; keep (not collect) legends so only the chosen one stays
patchwork::wrap_plots(plots, ncol = n, guides = "keep") +
  plot_annotation(title = "Top-5 SHAP dependence: interactions (off-diagonal) and main effects (diagonal)")
```

### VBG explainability

VBG Explainability

```{r explainability_vbg_fast_only}
#| code-block-title: "VBG propensity explainability setup"
#| label: explainability_vbg_fast_only
#| message: false
#| warning: false

library(WeightIt); library(gbm); library(dplyr); library(ggplot2)

stopifnot(exists("w_vbg", inherits = TRUE))
w_vbg <- ensure_gbm_obj(w_vbg)

imp_vbg   <- extract_gbm_importance(w_vbg, top_n = 25)
p_imp_vbg <- plot_gbm_importance(imp_vbg, "VBG selection model — GBM relative influence")
p_imp_vbg
```

```{r shap_build_vbg_fast}
#| code-block-title: "VBG propensity SHAP computation and importance"
#| label: shap_build_vbg_fast
#| message: false
#| warning: false

library(shapviz); library(fastshap)

t0 <- Sys.time()
sh_vbg_fast <- compute_shap_fast(w_vbg, top_k = 100, nsim = 32, frac_rows = 0.25, max_rows = 100000)
t1 <- Sys.time(); message(sprintf("[compute_shap_fast VBG] %.2f s", as.numeric(difftime(t1, t0, units="secs"))))

S_vbg <- as.matrix(sh_vbg_fast$shap)
X_vbg <- as.data.frame(sh_vbg_fast$X)

for (nm in names(X_vbg)) {
  if (inherits(X_vbg[[nm]], "haven_labelled")) X_vbg[[nm]] <- labelled::to_factor(X_vbg[[nm]])
  if (is.factor(X_vbg[[nm]]))  X_vbg[[nm]] <- as.character(X_vbg[[nm]])
  if (is.character(X_vbg[[nm]])) suppressWarnings(X_vbg[[nm]] <- as.numeric(X_vbg[[nm]]))
}
if (is.null(colnames(S_vbg))) colnames(S_vbg) <- colnames(X_vbg)
S_vbg <- S_vbg[, intersect(colnames(S_vbg), colnames(X_vbg)), drop = FALSE]
X_vbg <- X_vbg[, colnames(S_vbg), drop = FALSE]

sv_vbg <- shapviz::shapviz(S_vbg, X = as.matrix(X_vbg))

ord_vbg  <- order(colMeans(abs(S_vbg), na.rm = TRUE), decreasing = TRUE)
topK_vbg <- colnames(S_vbg)[ord_vbg[1:min(30, ncol(S_vbg))]]
sv_importance(sv_vbg, kind = "bar", v = topK_vbg)
```

```{r shap_beeswarm_vbg}
#| code-block-title: "VBG propensity SHAP beeswarm"
#| label: shap_beeswarm_vbg
#| message: false
#| warning: false

library(shapviz)
sv_importance(sv_vbg, kind = "beeswarm", max_display = 25)
```

```{r shap_dependence_vbg}
#| code-block-title: "VBG propensity SHAP dependence"
#| label: shap_dependence_vbg
#| message: false
#| warning: false

library(ggplot2)

imp_order_vbg <- colnames(S_vbg)[order(colMeans(abs(S_vbg), na.rm = TRUE), decreasing = TRUE)]
pri_vbg <- imp_order_vbg[1]
aux_vbg <- imp_order_vbg[2]
if (identical(aux_vbg, pri_vbg) || !(aux_vbg %in% colnames(X_vbg))) aux_vbg <- imp_order_vbg[3]

shapviz::sv_dependence(sv_vbg, v = pri_vbg, color_var = aux_vbg, size = 1) +
  geom_smooth(se = FALSE, method = "loess", formula = y ~ x, linewidth = 0.6) +
  labs(title = sprintf("VBG propensity — SHAP dependence: %s (color: %s)", pri_vbg, aux_vbg),
       x = pri_vbg, y = "SHAP") +
  theme_minimal(base_size = 11)
```

```{r shap_grid_top5_vbg}
#| code-block-title: "VBG propensity SHAP top-5 grid"
#| label: shap_grid_top5_vbg
#| fig-width: 8
#| fig-height: 8
#| warning: false
#| message: false

library(shapviz); library(ggplot2); library(patchwork); library(grid)

stopifnot(is.matrix(S_vbg), is.data.frame(X_vbg))

ranked_vbg <- colnames(S_vbg)[order(colMeans(abs(S_vbg), na.rm = TRUE), decreasing = TRUE)]
top5_vbg   <- head(ranked_vbg, 5)
y_rng_vbg  <- range(unlist(lapply(top5_vbg, function(v) S_vbg[, v])), finite = TRUE)

theme_axes_compact <- function(show_y = FALSE, show_x = FALSE, base = 8) {
  theme_minimal(base_size = base) +
    theme(
      axis.title.y   = if (show_y) element_text(size = base) else element_blank(),
      axis.text.y    = if (show_y) element_text(size = base - 1) else element_blank(),
      axis.ticks.y   = if (show_y) element_line(linewidth = 0.2) else element_blank(),
      axis.title.x   = if (show_x) element_text(size = base) else element_blank(),
      axis.text.x    = if (show_x) element_text(size = base - 1) else element_blank(),
      plot.title     = element_text(size = base, hjust = 0),
      legend.title   = element_text(size = base - 1),
      legend.text    = element_text(size = base - 2),
      legend.key.height = unit(22, "pt"),
      legend.key.width  = unit(3,  "pt"),
      legend.margin     = margin(0, 0, 0, 0, "pt"),
      legend.box.margin = margin(0, 0, 0, 0, "pt")
    )
}

cell_plot_vbg <- function(v_row, v_col, i, j, n) {
  show_y <- (j == 1); show_x <- (i == n)
  if (identical(v_row, v_col)) {
    df <- data.frame(x = as.numeric(X_vbg[[v_row]]), shap = as.numeric(S_vbg[, v_row]))
    df <- df[is.finite(df$x) & is.finite(df$shap), , drop = FALSE]
    ggplot(df, aes(x = x, y = shap)) +
      geom_point(alpha = 0.30, size = 0.45, na.rm = TRUE) +
      scale_y_continuous(limits = y_rng_vbg) +
      labs(title = v_row, x = v_row, y = "SHAP") +
      theme_axes_compact(show_y, show_x, base = 8) +
      theme(legend.position = "none")
  } else {
    keep_legend <- (i == 1 && j == length(top5_vbg))
    shapviz::sv_dependence(sv_vbg, v = v_row, color_var = v_col, size = 0.4) +
      scale_y_continuous(limits = y_rng_vbg) +
      labs(title = paste0(v_row, " | color: ", v_col), x = v_row, y = "SHAP") +
      theme_axes_compact(show_y, show_x, base = 8) +
      guides(colour = guide_colorbar(barheight = unit(24, "pt"), barwidth = unit(3, "pt"),
                                     title.position = "top", title.hjust = 0.5, label.position = "right")) +
      theme(legend.position = if (keep_legend) "right" else "none")
  }
}

n <- length(top5_vbg); plots <- vector("list", n * n); k <- 1
for (i in seq_len(n)) for (j in seq_len(n)) {
  plots[[k]] <- cell_plot_vbg(top5_vbg[i], top5_vbg[j], i, j, n); k <- k + 1
}
patchwork::wrap_plots(plots, ncol = n, guides = "keep") +
  plot_annotation(title = "VBG propensity — Top-5 SHAP dependence (off-diagonal interactions, diagonal main effects)")
```

### Calculated ABG explainability

```{r explainability_calc_fast_only}
#| code-block-title: "Calculated ABG propensity explainability setup"
#| label: explainability_calc_fast_only
#| message: false
#| warning: false

library(WeightIt); library(gbm); library(dplyr); library(ggplot2)

stopifnot(exists("w_vbg_calc", inherits = TRUE))
w_vbg_calc <- ensure_gbm_obj(w_vbg_calc)

imp_calc   <- extract_gbm_importance(w_vbg_calc, top_n = 25)
p_imp_calc <- plot_gbm_importance(imp_calc, "Calculated ABG selection model — GBM relative influence")
p_imp_calc
```

```{r shap_build_calc_fast}
#| code-block-title: "Calculated ABG propensity SHAP computation and importance"
#| label: shap_build_calc_fast
#| message: false
#| warning: false

library(shapviz); library(fastshap)

t0 <- Sys.time()
sh_calc_fast <- compute_shap_fast(w_vbg_calc, top_k = 100, nsim = 32, frac_rows = 0.25, max_rows = 100000)
t1 <- Sys.time(); message(sprintf("[compute_shap_fast Calc-ABG] %.2f s", as.numeric(difftime(t1, t0, units="secs"))))

S_calc <- as.matrix(sh_calc_fast$shap)
X_calc <- as.data.frame(sh_calc_fast$X)

for (nm in names(X_calc)) {
  if (inherits(X_calc[[nm]], "haven_labelled")) X_calc[[nm]] <- labelled::to_factor(X_calc[[nm]])
  if (is.factor(X_calc[[nm]]))  X_calc[[nm]] <- as.character(X_calc[[nm]])
  if (is.character(X_calc[[nm]])) suppressWarnings(X_calc[[nm]] <- as.numeric(X_calc[[nm]]))
}
if (is.null(colnames(S_calc))) colnames(S_calc) <- colnames(X_calc)
S_calc <- S_calc[, intersect(colnames(S_calc), colnames(X_calc)), drop = FALSE]
X_calc <- X_calc[, colnames(S_calc), drop = FALSE]

sv_calc <- shapviz::shapviz(S_calc, X = as.matrix(X_calc))

ord_calc  <- order(colMeans(abs(S_calc), na.rm = TRUE), decreasing = TRUE)
topK_calc <- colnames(S_calc)[ord_calc[1:min(30, ncol(S_calc))]]
sv_importance(sv_calc, kind = "bar", v = topK_calc)
```

```{r shap_beeswarm_calc}
#| code-block-title: "Calculated ABG propensity SHAP beeswarm"
#| label: shap_beeswarm_calc
#| message: false
#| warning: false

library(shapviz)
sv_importance(sv_calc, kind = "beeswarm", max_display = 25)
```

```{r shap_dependence_calc}
#| code-block-title: "Calculated ABG propensity SHAP dependence"
#| label: shap_dependence_calc
#| message: false
#| warning: false

library(ggplot2)

imp_order_calc <- colnames(S_calc)[order(colMeans(abs(S_calc), na.rm = TRUE), decreasing = TRUE)]
pri_calc <- imp_order_calc[1]
aux_calc <- imp_order_calc[2]
if (identical(aux_calc, pri_calc) || !(aux_calc %in% colnames(X_calc))) aux_calc <- imp_order_calc[3]

shapviz::sv_dependence(sv_calc, v = pri_calc, color_var = aux_calc, size = 1) +
  geom_smooth(se = FALSE, method = "loess", formula = y ~ x, linewidth = 0.6) +
  labs(title = sprintf("Calculated‑ABG propensity — SHAP dependence: %s (color: %s)", pri_calc, aux_calc),
       x = pri_calc, y = "SHAP") +
  theme_minimal(base_size = 11)
```

```{r shap_grid_top5_calc}
#| code-block-title: "Calculated ABG propensity SHAP top-5 grid"
#| label: shap_grid_top5_calc
#| fig-width: 8
#| fig-height: 8
#| warning: false
#| message: false

library(shapviz); library(ggplot2); library(patchwork); library(grid)

stopifnot(is.matrix(S_calc), is.data.frame(X_calc))

ranked_calc <- colnames(S_calc)[order(colMeans(abs(S_calc), na.rm = TRUE), decreasing = TRUE)]
top5_calc   <- head(ranked_calc, 5)
y_rng_calc  <- range(unlist(lapply(top5_calc, function(v) S_calc[, v])), finite = TRUE)

theme_axes_compact <- function(show_y = FALSE, show_x = FALSE, base = 8) {
  theme_minimal(base_size = base) +
    theme(
      axis.title.y   = if (show_y) element_text(size = base) else element_blank(),
      axis.text.y    = if (show_y) element_text(size = base - 1) else element_blank(),
      axis.ticks.y   = if (show_y) element_line(linewidth = 0.2) else element_blank(),
      axis.title.x   = if (show_x) element_text(size = base) else element_blank(),
      axis.text.x    = if (show_x) element_text(size = base - 1) else element_blank(),
      plot.title     = element_text(size = base, hjust = 0),
      legend.title   = element_text(size = base - 1),
      legend.text    = element_text(size = base - 2),
      legend.key.height = unit(22, "pt"),
      legend.key.width  = unit(3,  "pt"),
      legend.margin     = margin(0, 0, 0, 0, "pt"),
      legend.box.margin = margin(0, 0, 0, 0, "pt")
    )
}

cell_plot_calc <- function(v_row, v_col, i, j, n) {
  show_y <- (j == 1); show_x <- (i == n)
  if (identical(v_row, v_col)) {
    df <- data.frame(x = as.numeric(X_calc[[v_row]]), shap = as.numeric(S_calc[, v_row]))
    df <- df[is.finite(df$x) & is.finite(df$shap), , drop = FALSE]
    ggplot(df, aes(x = x, y = shap)) +
      geom_point(alpha = 0.30, size = 0.45, na.rm = TRUE) +
      scale_y_continuous(limits = y_rng_calc) +
      labs(title = v_row, x = v_row, y = "SHAP") +
      theme_axes_compact(show_y, show_x, base = 8) +
      theme(legend.position = "none")
  } else {
    keep_legend <- (i == 1 && j == length(top5_calc))
    shapviz::sv_dependence(sv_calc, v = v_row, color_var = v_col, size = 0.4) +
      scale_y_continuous(limits = y_rng_calc) +
      labs(title = paste0(v_row, " | color: ", v_col), x = v_row, y = "SHAP") +
      theme_axes_compact(show_y, show_x, base = 8) +
      guides(colour = guide_colorbar(barheight = unit(24, "pt"), barwidth = unit(3, "pt"),
                                     title.position = "top", title.hjust = 0.5, label.position = "right")) +
      theme(legend.position = if (keep_legend) "right" else "none")
  }
}

n <- length(top5_calc); plots <- vector("list", n * n); k <- 1
for (i in seq_len(n)) for (j in seq_len(n)) {
  plots[[k]] <- cell_plot_calc(top5_calc[i], top5_calc[j], i, j, n); k <- k + 1
}
patchwork::wrap_plots(plots, ncol = n, guides = "keep") +
  plot_annotation(title = "Calculated‑ABG propensity — Top-5 SHAP dependence (off-diagonal interactions, diagonal main effects)")
```

## Weighted effect estimates

**New** weighted binary regression figures.

```{r ipw-binary-or-plot}
#| code-block-title: "IPW odds ratios: binary hypercapnia"
#  IP‑weighted odds‑ratio plot (ABG, VBG, Calculated‑ABG)
#    – exact analogue of the un‑weighted figure
# ──────────────────────────────────────────────────────────────────────────────

# weights already attached earlier:
#   • w_abg         – propensity for *ABG*   (column in subset_data)
#   • w_vbg         – propensity for *VBG*   (column in subset_data)
#   • w_vbg_calc    – same weights, used for calculated ABG CO₂

# 1. helper to fit an IP‑weighted GLM and return tidy OR -----------------------
tidy_ipw <- function(data, outcome, exposure, weight_var,
                     group_label, outcome_label) {
  des <- svydesign(ids = ~1, weights = as.formula(paste0("~", weight_var)),
                   data = data)
  mod <- svyglm(
    as.formula(paste0(outcome, " ~ ", exposure)),
    design = des,
    family = quasibinomial()
  )

  tidy(mod, exponentiate = TRUE, conf.int = TRUE) %>%
    filter(term == exposure) %>%                # keep the exposure row
    mutate(group = group_label, outcome = outcome_label)
}

# 2. cohort‑specific data frames ----------------------------------------------
abg_df   <- subset_data %>% filter(has_abg == 1)
vbg_df   <- subset_data %>% filter(has_vbg == 1)
calc_df  <- subset_data %>% filter(!is.na(calc_abg))   # implies VBG present

# 3. fit models & collect estimates -------------------------------------------
ipw_estimates <- bind_rows(
  # ABG
  tidy_ipw(abg_df,  "imv_proc",              "hypercap_on_abg", "w_abg",      "ABG",           "Intubation"),
  tidy_ipw(abg_df,  "niv_proc",              "hypercap_on_abg", "w_abg",      "ABG",           "NIV"),
  tidy_ipw(abg_df,  "death_60d",                  "hypercap_on_abg", "w_abg",      "ABG",           "Death"),
  tidy_ipw(abg_df,  "hypercap_resp_failure", "hypercap_on_abg", "w_abg",      "ABG",           "ICD Code"),

  # VBG
  tidy_ipw(vbg_df,  "imv_proc",              "hypercap_on_vbg", "w_vbg",      "VBG",           "Intubation"),
  tidy_ipw(vbg_df,  "niv_proc",              "hypercap_on_vbg", "w_vbg",      "VBG",           "NIV"),
  tidy_ipw(vbg_df,  "death_60d",                  "hypercap_on_vbg", "w_vbg",      "VBG",           "Death"),
  tidy_ipw(vbg_df,  "hypercap_resp_failure", "hypercap_on_vbg", "w_vbg",      "VBG",           "ICD Code"),

  # Calculated ABG
  tidy_ipw(calc_df, "imv_proc",              "hypercapnia_calc","w_vbg_calc", "Calculated ABG","Intubation"),
  tidy_ipw(calc_df, "niv_proc",              "hypercapnia_calc","w_vbg_calc", "Calculated ABG","NIV"),
  tidy_ipw(calc_df, "death_60d",                  "hypercapnia_calc","w_vbg_calc", "Calculated ABG","Death"),
  tidy_ipw(calc_df, "hypercap_resp_failure", "hypercapnia_calc","w_vbg_calc", "Calculated ABG","ICD Code")
)

# 4. plotting ------------------------------------------------------------------
ipw_estimates$group <- factor(
  ipw_estimates$group,
  levels = c("ABG", "VBG", "Calculated ABG")
)

ggplot(
  ipw_estimates,
  aes(
    x     = outcome,
    y     = estimate,
    ymin  = conf.low,
    ymax  = conf.high,
    color = group
  )
) +
  geom_pointrange(position = position_dodge(width = 0.6), size = 0.6) +
  geom_hline(yintercept = 1, linetype = "dashed", colour = "grey40") +
  scale_y_log10(
    breaks = c(0.25, 0.5, 1, 2, 4, 8, 16),
    limits = c(0.25, 16),
    labels = number_format(accuracy = 0.01)
  ) +
  coord_flip() +
  labs(
    title  = "IP Weighted Odds Ratio of Outcomes When Hypercapnia Present",
    x      = "Outcome",
    y      = "Odds Ratio (log scale, 95 % CI)",
    color  = "Blood gas type",
    caption = paste(
      "Inverse‑probability weights adjust for covariates associated with receiving each blood‑gas.",
      "Models are fitted within their respective cohorts:",
      "ABG (weights = w_abg), VBG (w_vbg), Calculated ABG (w_vbg_calc).",
      "Numerator = hypercapnic; denominator = normocapnic within cohort.",
      sep = "\n"
    )
  ) +
  theme_minimal(base_size = 10) +
  theme(plot.caption = element_text(hjust = 0))
```

### Three-level PCO₂ categories (weighted; ABG, VBG, Calc ABG)

Three Groups with Weights

```{r ipw-three-level-pco2-all}
#| code-block-title: "IPW odds ratios: three-level PCO2 (ABG/VBG/Calculated)"
library(dplyr)
library(survey)
library(broom)
library(ggplot2)
library(scales)

# ── 1. Create PCO₂ categories ───────────────────────────────────────────────
subset_data <- subset_data %>%
  mutate(
    pco2_cat_abg = case_when(
      !is.na(paco2) & paco2 < 35 ~ "Below normal",
      !is.na(paco2) & paco2 >= 35 & paco2 <= 45 ~ "Normal",
      !is.na(paco2) & paco2 > 45 ~ "Above normal",
      TRUE ~ NA_character_
    ),
    pco2_cat_vbg = case_when(
      !is.na(vbg_co2) & vbg_co2 < 40 ~ "Below normal",
      !is.na(vbg_co2) & vbg_co2 >= 40 & vbg_co2 <= 50 ~ "Normal",
      !is.na(vbg_co2) & vbg_co2 > 50 ~ "Above normal",
      TRUE ~ NA_character_
    ),
    pco2_cat_calc = case_when(
      !is.na(calc_abg) & calc_abg < 35 ~ "Below normal",
      !is.na(calc_abg) & calc_abg >= 35 & calc_abg <= 45 ~ "Normal",
      !is.na(calc_abg) & calc_abg > 45 ~ "Above normal",
      TRUE ~ NA_character_
    )
  )

# ── 2. Function: weighted logistic regression & OR extraction ───────────────
run_weighted_or <- function(data, outcome, cat_var, weight_var, group_name) {
  dat <- data %>%
    filter(
      !is.na(.data[[cat_var]]),
      !is.na(.data[[outcome]]),
      !is.na(.data[[weight_var]]),
      .data[[weight_var]] > 0
    ) %>%
    mutate(
      !!cat_var := factor(.data[[cat_var]],
                          levels = c("Normal", "Below normal", "Above normal"))
    ) %>%
    droplevels()

  design <- svydesign(
    ids = ~1,
    weights = as.formula(paste0("~", weight_var)),
    data = dat
  )

  fit <- svyglm(as.formula(paste(outcome, "~", cat_var)),
                design = design, family = quasibinomial())

  tidy(fit, exponentiate = TRUE, conf.int = TRUE) %>%
    filter(term != "(Intercept)") %>%
    mutate(
      group    = group_name,
      outcome  = outcome,
      exposure = gsub(paste0(cat_var), "", term) %>%
                   gsub("`", "", .)
    )
}

# ── 3. Run across outcomes & cohorts ────────────────────────────────────────
outcomes <- c("imv_proc", "niv_proc", "death_60d", "hypercap_resp_failure")

combined_or_df <- bind_rows(
  lapply(outcomes, function(out)
    run_weighted_or(subset_data, out, "pco2_cat_abg",  "w_abg",      "ABG")),
  lapply(outcomes, function(out)
    run_weighted_or(subset_data, out, "pco2_cat_vbg",  "w_vbg",      "VBG")),
  lapply(outcomes, function(out)
    run_weighted_or(subset_data, out, "pco2_cat_calc", "w_vbg_calc", "Calculated ABG"))
)

# Ensure nice ordering
combined_or_df$group    <- factor(combined_or_df$group,
                                  levels = c("ABG", "VBG", "Calculated ABG"))
combined_or_df$exposure <- factor(combined_or_df$exposure,
                                  levels = c("Below normal", "Above normal"))

# ── 4. Plot weighted odds ratios ────────────────────────────────────────────
ggplot(
  combined_or_df,
  aes(
    x      = outcome,
    y      = estimate,
    ymin   = conf.low,
    ymax   = conf.high,
    color  = group,
    shape  = exposure
  )
) +
  geom_pointrange(position = position_dodge(width = 0.7), size = 0.6) +
  geom_hline(yintercept = 1, linetype = "dashed", colour = "grey40") +
  scale_y_log10(
    breaks = c(0.25, 0.5, 1, 2, 4, 8, 16),
    limits = c(0.25, 16),
    labels = number_format(accuracy = 0.01)
  ) +
  coord_flip() +
  labs(
    title  = "Weighted Odds Ratios of Outcomes by PCO₂ Category (ABG, VBG, Calc ABG)",
    x      = "Outcome",
    y      = "Odds Ratio (log scale, 95% CI)",
    color  = "Blood-gas type",
    shape  = "PCO₂ category"
  ) +
  theme_minimal(base_size = 10) +
  theme(plot.caption = element_text(hjust = 0))

```

### Three-level PCO₂ categories (weighted; ABG vs VBG only)

Three groups with weights: Just ABG and VBG

```{r ipw-three-level-pco2-abg-vbg}
#| code-block-title: "IPW odds ratios: three-level PCO2 (ABG vs VBG)"
library(dplyr)
library(survey)
library(broom)
library(ggplot2)
library(scales)

# ── 2. Function: weighted logistic regression & OR extraction ───────────────
run_weighted_or <- function(data, outcome, cat_var, weight_var, group_name) {
  dat <- data %>%
    filter(
      !is.na(.data[[cat_var]]),
      !is.na(.data[[outcome]]),
      !is.na(.data[[weight_var]]),
      .data[[weight_var]] > 0
    ) %>%
    mutate(
      !!cat_var := factor(.data[[cat_var]],
                          levels = c("Normal", "Below normal", "Above normal"))
    ) %>%
    droplevels()

  design <- svydesign(
    ids = ~1,
    weights = as.formula(paste0("~", weight_var)),
    data = dat
  )

  fit <- svyglm(as.formula(paste(outcome, "~", cat_var)),
                design = design, family = quasibinomial())

  tidy(fit, exponentiate = TRUE, conf.int = TRUE) %>%
    filter(term != "(Intercept)") %>%
    mutate(
      group    = group_name,
      outcome  = outcome,
      exposure = gsub(paste0(cat_var), "", term) %>%
                   gsub("`", "", .)
    )
}

# ── 3. Run across outcomes & cohorts ────────────────────────────────────────
outcomes <- c("imv_proc", "niv_proc", "death_60d", "hypercap_resp_failure")

combined_or_df <- bind_rows(
  lapply(outcomes, function(out)
    run_weighted_or(subset_data, out, "pco2_cat_abg",  "w_abg",      "ABG")),
  lapply(outcomes, function(out)
    run_weighted_or(subset_data, out, "pco2_cat_vbg",  "w_vbg",      "VBG"))
)

# Ensure nice ordering
combined_or_df$group    <- factor(combined_or_df$group,
                                  levels = c("ABG", "VBG"))
combined_or_df$exposure <- factor(combined_or_df$exposure,
                                  levels = c("Below normal", "Above normal"))

# ── 4. Plot weighted odds ratios ────────────────────────────────────────────
ggplot(
  combined_or_df,
  aes(
    x      = outcome,
    y      = estimate,
    ymin   = conf.low,
    ymax   = conf.high,
    color  = group,
    shape  = exposure
  )
) +
  geom_pointrange(position = position_dodge(width = 0.7), size = 0.6) +
  geom_hline(yintercept = 1, linetype = "dashed", colour = "grey40") +
  scale_y_log10(
    breaks = c(0.25, 0.5, 1, 2, 4, 8, 16),
    limits = c(0.25, 16),
    labels = number_format(accuracy = 0.01)
  ) +
  coord_flip() +
  labs(
    title  = "Weighted Odds Ratios of Outcomes by PCO₂ Category (ABG, VBG)",
    x      = "Outcome",
    y      = "Odds Ratio (log scale, 95% CI)",
    color  = "Blood-gas type",
    shape  = "PCO₂ category"
  ) +
  theme_minimal(base_size = 10) +
  theme(plot.caption = element_text(hjust = 0))
```

## Propensity score diagnostics

Plotting propensity scores

```{r propensity-histograms-conditional}
#| code-block-title: "Propensity score histograms (conditional panels)"
# --- Propensity score histograms (ABG / VBG / Calculated-ABG) -----------------
# ABG = arterial blood gas; VBG = venous blood gas

library(dplyr)
library(ggplot2)
library(scales)

# Resolve WeightIt objects regardless of naming used upstream
w_abg_obj      <- if (exists("w_abg")) w_abg else if (exists("weight_model")) weight_model else NULL
w_vbg_obj      <- if (exists("w_vbg")) w_vbg else NULL
w_vbg_calc_obj <- if (exists("w_vbg_calc")) w_vbg_calc else if (exists("w_vbg")) w_vbg else NULL

if (is.null(w_abg_obj)) stop("ABG WeightIt object not found. Define `w_abg` or `weight_model` before this block.")
if (!"has_abg" %in% names(subset_data)) stop("`subset_data` must contain `has_abg` for ABG PS plotting.")

# Build list of per-cohort PS data frames conditionally (so missing cohorts don't error)
ps_dfs <- list(
  ABG = data.frame(
    ps        = w_abg_obj$ps,
    treat     = subset_data$has_abg,
    ScoreType = "ABG"
  )
)

if (!is.null(w_vbg_obj) && "has_vbg" %in% names(subset_data)) {
  ps_dfs$VBG <- data.frame(
    ps        = w_vbg_obj$ps,
    treat     = subset_data$has_vbg,
    ScoreType = "VBG"
  )
} else if (is.null(w_vbg_obj)) {
  message("Note: VBG WeightIt object `w_vbg` not found; skipping VBG panel.")
}

# Calculated ABG uses the VBG selection model; prefer a dedicated `w_vbg_calc` if present
if (!is.null(w_vbg_calc_obj) && "has_vbg_co2_o2_sat" %in% names(subset_data)) {
  ps_dfs$CalcABG <- data.frame(
    ps        = w_vbg_calc_obj$ps,
    treat     = subset_data$has_vbg_co2_o2_sat,
    ScoreType = "Calculated ABG"
  )
} else if (is.null(w_vbg_calc_obj)) {
  message("Note: Calculated-ABG WeightIt object `w_vbg_calc` (or fallback `w_vbg`) not found; skipping Calc-ABG panel.")
}

# Bind, clean, and factorize for plotting
df_ps <- bind_rows(ps_dfs) %>%
  filter(!is.na(ps), !is.na(treat)) %>%
  mutate(
    treat     = factor(treat, levels = c(0, 1), labels = c("No Test", "Test")),
    ScoreType = factor(ScoreType, levels = c("ABG", "VBG", "Calculated ABG"))
  )

# Plot
ggplot(df_ps, aes(x = ps, fill = treat)) +
  geom_histogram(aes(y = ..density..), alpha = 0.5,
                 position = "identity", bins = 30) +
  scale_fill_manual(values = c("No Test" = "steelblue", "Test" = "tomato")) +
  facet_wrap(~ScoreType, scales = "free_y") +
  coord_cartesian(xlim = c(0, 1)) +
  labs(
    title = "Propensity Score Distributions",
    x     = "Propensity score",
    y     = "Density",
    fill  = "Group"
  ) +
  theme_minimal(base_size = 12)
```

```{r propensity-histograms-all}
#| code-block-title: "Propensity score histograms (all panels explicit)"
df_ps <- bind_rows(
  data.frame(
    ps        = w_abg$ps,
    treat     = subset_data$has_abg,
    ScoreType = "ABG"
  ),
  data.frame(
    ps        = w_vbg$ps,
    treat     = subset_data$has_vbg,
    ScoreType = "VBG"
  ),
  data.frame(
    ps        = w_vbg_calc$ps,
    treat     = subset_data$has_vbg_co2_o2_sat,
    ScoreType = "Calculated ABG"
  )
) %>%
  mutate(
    treat = factor(treat, levels = c(0,1), labels = c("No Test", "Test"))
  )

ggplot(df_ps, aes(x = ps, fill = treat)) +
  geom_histogram(aes(y = ..density..), alpha = 0.5,
                 position = "identity", bins = 30) +
  scale_fill_manual(values = c("No Test" = "steelblue", "Test" = "tomato")) +
  facet_wrap(~ScoreType, scales = "free_y") +
  labs(
    title = "Propensity Score Distributions",
    x = "Propensity Score",
    y = "Density",
    fill = "Group"
  ) +
  theme_minimal(base_size = 12)

```

# Multiple Imputation Analysis

added 12/6/2025

## 1.) Packages and Reproducibility

```{r mi-packages}
# Core MI + diagnostics
library(mice)         # chained equations (MICE)
library(miceadds)     # pooling helpers & utilities
library(naniar)       # missingness summaries/plots
library(visdat)       # quick type/missingness viz
library(skimr)        # data skim for large frames

# Modeling
library(WeightIt)     # GBM propensity with weights
library(gbm)          # underlying GBM engine
library(survey)       # svyglm outcome models
library(cobalt)       # balance diagnostics
library(broom)        # tidy model outputs
library(dplyr)        # data manipulation
library(ggplot2)

# Pooling and MI bookkeeping
library(mitools)      # MIcombine for pooling (generic)
library(parallel)     # basic parallel where helpful

# Parallel + progress setup
library(future)

# setup
library(future.apply)
library(progressr)

workers <- max(1L, future::availableCores() - 1L)
future::plan(multisession, workers = workers)
on.exit(future::plan("sequential"), add = TRUE)

# choose a handler, but DO NOT make it global inside a knitted document
progressr::handlers(progressr::handler_rstudio)   # or handler_txtprogressbar
options(future.rng.onMisuse = "error")            # safer RNG with futures

set.seed(20251206)

# ensure a writable figure dir + stable device on macOS
if (!dir.exists("figs")) dir.create("figs", recursive = TRUE, showWarnings = FALSE)
knitr::opts_chunk$set(fig.path = "figs/", dev = "png", dpi = 144)
options(bitmapType = "cairo")  # prevents device issues on macOS

```

### **1.1) Missingness audit (what, where, how much)**

```{r mi-missing-audit}
# High-level profiles
skimr::skim(subset_data)

# Variable-wise % missing
naniar::miss_var_summary(subset_data)

# Patterns
naniar::gg_miss_var(subset_data, facet = encounter_type)
naniar::gg_miss_upset(subset_data, nsets = 6)

# Types & potential issues
visdat::vis_dat(subset_data, warn_large_data = FALSE)
```

## **2) Pre‑imputation data prep (consistent types & predictors)**

**Why**: MI models need coherent types; using exactly the same covariates as the propensity score models avoids model drift.

```{r mi-prep}
# Ensure intended factor/numeric types for imputation
# --- Inspect current encounter_type -------------------------------------------
cat("encounter_type class:", paste(class(subset_data$encounter_type), collapse = ", "), "\n")
print(utils::head(unique(subset_data$encounter_type), 20))

# Keep a raw copy for debugging if mapping fails
encounter_type_raw <- subset_data$encounter_type

# --- Helpers ------------------------------------------------------------------

# Map various encodings to strict 0/1 integer (for sex + 0/1 indicators)
to01 <- function(x) {
  if (is.logical(x)) return(as.integer(x))
  if (is.factor(x))  x <- as.character(x)

  out <- rep(NA_integer_, length(x))
  xs  <- suppressWarnings(as.numeric(x))
  is_num <- !is.na(xs)

  # numeric 0/1
  out[is_num & xs %in% c(0, 1)] <- as.integer(xs[is_num & xs %in% c(0, 1)])

  # character encodings (case/space-insensitive)
  if (any(!is_num)) {
    s <- trimws(tolower(as.character(x[!is_num])))
    out[!is_num][s %in% c("0","no","false","female","f")] <- 0L
    out[!is_num][s %in% c("1","yes","true","male","m")]   <- 1L
  }
  out
}

# Robust normalizer for encounter_type:
# - accepts numeric 2/3, digit-strings "2", "3", "2 - ED", etc.
# - accepts common synonyms with word-boundary protection
normalize_encounter_type <- function(x) {
  # to character once
  s_chr <- trimws(tolower(as.character(x)))

  # try to pull numeric code from any digits present
  num_from_text <- suppressWarnings(as.numeric(gsub("[^0-9]+", "", s_chr)))

  lab <- rep(NA_character_, length(s_chr))

  # numeric path
  lab[!is.na(num_from_text) & num_from_text == 2] <- "Emergency"
  lab[!is.na(num_from_text) & num_from_text == 3] <- "Inpatient"

  # synonym path (fill only still-NA)
  is_na <- is.na(lab)

  # Emergency synonyms: "emergency", "emerg", exact "ed", "a&e", "emergency dept"
  is_em <- grepl("\\bemerg(?:ency)?\\b", s_chr) |
           grepl("(^|[^a-z])ed([^a-z]|$)", s_chr) |
           grepl("\\ba&e\\b", s_chr) |
           grepl("\\bemergency\\s+dept\\b", s_chr)

  # Inpatient synonyms: "inpatient", "inpt", "inpat", exact "ip"
  is_ip <- grepl("\\binpatient\\b", s_chr) |
           grepl("\\binpt\\b",     s_chr) |
           grepl("\\binpat\\b",    s_chr) |
           grepl("(^|[^a-z])ip([^a-z]|$)", s_chr)

  lab[is_na & is_em] <- "Emergency"
  lab[is_na & is_ip] <- "Inpatient"

  factor(lab, levels = c("Emergency", "Inpatient"))
}

# --- Coerce analysis types (including encounter_type) --------------------------
subset_data <- subset_data |>
  mutate(
    sex               = factor(to01(sex), levels = c(0L, 1L), labels = c("Female", "Male")),
    race_ethnicity    = if (is.factor(race_ethnicity)) race_ethnicity else factor(race_ethnicity),
    location          = if (is.factor(location))       location       else factor(location),
    encounter_type    = normalize_encounter_type(encounter_type),
    has_abg           = to01(has_abg),
    has_vbg           = to01(has_vbg),
    hypercap_on_abg   = to01(hypercap_on_abg),
    hypercap_on_vbg   = to01(hypercap_on_vbg)
  )

# immediately drop unused levels and assert exactly two levels in the observed data used by MI
subset_data$encounter_type <- droplevels(subset_data$encounter_type)
stopifnot(nlevels(subset_data$encounter_type) == 2L)

# --- Diagnostics for encounter_type -------------------------------------------
tab_enc <- table(subset_data$encounter_type, useNA = "ifany")
print(tab_enc)

if (sum(!is.na(subset_data$encounter_type)) == 0) {
  message("All encounter_type values are NA after normalization. Showing top raw values:")
  s_raw <- trimws(tolower(as.character(encounter_type_raw)))
  print(utils::head(sort(table(s_raw), decreasing = TRUE), 20))
  stop("normalize_encounter_type produced all NA; extend the synonym map to your raw values.")
}

# Must have at least one observed value and (after droplevels) exactly two levels
stopifnot(sum(!is.na(subset_data$encounter_type)) > 0)
stopifnot(nlevels(droplevels(subset_data$encounter_type)) == 2)

# --- Covariate set for GBM propensity models ----------------------------------
covars_gbm <- c(
  "age_at_encounter","sex","race_ethnicity","curr_bmi",
  "copd","asthma","osa","chf","acute_nmd","phtn","ckd","dm",
  "location","encounter_type","temp_new","sbp","dbp","hr","spo2",
  "sodium","serum_cr","serum_hco3","serum_cl","serum_lac","serum_k",
  "wbc","plt","bnp","serum_phos","serum_ca"
)

# Verify presence
missing_covars <- setdiff(covars_gbm, names(subset_data))
if (length(missing_covars)) {
  warning("These covariates are missing from subset_data: ",
          paste(missing_covars, collapse = ", "))
} else {
  message("All GBM covariates present.")
}
```

## **3) Imputation model specification (MICE)**

### **3.1) Predictor matrix & methods. Run MICE (moderate settings for scale)**

```{r mi-exec}
# --- variables for GBM propensity (kept identical to main analysis) ---
# ---- MICE setup (Option A: include PaCO2 for ABG + keep VBG CO2/O2Sat) ----
library(mice)
library(dplyr)

# --- variables for GBM propensity (kept identical to main analysis) ---
covars_gbm <- c(
  "age_at_encounter","sex","race_ethnicity","curr_bmi",
  "copd","asthma","osa","chf","acute_nmd","phtn","ckd","dm",
  "location","encounter_type","temp_new","sbp","dbp","hr","spo2",
  "sodium","serum_cr","serum_hco3","serum_cl","serum_lac","serum_k",
  "wbc","plt","bnp","serum_phos","serum_ca"
)

# --- add analysis targets and CO2 measures explicitly -------------------------
co2_vars <- c("paco2", "vbg_co2", "vbg_o2sat")

mi_vars <- unique(c(
  covars_gbm,
  "has_abg","has_vbg",                                  # treatments (NOT imputed)
  "imv_proc","niv_proc","death_60d","hypercap_resp_failure",  # outcomes (NOT imputed)
  co2_vars
))

mi_df <- subset_data[, mi_vars, drop = FALSE]

# Make binary comorbids factors so "logreg" is used (and stays binary)
bin_covars <- c("copd","asthma","osa","chf","acute_nmd","phtn","ckd","dm")
mi_df[bin_covars] <- lapply(mi_df[bin_covars], function(z) {
  if (is.factor(z)) return(droplevels(z))
  zz <- suppressWarnings(as.integer(z))
  factor(zz, levels = c(0L,1L), labels = c("0","1"))
})

# Force CO2 variables to be numeric BEFORE we convert any leftover characters to factor
coerce_num <- function(x) suppressWarnings(as.numeric(as.character(x)))
for (nm in intersect(co2_vars, names(mi_df))) mi_df[[nm]] <- coerce_num(mi_df[[nm]])

# For MICE: convert any remaining characters → factors (after CO2 numeric coercion)
mi_df <- dplyr::mutate(mi_df, across(where(is.character), ~ factor(.x)))

# --- methods & predictor matrix aligned to *mi_df* -----------------------------
meth <- mice::make.method(mi_df)

is_fac      <- vapply(mi_df, is.factor,  logical(1))
is_num      <- vapply(mi_df, is.numeric, logical(1))
is_bin_fac  <- vapply(mi_df, function(x) is.factor(x)  && nlevels(x) == 2, logical(1))
is_multicat <- vapply(mi_df, function(x) is.factor(x)  && nlevels(x) >  2, logical(1))

# robust defaults
meth[is_num]      <- "pmm"      # numerics: predictive mean matching
meth[is_multicat] <- "polyreg"  # unordered multicategory
meth[is_bin_fac]  <- "logreg"   # binary factors: logistic regression

# never impute treatments or outcomes
no_imp <- c("has_abg","has_vbg","imv_proc","niv_proc","death_60d","hypercap_resp_failure")
meth[intersect(names(meth), no_imp)] <- ""

# predictor matrix; forbid treatments/outcomes as predictors
pred <- mice::quickpred(mi_df, mincor = 0.05, minpuc = 0.25)
pred[, intersect(colnames(pred), no_imp)] <- 0
pred[intersect(rownames(pred), no_imp), ] <- 0

# integrity checks
stopifnot(
  ncol(pred) == ncol(mi_df),
  nrow(pred) == ncol(mi_df),
  length(meth) == ncol(mi_df),
  identical(names(meth), colnames(mi_df))
)

# --- run MICE ------------------------------------------------------------------
set.seed(20251206)
imp <- mice::mice(
  data            = mi_df,
  m               = 5,
  maxit           = 10,
  predictorMatrix = pred,
  method          = meth,
  printFlag       = TRUE,
  seed            = 20251206
)
saveRDS(imp, file = "mi_abg_vbg_mids.rds")

# quick sanity: these must exist and be numeric in completed data
dlist <- mice::complete(imp, action = "all")
stopifnot(all(c("paco2","vbg_co2") %in% names(dlist[[1]])))
stopifnot(is.numeric(dlist[[1]]$paco2), is.numeric(dlist[[1]]$vbg_co2))
```

### **3.3) Convergence & plausibility checks**

```{r mi-diagnostics}
imp <- readRDS("mi_abg_vbg_mids.rds")

plot(imp)                                    # trace plots
densityplot(imp, ~ curr_bmi + serum_hco3)    # imputed vs observed
stripplot(imp,  ~ spo2 + hr)                 # distribution overlap

md.pattern(complete(imp, "long"))            # pattern after MI - should be complete
```

## **4) Refit propensity models within each imputation**

We keep the GBM recipe close to the non‑MI run, but with lighter CV (cv.folds = 3) and slightly fewer trees.

### **4.1) ABG propensity (has_abg)**

```{r}
# Create completed datasets
dlist <- mice::complete(imp, action = "all")

# Fit ABG propensity weights in each imputation
fit_abg_one <- function(d) {
  w <- weightit(
    has_abg ~ .,
    data   = d[, c("has_abg", covars_gbm)],
    method = "gbm",
    estimand    = "ATE",
    include.obj = TRUE,
    n.trees     = 1000,
    interaction.depth = 3,
    shrinkage   = 0.02,
    bag.fraction= 0.6,
    cv.folds    = 2,
    stop.method = "es.mean"
  )
  # stabilise + two‑sided Winsorization
  ww <- w$weights; ww <- ww/mean(ww)
  cut <- stats::quantile(ww, c(.01,.99), na.rm = TRUE)
  ww <- pmin(pmax(ww, cut[1]), cut[2]); ww <- ww/mean(ww)
  w$weights <- ww
  w
}

with_progress({
  p <- progressor(along = seq_along(dlist))
  W_abg_list <- future_lapply(
    X = seq_along(dlist),
    FUN = function(i) {
      p(sprintf("Fitting ABG on imputation %d", i))
      set.seed(20251206 + i)           # per‑imputation seed for reproducibility
      fit_abg_one(dlist[[i]])
    },
    future.seed = TRUE                  # reproducible RNG across workers
  )
})

saveRDS(W_abg_list, "mi_W_abg_list.rds")
```

### **4.2) Balance diagnostics across imputations**

```{r}
# Vars you intended to use (from your earlier code)
vars0 <- covars_gbm

# Which factors collapse to 1 level AFTER complete-case filtering (per imputation, per arm)?
find_offenders_post_cc <- function(d, treat_var, vars) {
  keep <- c(treat_var, vars)
  dd   <- d[, keep, drop = FALSE]
  dd   <- dd[stats::complete.cases(dd), , drop = FALSE]  # mimic cobalt's CC
  if (!nrow(dd)) return(character(0))

  # factor with <2 levels in either arm
  bad <- vapply(vars, function(v) {
    x <- dd[[v]]
    if (!is.factor(x)) return(FALSE)
    by_arm <- tapply(x, dd[[treat_var]], function(z) nlevels(droplevels(z)))
    any(is.na(by_arm)) || any(by_arm < 2)
  }, logical(1))

  names(bad)[bad]
}

off_by_imp <- lapply(dlist, find_offenders_post_cc, treat_var = "has_abg", vars = vars0)
to_drop    <- Reduce(union, off_by_imp)  # union across imputations
message("Offenders (post CC): ", if (length(to_drop)) paste(to_drop, collapse = ", ") else "<none>")

# Keep only variables that never collapse post-CC
vars_keep2 <- setdiff(vars0, to_drop)
stopifnot(length(vars_keep2) > 0)
```

```{r mi-balance-abg}
# Build a variable set that has ≥2 levels in *every* imputation (prevents contrasts errors)
vary_ok <- function(z) {
  nz <- z[!is.na(z)]
  if (is.factor(nz)) nlevels(droplevels(nz)) > 1 else dplyr::n_distinct(nz) > 1
}
vars_keep <- Reduce(intersect, lapply(dlist, function(d) {
  keep <- vapply(d[, covars_gbm, drop = FALSE], vary_ok, logical(1))
  names(keep)[keep]
}))

# Long data for cobalt with weights and imputation id
make_long_for_cobalt <- function(dlist, W_list, treat_var, covars) {
  stopifnot(length(dlist) == length(W_list))
  do.call(rbind, lapply(seq_along(dlist), function(i) {
    di <- dlist[[i]][, c(treat_var, covars), drop = FALSE]
    di$.imp <- i
    di$.w   <- W_list[[i]]$weights
    di
  }))
}
dlong_abg <- make_long_for_cobalt(dlist, W_abg_list, "has_abg", vars_keep)

# removes empty levels introduced by the per‑imputation slicing and prevents spurious contrast errors.
dlong_abg <- droplevels(dlong_abg)

# Final guard: drop any factor that is 1‑level in the long frame (should be none after vars_keep)
one_level_factors <- names(Filter(function(x) is.factor(x) && nlevels(droplevels(x)) < 2,
                                 dlong_abg[vars_keep]))
if (length(one_level_factors)) {
  message("Dropping 1‑level factors in long data: ", paste(one_level_factors, collapse = ", "))
  vars_keep <- setdiff(vars_keep, one_level_factors)
}

# Balance with imputation identifiers
fml_abg <- reformulate(termlabels = vars_keep, response = "has_abg")
bal_abg <- cobalt::bal.tab(
  fml_abg,
  data        = dlong_abg,
  weights     = dlong_abg$.w,
  imp         = dlong_abg$.imp,      # vector of imputation IDs
  estimand    = "ATE",
  un          = TRUE,
  m.threshold = 0.1
)

# Optional plot
cobalt::love.plot(
  bal_abg,
  var.order    = "unadjusted",
  thresholds   = c(m = .1),
  sample.names = c("Raw", "IPW"),
  abs          = TRUE
)
```

### **4.3) VBG propensity (has_vbg) — mirror of 4.1**

```{r mi-propensity-vbg}
fit_vbg_one <- function(d) {
  w <- weightit(
    has_vbg ~ .,
    data   = d[, c("has_vbg", covars_gbm)],
    method = "gbm",
    estimand    = "ATE",
    include.obj = TRUE,
    n.trees     = 2000,
    interaction.depth = 3,
    shrinkage   = 0.01,
    bag.fraction= 0.6,
    cv.folds    = 3,
    stop.method = "es.mean"
  )
  ww <- w$weights; ww <- ww/mean(ww); cut <- stats::quantile(ww, c(.01,.99), na.rm=TRUE)
  ww <- pmin(pmax(ww, cut[1]), cut[2]); ww <- ww/mean(ww)
  w$weights <- ww
  w
}

with_progress({
  p <- progressor(along = seq_along(dlist))
  W_vbg_list <- future_lapply(
    X = seq_along(dlist),
    FUN = function(i) {
      p(sprintf("Fitting VBG on imputation %d", i))
      set.seed(30251206 + i)
      fit_vbg_one(dlist[[i]])
    },
    future.seed = TRUE
  )
})

saveRDS(W_vbg_list, "mi_W_vbg_list.rds")
```

### 4.4) VBG Balance

```{r mi-balance-vbg}
# --- VBG: balance across imputations (parallel to ABG) ------------------------

# Preconditions: dlist (m completed data sets), W_vbg_list (weights per imputation),
#                covars_gbm (covariate set). If W_vbg_list not in memory, load it.
if (!exists("W_vbg_list", inherits = TRUE)) {
  W_vbg_list <- readRDS("mi_W_vbg_list.rds")
}

# Helper(s) if not already defined above
if (!exists("vary_ok", inherits = TRUE)) {
  vary_ok <- function(z) {
    nz <- z[!is.na(z)]
    if (is.factor(nz)) nlevels(droplevels(nz)) > 1 else dplyr::n_distinct(nz) > 1
  }
}
if (!exists("make_long_for_cobalt", inherits = TRUE)) {
  make_long_for_cobalt <- function(dlist, W_list, treat_var, covars) {
    stopifnot(length(dlist) == length(W_list))
    do.call(rbind, lapply(seq_along(dlist), function(i) {
      di <- dlist[[i]][, c(treat_var, covars), drop = FALSE]
      di$.imp <- i
      di$.w   <- W_list[[i]]$weights
      di
    }))
  }
}

# 1) Keep only covariates that vary (≥2 levels for factors) in every imputation
vars_keep_vbg <- Reduce(intersect, lapply(dlist, function(d) {
  keep <- vapply(d[, covars_gbm, drop = FALSE], vary_ok, logical(1))
  names(keep)[keep]
}))

# 2) Long data (stack imputations), attach weights and imputation id
dlong_vbg <- make_long_for_cobalt(dlist, W_vbg_list, "has_vbg", vars_keep_vbg)
dlong_vbg <- droplevels(dlong_vbg)  # remove empty factor levels from stacking

# 3) Final guard: drop any factor that is 1-level in the stacked frame
one_level_factors_vbg <- names(Filter(function(x) is.factor(x) && nlevels(x) < 2,
                                      dlong_vbg[vars_keep_vbg]))
if (length(one_level_factors_vbg)) {
  message("Dropping 1-level factors in long VBG data: ",
          paste(one_level_factors_vbg, collapse = ", "))
  vars_keep_vbg <- setdiff(vars_keep_vbg, one_level_factors_vbg)
}

# 4) Balance with imputation identifiers
fml_vbg <- reformulate(termlabels = vars_keep_vbg, response = "has_vbg")

bal_vbg <- cobalt::bal.tab(
  fml_vbg,
  data        = dlong_vbg,
  weights     = dlong_vbg$.w,
  imp         = dlong_vbg$.imp,   # vector of imputation IDs
  estimand    = "ATE",
  un          = TRUE,
  m.threshold = 0.1
)

# 5) Optional Love plot
cobalt::love.plot(
  bal_vbg,
  var.order    = "unadjusted",
  thresholds   = c(m = .1),
  sample.names = c("Raw", "IPW"),
  abs          = TRUE
)
```

## **5) Weighted outcome models within each imputation + pooling**

Pool via Rubin’s rules using mitools::MIcombine. Extract the coefficient and its variance for the treatment effect from each imputation.

### **5.1) Helper: fit + extract log‑OR and SE from svyglm**

```{r mi-pool-helpers}
# --- Robust coefficient extraction from svyglm (handles factor-coded terms) ---
coef_var_from_svy <- function(fit, treat_name) {
  cn <- names(coef(fit))
  idx <- match(treat_name, cn)
  if (is.na(idx)) {
    # handle factor encodings like has_abg1, has_abgYes, etc.
    pat <- paste0("^", gsub("([\\W])", "\\\\$1", treat_name), "(1|Yes|TRUE|Male)?$")
    idx <- grep(pat, cn, perl = TRUE)[1]
  }
  if (is.na(idx)) stop("Treatment coefficient '", treat_name, "' not found in model.")
  b <- unname(coef(fit)[idx])
  V <- unname(vcov(fit)[idx, idx, drop = TRUE])
  if (!is.finite(b) || !is.finite(V)) stop("Non-finite estimate/variance.")
  list(b = b, V = V)
}

# --- Fit one weighted GLM on one completed dataset and extract log-OR + var ---
fit_and_extract <- function(data, weights, formula, treat_name) {
  stopifnot(length(weights) == nrow(data))
  # basic guards: variation in outcome and treatment
  yname <- all.vars(formula)[1L]
  if (dplyr::n_distinct(na.omit(data[[yname]]))   < 2L) stop("Outcome '", yname, "' has one level.")
  if (dplyr::n_distinct(na.omit(data[[treat_name]])) < 2L) stop("Treatment '", treat_name, "' has one level.")
  # design + fit
  data$w <- as.numeric(weights)
  des <- survey::svydesign(ids = ~1, weights = ~w, data = data)
  fit <- survey::svyglm(formula, design = des, family = quasibinomial())
  cv  <- coef_var_from_svy(fit, treat_name)
  list(coef = cv$b, vcov = cv$V)
}

# --- Pool across imputations; tolerate failures; report how many used ----------
pool_logOR <- function(est_list, term) {
  ok <- vapply(est_list, function(x) is.list(x) && is.finite(x$coef) && is.finite(x$vcov), logical(1))
  est_list <- est_list[ok]
  m_ok  <- length(est_list); m_tot <- length(ok)
  if (m_ok == 0L) {
    return(data.frame(term = term, logOR = NA_real_, SE = NA_real_, OR = NA_real_,
                      LCL = NA_real_, UCL = NA_real_, m_used = 0L, m_total = m_tot))
  }
  results   <- lapply(est_list, function(x) setNames(c(x$coef), term))
  variances <- lapply(est_list, function(x) { M <- matrix(x$vcov, 1, 1); dimnames(M) <- list(term, term); M })
  pooled <- mitools::MIcombine(results = results, variances = variances)
  est <- as.numeric(coef(pooled))
  se  <- sqrt(diag(pooled$variance))
  data.frame(term = term, logOR = est, SE = se, OR = exp(est),
             LCL = exp(est - 1.96 * se), UCL = exp(est + 1.96 * se),
             m_used = m_ok, m_total = m_tot, row.names = NULL)
}
```

### **5.2) ABG: outcomes = IMV, NIV, Death(60d), Hypercapnic RF**

```{r mi-abg-outcomes}
# Parallel ABG outcome fits and pooling across imputations
library(future.apply)
library(progressr)

# Inputs assumed present: imp, W_abg_list
stopifnot(exists("imp"), exists("W_abg_list"))
dlist <- mice::complete(imp, action = "all")
stopifnot(length(W_abg_list) == length(dlist))

outcomes_abg <- list(
  imv_proc = imv_proc ~ has_abg,
  niv_proc = niv_proc ~ has_abg,
  death    = death_60d ~ has_abg,
  hcrf     = hypercap_resp_failure ~ has_abg
)

old_plan <- future::plan()
workers  <- max(1L, as.integer(future::availableCores() - 1L))
future::plan(multisession, workers = workers)
on.exit(future::plan(old_plan), add = TRUE)

abg_results <- NULL
progressr::with_progress({
  p <- progressr::progressor(steps = length(outcomes_abg) * length(dlist))
  abg_results <- lapply(names(outcomes_abg), function(nm) {
    fml <- outcomes_abg[[nm]]
    ests <- future.apply::future_lapply(
      X = seq_along(dlist),
      FUN = function(i) {
        p(sprintf("ABG: %s (imp %d)", nm, i))
        tryCatch(
          fit_and_extract(dlist[[i]], W_abg_list[[i]]$weights, fml, "has_abg"),
          error = function(e) NULL
        )
      },
      future.seed = TRUE
    )
    out <- pool_logOR(ests, term = "has_abg")
    out$outcome <- nm
    out
  })
})
abg_results <- dplyr::bind_rows(abg_results)[, c("outcome","term","logOR","SE","OR","LCL","UCL","m_used","m_total")]
abg_results
```

### **5.3) Repeat for VBG**

```{r mi-vbg-outcomes}
# --- VBG outcomes --------------------------------------------------------------
# Parallel VBG outcome fits and pooling across imputations
library(future.apply)
library(progressr)

# Inputs assumed present: imp, W_vbg_list
stopifnot(exists("imp"), exists("W_vbg_list"))
dlist <- mice::complete(imp, action = "all")
stopifnot(length(W_vbg_list) == length(dlist))

outcomes_vbg <- list(
  imv_proc = imv_proc ~ has_vbg,
  niv_proc = niv_proc ~ has_vbg,
  death    = death_60d ~ has_vbg,
  hcrf     = hypercap_resp_failure ~ has_vbg
)

old_plan <- future::plan()
workers  <- max(1L, as.integer(future::availableCores() - 1L))
future::plan(multisession, workers = workers)
on.exit(future::plan(old_plan), add = TRUE)

vbg_results <- NULL
progressr::with_progress({
  p <- progressr::progressor(steps = length(outcomes_vbg) * length(dlist))
  vbg_results <- lapply(names(outcomes_vbg), function(nm) {
    fml <- outcomes_vbg[[nm]]
    ests <- future.apply::future_lapply(
      X = seq_along(dlist),
      FUN = function(i) {
        p(sprintf("VBG: %s (imp %d)", nm, i))
        tryCatch(
          fit_and_extract(dlist[[i]], W_vbg_list[[i]]$weights, fml, "has_vbg"),
          error = function(e) NULL
        )
      },
      future.seed = TRUE
    )
    out <- pool_logOR(ests, term = "has_vbg")
    out$outcome <- nm
    out
  })
})
vbg_results <- dplyr::bind_rows(vbg_results)[, c("outcome","term","logOR","SE","OR","LCL","UCL","m_used","m_total")]
vbg_results
```

## **6) Explainability on one representative imputation**

To manage runtime, compute SHAP/PDP/ALE on the first imputed dataset and its fitted GBM(s).

```{r}
# --- Fast SHAP for WeightIt GBM fits (works with MI) -------------------------

library(fastshap)
library(shapviz)
# --- Robust SHAP backend for WeightIt GBM fits --------------------------------
# Works whether gbm$var.names are raw feature names (factors ok) or one‑hot names
# like "sexFemale", "race_ethnicity3", "encounter_typeInpatient", etc.

# Map of factor levels observed at training time (for raw‑factor path)
.train_levels <- function(df) {
  f <- vapply(df, is.factor, logical(1))
  lapply(df[f], levels)
}

# Align factors in 'df' to a stored levels map (keeps order, avoids new/ambiguous levels)
.align_to_levels <- function(df, levels_map) {
  out <- as.data.frame(df, stringsAsFactors = FALSE)
  for (nm in intersect(names(levels_map), names(out))) {
    out[[nm]] <- factor(as.character(out[[nm]]), levels = levels_map[[nm]])
  }
  out
}

# Build a design with columns EXACTLY equal to 'varnames' by deriving indicators
# from the raw covariate frame 'X_raw'. This covers one‑hot names like "sexMale",
# "race_ethnicity2", "encounter_typeInpatient", etc.
.design_from_varnames <- function(X_raw, varnames) {
  X_raw <- as.data.frame(X_raw, stringsAsFactors = FALSE)

  # normalize odd classes; turn characters into factors (stable level strings)
  for (nm in names(X_raw)) {
    if (inherits(X_raw[[nm]], "haven_labelled")) X_raw[[nm]] <- as.character(X_raw[[nm]])
  }
  X_raw[] <- lapply(X_raw, function(z) if (is.character(z)) factor(z) else z)

  cn    <- colnames(X_raw)
  cn_s  <- make.names(cn)
  vn    <- varnames
  vn_s  <- make.names(vn)

  out <- matrix(NA_real_, nrow = nrow(X_raw), ncol = length(vn))
  colnames(out) <- vn

  for (i in seq_along(vn)) {
    v   <- vn[i]
    v_s <- vn_s[i]

    # Case 1: exact column present
    if (v %in% cn) {
      z <- X_raw[[v]]
      out[, i] <- if (is.factor(z)) as.numeric(z) else as.numeric(z)
      next
    }

    # Case 2: derive dummy = 1{ base == level } from a base column prefix
    # Find the longest raw name that is a prefix of v (sanitized comparison)
    cand <- which(startsWith(v_s, cn_s))
    if (length(cand)) {
      j <- cand[which.max(nchar(cn_s[cand]))]
      base <- cn[j]
      # level is the suffix of v after the base name (unsanitized; preserves case)
      lev  <- sub(paste0("^", base), "", v)
      x    <- X_raw[[base]]

      # Compare as strings to match labels like "Female", "Inpatient", "0","1",...
      x_chr <- if (is.factor(x)) as.character(x) else as.character(x)
      out[, i] <- as.numeric(x_chr == lev)
      out[is.na(x_chr), i] <- NA_real_
      next
    }

    stop("Cannot construct design column for '", v, "'. ",
         "No matching base variable found in raw covariates.")
  }

  as.data.frame(out, check.names = FALSE)
}

# Unified backend:
#  - If gbm$var.names are raw feature names, pass factors directly (aligning levels).
#  - Otherwise, build a one‑hot design with those exact column names and predict on it.
make_shap_backend_any <- function(W) {
  gbm_fit <- if (!is.null(W$obj)) W$obj else if (!is.null(W$info$obj)) W$info$obj else W$info$model.obj
  stopifnot(inherits(gbm_fit, "gbm"))
  best_tree <- if (!is.null(W$info$best.tree)) W$info$best.tree else gbm_fit$n.trees

  X_raw <- as.data.frame(W$covs, stringsAsFactors = FALSE)
  # tidy odd classes; keep factors where they already are
  for (nm in names(X_raw)) {
    if (inherits(X_raw[[nm]], "haven_labelled")) X_raw[[nm]] <- as.character(X_raw[[nm]])
  }
  X_raw[] <- lapply(X_raw, function(z) if (is.character(z)) factor(z) else z)
  X_raw[] <- lapply(X_raw, function(z) if (is.factor(z)) droplevels(z) else z)

  vn <- gbm_fit$var.names
  levels_map <- .train_levels(X_raw)

  # Path A: raw‑factor training (names line up directly)
  if (all(vn %in% colnames(X_raw))) {
    X_use <- .align_to_levels(X_raw[, vn, drop = FALSE], levels_map)
    pred  <- function(object, newdata) {
      nd <- .align_to_levels(newdata, levels_map)
      predict(object, newdata = nd, n.trees = best_tree, type = "link")
    }
    return(list(gbm = gbm_fit, X = X_use, pred = pred, best_tree = best_tree))
  }

  # Path B: dummy‑coded training (var.names are one‑hot)
  X_use <- .design_from_varnames(X_raw, vn)
  pred  <- function(object, newdata) {
    # If caller already supplies the dummy design, use it; else derive it
    if (all(vn %in% colnames(newdata))) {
      nd <- as.data.frame(newdata)[, vn, drop = FALSE]
    } else {
      nd <- .design_from_varnames(newdata, vn)
    }
    predict(object, newdata = nd, n.trees = best_tree, type = "link")
  }

  list(gbm = gbm_fit, X = X_use, pred = pred, best_tree = best_tree)
}
```

```{r}
# Choose one completed dataset’s fit
# Device safety (once per doc)
if (!dir.exists("figs")) dir.create("figs", recursive = TRUE, showWarnings = FALSE)
knitr::opts_chunk$set(fig.path = "figs/", dev = "ragg_png", dpi = 200)

# --- ABG explainability on imputation 1 ---------------------------------------
stopifnot(exists("W_abg_list"), length(W_abg_list) >= 1)
W1_abg <- W_abg_list[[1]]

bk_abg <- make_shap_backend_any(W1_abg)

# Fast SHAP on link (logit) scale
S_abg <- fastshap::explain(
  object       = bk_abg$gbm,
  X            = bk_abg$X,
  pred_wrapper = bk_abg$pred,
  nsim         = 32,
  adjust       = TRUE
)

# shapviz object (X can be data.frame or matrix; keep column names)
sv_abg <- shapviz::shapviz(as.matrix(S_abg), X = as.matrix(bk_abg$X))

# Bar importance (top 30)
ord_abg   <- order(colMeans(abs(S_abg), na.rm = TRUE), decreasing = TRUE)
topK_abg  <- colnames(S_abg)[ord_abg[1:min(30, ncol(S_abg))]]
p_bar_abg <- shapviz::sv_importance(sv_abg, kind = "bar", v = topK_abg)
p_bar_abg

# Dependence: top feature colored by second (add smoother explicitly)
pri_abg <- topK_abg[1]
aux_abg <- topK_abg[2]
# dependence: replace loess with GAM to avoid near-singularity
p_dep_abg <- shapviz::sv_dependence(sv_abg, v = pri_abg, color_var = aux_abg) +
  ggplot2::geom_smooth(method = "gam", formula = y ~ s(x, bs = "cs", k = 4),
                       se = FALSE, linewidth = 0.5)

# for importance: don't set label = element_blank() on shapviz's plot; let it draw defaults
# if you see "aesthetics dropped: colour", avoid mapping `colour` in a stat
p_dep_abg
```

```{r}
# Repeat for VBG

# --- VBG explainability on imputation 1 ---------------------------------------
stopifnot(exists("W_vbg_list"), length(W_vbg_list) >= 1)
W1_vbg <- W_vbg_list[[1]]

bk_vbg <- make_shap_backend_any(W1_vbg)

S_vbg <- fastshap::explain(
  object       = bk_vbg$gbm,
  X            = bk_vbg$X,
  pred_wrapper = bk_vbg$pred,
  nsim         = 32,
  adjust       = TRUE
)

sv_vbg <- shapviz::shapviz(as.matrix(S_vbg), X = as.matrix(bk_vbg$X))

ord_vbg   <- order(colMeans(abs(S_vbg), na.rm = TRUE), decreasing = TRUE)
topK_vbg  <- colnames(S_vbg)[ord_vbg[1:min(30, ncol(S_vbg))]]
p_bar_vbg <- shapviz::sv_importance(sv_vbg, kind = "bar", v = topK_vbg)
p_bar_vbg

pri_vbg <- topK_vbg[1]
aux_vbg <- topK_vbg[2]
p_dep_vbg <- shapviz::sv_dependence(sv_vbg, v = pri_vbg, color_var = aux_vbg) +
  ggplot2::geom_smooth(se = FALSE, linewidth = 0.5, method = "loess", formula = y ~ x)
p_dep_vbg
```

## 7) Imputed, Weighted, **Three‑level PCO₂ categories (ABG weighted; VBG weighted)**

```{r}
#| label: ipw-three-level-pco2-mi-abg-vbg
#| message: false
#| warning: false
#| fig-width: 9
#| fig-height: 5

library(dplyr)
library(purrr)
library(survey)
library(mitools)
library(broom)
library(ggplot2)
library(scales)

# Expect: 'imp', 'W_abg_list', 'W_vbg_list' already available
if (!exists("dlist")) dlist <- mice::complete(imp, action = "all")
stopifnot(length(W_abg_list) == length(dlist),
          length(W_vbg_list) == length(dlist))

# Pool a set of survey GLMs across imputations for terms with a common prefix
pool_terms <- function(fits, term_prefix = "^co2_cat") {
  fits <- Filter(Negate(is.null), fits)
  stopifnot(length(fits) >= 2L)
  common <- Reduce(intersect, lapply(fits, ~ names(coef(.x))))
  keep   <- grep(term_prefix, common, value = TRUE)
  map_dfr(keep, function(term) {
    # lists of named scalars and 1x1 variance matrices for MIcombine()
    results   <- lapply(fits, function(f) setNames(c(coef(f)[term]), term))
    variances <- lapply(fits, function(f) {
      V <- vcov(f); m <- matrix(V[term, term], 1, 1); dimnames(m) <- list(term, term); m
    })
    pooled <- MIcombine(results = results, variances = variances)
    est <- as.numeric(coef(pooled)); se <- sqrt(diag(pooled$variance))
    tibble(term  = term,
           logOR = est,
           SE    = se,
           OR    = exp(est),
           LCL   = exp(est - 1.96 * se),
           UCL   = exp(est + 1.96 * se))
  })
}
```

### ABG, imputed, weighted, 3-level outcome

```{r}

# --- ABG: outcome ~ CO2 category, IPW by W_abg_list ---------------------------
# Assumes: dlist, W_abg_list, make_co2_cat(), use_fixed_abg, co2_breaks_abg,
#          co2_labels_abg, ref_label_abg are defined.

# ABG: outcome ~ CO2 category with IPW
fit_abg_cat <- function(outcome_var,
                        use_fixed_abg   = exists("co2_breaks_abg", inherits = TRUE),
                        co2_labels_abg  = c("Below normal","Normal","Above normal")) {
  fits <- vector("list", length(dlist))
  for (i in seq_along(dlist)) {
    d <- dlist[[i]]
    if (!("paco2" %in% names(d))) { fits[[i]] <- NULL; next }
    d$paco2 <- suppressWarnings(as.numeric(d$paco2))

    g <- with(d, has_abg == 1 & is.finite(paco2))
    if (!any(g)) { fits[[i]] <- NULL; next }

    d2 <- d[g, , drop = FALSE]
    d2$co2_cat <- make_co2_cat(
      d2$paco2,
      fixed_breaks = if (use_fixed_abg) co2_breaks_abg else NULL,
      labels       = co2_labels_abg
    )
    d2$co2_cat <- stats::relevel(base::droplevels(d2$co2_cat), ref = "Normal")
    if (nlevels(d2$co2_cat) < 2L) { fits[[i]] <- NULL; next }

    w <- W_abg_list[[i]]$weights[g]
    d2$w <- w
    des  <- svydesign(ids = ~1, weights = ~w, data = d2)
    fml  <- stats::as.formula(paste0(outcome_var, " ~ co2_cat"))
    fit  <- try(svyglm(fml, design = des, family = quasibinomial()), silent = TRUE)
    fits[[i]] <- if (!inherits(fit, "try-error")) fit else NULL
  }
  pool_terms(fits, term_prefix = "^co2_cat")
}
```

### VBG, imputed, weighted, 3-level

```{r}
# Assumes: dlist, W_vbg_list, make_co2_cat(), use_fixed_vbg, co2_breaks_vbg,
#          co2_labels_vbg, ref_label_vbg are defined.


# VBG: outcome ~ CO2 category with IPW
fit_vbg_cat <- function(outcome_var,
                        use_fixed_vbg  = exists("co2_breaks_vbg", inherits = TRUE),
                        co2_labels_vbg = c("Below normal","Normal","Above normal")) {
  fits <- vector("list", length(dlist))
  for (i in seq_along(dlist)) {
    d <- dlist[[i]]
    if (!("vbg_co2" %in% names(d))) { fits[[i]] <- NULL; next }
    d$vbg_co2 <- suppressWarnings(as.numeric(d$vbg_co2))

    g <- with(d, has_vbg == 1 & is.finite(vbg_co2))
    if (!any(g)) { fits[[i]] <- NULL; next }

    d2 <- d[g, , drop = FALSE]
    d2$co2_cat <- make_co2_cat(
      d2$vbg_co2,
      fixed_breaks = if (use_fixed_vbg) co2_breaks_vbg else NULL,
      labels       = co2_labels_vbg
    )
    d2$co2_cat <- stats::relevel(base::droplevels(d2$co2_cat), ref = "Normal")
    if (nlevels(d2$co2_cat) < 2L) { fits[[i]] <- NULL; next }

    w <- W_vbg_list[[i]]$weights[g]
    d2$w <- w
    des  <- svydesign(ids = ~1, weights = ~w, data = d2)
    fml  <- stats::as.formula(paste0(outcome_var, " ~ co2_cat"))
    fit  <- try(svyglm(fml, design = des, family = quasibinomial()), silent = TRUE)
    fits[[i]] <- if (!inherits(fit, "try-error")) fit else NULL
  }
  pool_terms(fits, term_prefix = "^co2_cat")
}
```

```{r}

# Run and combine
outs <- c("imv_proc", "niv_proc", "death_60d", "hypercap_resp_failure")

abg_df <- map_dfr(outs, ~ mutate(fit_abg_cat(.x), outcome = .x, group = "ABG"))
vbg_df <- map_dfr(outs, ~ mutate(fit_vbg_cat(.x), outcome = .x, group = "VBG"))

or_df <- bind_rows(abg_df, vbg_df) |>
  mutate(exposure = sub("^co2_cat", "", term),
         exposure = factor(exposure, levels = c("Below normal","Above normal")),
         outcome  = factor(outcome, levels = outs),
         group    = factor(group,   levels = c("ABG","VBG")))

# Plot
ggplot(or_df,
       aes(x = outcome, y = OR, ymin = LCL, ymax = UCL,
           color = group, shape = exposure)) +
  geom_pointrange(position = position_dodge(width = 0.7), size = 0.6) +
  geom_hline(yintercept = 1, linetype = "dashed", colour = "grey40") +
  scale_y_log10(breaks = c(0.25, 0.5, 1, 2, 4, 8, 16), limits = c(0.25, 16),
                labels = number_format(accuracy = 0.01)) +
  coord_flip() +
  labs(title = "Weighted Odds Ratios of Outcomes by PCO\u2082 Category (ABG, VBG)",
       x = "Outcome", y = "Odds Ratio (log scale, 95% CI)",
       color = "Blood-gas type", shape = "PCO\u2082 category") +
  theme_minimal(base_size = 10)
```

```{r}
# After re-running MICE:
dlist <- mice::complete(imp, action = "all")

# 1) must exist and be numeric
stopifnot(all(c("paco2","vbg_co2") %in% names(dlist[[1]])))
stopifnot(is.numeric(dlist[[1]]$paco2), is.numeric(dlist[[1]]$vbg_co2))

# 2) confirm at least two PaCO2 levels among those with ABG in each imputation
table(vapply(dlist, function(d) dplyr::n_distinct(d$paco2[d$has_abg == 1 & is.finite(d$paco2)]), integer(1)) > 1)

# 3) smoke test the ABG category fit on the first imputation
tmp <- fit_abg_cat("imv_proc"); print(tmp)
```

### Visualization

```{r}
#| label: ipw-three-level-pco2-mi-abg-vbg
#| message: false
#| warning: false
#| fig-width: 9
#| fig-height: 5

library(dplyr)
library(survey)
library(ggplot2)
library(scales)
library(purrr)
library(mitools)

# --- Pre-flight ----------------------------------------------------------------
if (!exists("dlist")) dlist <- mice::complete(imp, action = "all")
stopifnot(length(W_abg_list) == length(dlist),
          length(W_vbg_list) == length(dlist))

# --- Pooling helper for term-level log-ORs across imputations ------------------
pool_terms <- function(fits, term_prefix) {
  fits <- Filter(Negate(is.null), fits)
  if (length(fits) == 0L) {
    return(tibble::tibble(term=character(), logOR=numeric(), SE=numeric(),
                          OR=numeric(), LCL=numeric(), UCL=numeric()))
  }
  terms_list <- lapply(fits, function(f) names(stats::coef(f)))
  common     <- Reduce(intersect, terms_list)
  keep_terms <- grep(paste0("^", term_prefix), common, value = TRUE)
  if (!length(keep_terms)) {
    return(tibble::tibble(term=character(), logOR=numeric(), SE=numeric(),
                          OR=numeric(), LCL=numeric(), UCL=numeric()))
  }

  purrr::map_dfr(keep_terms, function(term) {
    res <- lapply(fits, function(f) setNames(c(stats::coef(f)[term]), term))
    vars <- lapply(fits, function(f) {
      V <- stats::vcov(f)
      m <- matrix(V[term, term], 1, 1); dimnames(m) <- list(term, term); m
    })
    pooled <- mitools::MIcombine(results = res, variances = vars)
    est <- as.numeric(stats::coef(pooled))
    se  <- sqrt(diag(pooled$variance))
    tibble::tibble(
      term  = term,
      logOR = est,
      SE    = se,
      OR    = exp(est),
      LCL   = exp(est - 1.96 * se),
      UCL   = exp(est + 1.96 * se)
    )
  })
}

# --- Per-group runner over imputations (ABG/VBG) -------------------------------
fit_cat_group <- function(group = c("ABG", "VBG"), outcome) {
  group <- match.arg(group)
  fits <- vector("list", length(dlist))

  for (i in seq_along(dlist)) {
    d <- dlist[[i]]

    if (group == "ABG") {
      if (!("paco2" %in% names(d))) { fits[[i]] <- NULL; next }
      d$paco2 <- suppressWarnings(as.numeric(d$paco2))
      g <- with(d, has_abg == 1 & is.finite(paco2))
      if (!any(g)) { fits[[i]] <- NULL; next }
      d2 <- d[g, , drop = FALSE]
      d2$co2_cat <- make_co2_cat(
        d2$paco2,
        normal = if (exists("co2_breaks_abg", inherits = TRUE)) co2_breaks_abg else c(35, 45)
      )
      w <- W_abg_list[[i]]$weights[g]

    } else {
      if (!("vbg_co2" %in% names(d))) { fits[[i]] <- NULL; next }
      d$vbg_co2 <- suppressWarnings(as.numeric(d$vbg_co2))
      g <- with(d, has_vbg == 1 & is.finite(vbg_co2))
      if (!any(g)) { fits[[i]] <- NULL; next }
      d2 <- d[g, , drop = FALSE]
      d2$co2_cat <- make_co2_cat(
        d2$vbg_co2,
        normal = if (exists("co2_breaks_vbg", inherits = TRUE)) co2_breaks_vbg else c(35, 45)
      )
      w <- W_vbg_list[[i]]$weights[g]
    }

    d2$co2_cat <- stats::relevel(base::droplevels(d2$co2_cat), ref = "Normal")
    if (nlevels(d2$co2_cat) < 2) { fits[[i]] <- NULL; next }

    d2$w <- w
    des  <- survey::svydesign(ids = ~1, weights = ~w, data = d2)
    fml  <- stats::as.formula(paste0(outcome, " ~ co2_cat"))
    fit  <- try(survey::svyglm(fml, design = des, family = quasibinomial()), silent = TRUE)
    fits[[i]] <- if (!inherits(fit, "try-error")) fit else NULL
  }

  out <- pool_terms(fits, term_prefix = "co2_cat")
  out
}

# --- Run & plot ----------------------------------------------------------------
outs <- c("imv_proc", "niv_proc", "death_60d", "hypercap_resp_failure")

abg_df <- purrr::map_dfr(outs, ~ dplyr::mutate(fit_cat_group("ABG", .x),
                                               outcome = .x, group = "ABG"))
vbg_df <- purrr::map_dfr(outs, ~ dplyr::mutate(fit_cat_group("VBG", .x),
                                               outcome = .x, group = "VBG"))
combined <- dplyr::bind_rows(abg_df, vbg_df)

# decode "co2_cat<level>" → exposure
combined <- combined |>
  dplyr::mutate(exposure = gsub("^co2_cat", "", term),
                exposure = factor(exposure, levels = c("Below normal","Above normal")),
                outcome  = factor(outcome,
                                  levels = c("imv_proc","niv_proc","death_60d","hypercap_resp_failure"),
                                  labels = c("IMV","NIV","Death (60d)","Hypercapnic RF")),
                group    = factor(group, levels = c("ABG","VBG")))

ggplot(
  combined,
  aes(x = outcome, y = OR, ymin = LCL, ymax = UCL, color = group, shape = exposure)
) +
  geom_pointrange(position = position_dodge(width = 0.7), size = 0.6) +
  geom_hline(yintercept = 1, linetype = "dashed", colour = "grey40") +
  scale_y_log10(
    breaks = c(0.25, 0.5, 1, 2, 4, 8, 16),
    limits = c(0.25, 16),
    labels = scales::number_format(accuracy = 0.01)
  ) +
  coord_flip() +
  labs(
    title = "MI‑pooled, IPW odds ratios by PCO₂ category (ABG vs VBG)",
    x = "Outcome",
    y = "Odds Ratio (log scale, 95% CI)",
    color = "Blood‑gas type",
    shape = "PCO₂ category"
  ) +
  theme_minimal(base_size = 10)
```

## 8) Imputed, Weighted **spline PCO₂ (ABG weighted; VBG weighted)**

### ABG, imputed, weighted, spline outcome

```{r}
# --- ABG: outcome ~ CO2 category, IPW by W_abg_list -------------------------
fit_abg_cat <- function(outcome_var) {
  fits <- vector("list", length(dlist))
  for (i in seq_along(dlist)) {
    d <- dlist[[i]]
    g <- with(d, has_abg == 1 & is.finite(paco2))
    if (!any(g)) { fits[[i]] <- NULL; next }

    d2 <- d[g, , drop = FALSE]
    d2$co2_cat <- make_co2_cat(
      d2$paco2,
      fixed_breaks = if (use_fixed_abg) co2_breaks_abg else NULL,
      labels       = co2_labels_abg
    )
    d2$co2_cat <- stats::relevel(droplevels(d2$co2_cat), ref = ref_label_abg)
    if (nlevels(d2$co2_cat) < 2) { fits[[i]] <- NULL; next }

    w <- W_abg_list[[i]]$weights[g]
    des <- survey::svydesign(ids = ~1, weights = ~w, data = d2)
    fml <- stats::as.formula(sprintf("%s ~ co2_cat", outcome_var))
    fits[[i]] <- survey::svyglm(fml, design = des, family = quasibinomial())
  }
  pool_terms(fits, term_pattern = "^co2_cat")
}

abg_cat_results <- dplyr::bind_rows(
  dplyr::mutate(fit_abg_cat("imv_proc"),               outcome = "IMV"),
  dplyr::mutate(fit_abg_cat("niv_proc"),               outcome = "NIV"),
  dplyr::mutate(fit_abg_cat("death_60d"),              outcome = "Death60d"),
  dplyr::mutate(fit_abg_cat("hypercap_resp_failure"),  outcome = "HCRF")
) |> dplyr::relocate(outcome)
abg_cat_results
```

### VBG, imputed, weighted, spline outcome

```{r}
# --- ABG: outcome ~ CO2 category, IPW by W_abg_list -------------------------
fit_abg_cat <- function(outcome_var) {
  fits <- vector("list", length(dlist))
  for (i in seq_along(dlist)) {
    d <- dlist[[i]]
    g <- with(d, has_abg == 1 & is.finite(paco2))
    if (!any(g)) { fits[[i]] <- NULL; next }

    d2 <- d[g, , drop = FALSE]
    d2$co2_cat <- make_co2_cat(
      d2$paco2,
      fixed_breaks = if (use_fixed_abg) co2_breaks_abg else NULL,
      labels       = co2_labels_abg
    )
    d2$co2_cat <- stats::relevel(droplevels(d2$co2_cat), ref = ref_label_abg)
    if (nlevels(d2$co2_cat) < 2) { fits[[i]] <- NULL; next }

    w <- W_abg_list[[i]]$weights[g]
    des <- survey::svydesign(ids = ~1, weights = ~w, data = d2)
    fml <- stats::as.formula(sprintf("%s ~ co2_cat", outcome_var))
    fits[[i]] <- survey::svyglm(fml, design = des, family = quasibinomial())
  }
  pool_terms(fits, term_pattern = "^co2_cat")
}

abg_cat_results <- dplyr::bind_rows(
  dplyr::mutate(fit_abg_cat("imv_proc"),               outcome = "IMV"),
  dplyr::mutate(fit_abg_cat("niv_proc"),               outcome = "NIV"),
  dplyr::mutate(fit_abg_cat("death_60d"),              outcome = "Death60d"),
  dplyr::mutate(fit_abg_cat("hypercap_resp_failure"),  outcome = "HCRF")
) |> dplyr::relocate(outcome)
abg_cat_results
```

### Visualization

```{r}
#| label: ipw-rcs-overlay-mi-abg-vbg
#| message: false
#| warning: false
#| fig-width: 10
#| fig-height: 8

library(dplyr)
library(ggplot2)
library(patchwork)
library(splines)
library(survey)
library(purrr)

if (!exists("dlist")) dlist <- mice::complete(imp, action = "all")
stopifnot(length(W_abg_list) == length(dlist),
          length(W_vbg_list) == length(dlist))

# Predict link for svyglm; fallback to Xβ and delta method if predict() returns a vector
predict_link_svyglm <- function(fit, newdata) {
  pr <- try(stats::predict(fit, newdata = newdata, type = "link", se.fit = TRUE), silent = TRUE)
  if (!inherits(pr, "try-error") && is.list(pr) && !is.null(pr$fit)) {
    return(list(fit = as.numeric(pr$fit), se.fit = as.numeric(pr$se.fit)))
  }
  # manual: η = Xβ; Var(η) = X V X^T
  X <- stats::model.matrix(stats::delete.response(stats::terms(fit)), newdata)
  beta <- stats::coef(fit)
  eta  <- drop(X %*% beta)
  V    <- stats::vcov(fit)
  se   <- sqrt(rowSums((X %*% V) * X))
  list(fit = eta, se.fit = se)
}

# Pool predicted curves on the link scale, then transform with logistic
pool_rcs_curve <- function(group = c("ABG","VBG"), outcome,
                           df = 4, grid_n = 220, trim = c(0.02, 0.98)) {
  group <- match.arg(group)

  # global trimmed range for this group
  co2_all <- unlist(lapply(seq_along(dlist), function(i) {
    d <- dlist[[i]]
    if (group == "ABG") as.numeric(d$paco2[d$has_abg == 1])
    else as.numeric(d$vbg_co2[d$has_vbg == 1])
  }), use.names = FALSE)
  co2_all <- co2_all[is.finite(co2_all)]
  stopifnot(length(co2_all) > 0)
  rng  <- as.numeric(stats::quantile(co2_all, probs = trim, na.rm = TRUE))
  if (!is.finite(rng[1]) || !is.finite(rng[2]) || rng[2] <= rng[1]) {
    med <- stats::median(co2_all); rng <- c(med - 1, med + 1)
  }
  xseq <- seq(rng[1], rng[2], length.out = grid_n)

  eta_list <- list()
  var_list <- list()

  for (i in seq_along(dlist)) {
    d <- dlist[[i]]

    if (group == "ABG") {
      d$paco2 <- suppressWarnings(as.numeric(d$paco2))
      g <- with(d, has_abg == 1 & is.finite(paco2))
      if (!any(g)) next
      d2 <- d[g, , drop = FALSE]
      d2$co2 <- d2$paco2
      w  <- W_abg_list[[i]]$weights[g]
    } else {
      d$vbg_co2 <- suppressWarnings(as.numeric(d$vbg_co2))
      g <- with(d, has_vbg == 1 & is.finite(vbg_co2))
      if (!any(g)) next
      d2 <- d[g, , drop = FALSE]
      d2$co2 <- d2$vbg_co2
      w  <- W_vbg_list[[i]]$weights[g]
    }

    d2$w <- w
    des  <- survey::svydesign(ids = ~1, weights = ~w, data = d2)
    fml  <- stats::as.formula(paste0(outcome, " ~ splines::ns(co2, ", df, ")"))
    fit  <- try(survey::svyglm(fml, design = des, family = quasibinomial()), silent = TRUE)
    if (inherits(fit, "try-error")) next

    newd <- data.frame(co2 = xseq)
    pr   <- predict_link_svyglm(fit, newd)
    eta_list[[length(eta_list) + 1L]] <- pr$fit
    var_list[[length(var_list) + 1L]] <- pr$se.fit^2
  }

  m <- length(eta_list)
  if (m == 0L) stop("No successful fits to pool for ", group, " / ", outcome)

  ETA <- do.call(cbind, eta_list)   # ngrid × m
  VAR <- do.call(cbind, var_list)   # ngrid × m

  if (m == 1L) {
    etaBar <- as.numeric(ETA)
    Tvar   <- as.numeric(VAR)
  } else {
    etaBar <- rowMeans(ETA)
    Wbar   <- rowMeans(VAR)
    B      <- apply(ETA, 1, stats::var)
    Tvar   <- Wbar + (1 + 1/m) * B
  }
  seBar <- sqrt(pmax(Tvar, 0))

  tibble::tibble(
    co2   = xseq,
    yhat  = plogis(etaBar),
    lower = plogis(etaBar - 1.96 * seBar),
    upper = plogis(etaBar + 1.96 * seBar),
    group = group
  )
}

mk_curves <- function(outcome)
  dplyr::bind_rows(
    pool_rcs_curve("ABG", outcome, df = 4, grid_n = 220, trim = c(0.02, 0.98)),
    pool_rcs_curve("VBG", outcome, df = 4, grid_n = 220, trim = c(0.02, 0.98))
  )

cur_imv   <- mk_curves("imv_proc")
cur_niv   <- mk_curves("niv_proc")
cur_death <- mk_curves("death_60d")
cur_hcrf  <- mk_curves("hypercap_resp_failure")

plt_gray <- function(dat, title) {
  ggplot(dat, aes(x = co2, y = yhat, linetype = group)) +
    geom_line(color = "black", linewidth = 1) +
    geom_ribbon(aes(ymin = lower, ymax = upper, fill = group), alpha = 0.3, color = NA) +
    scale_fill_manual(values = c("ABG" = "gray90", "VBG" = "gray20")) +
    scale_linetype_manual(values = c("ABG" = "solid", "VBG" = "dashed")) +
    scale_y_continuous(limits = c(0, 1),
                       labels = scales::percent_format(accuracy = 1)) +
    labs(title = title,
         x = expression(CO[2]~"(mmHg)"),
         y = "Predicted probability",
         fill = "Group", linetype = "Group") +
    theme_minimal(base_size = 10) +
    theme(legend.position = "bottom")
}

(patchwork::wrap_plots(
   plt_gray(cur_imv,   "IMV"),
   plt_gray(cur_niv,   "NIV"),
   plt_gray(cur_death, "Death (60d)"),
   plt_gray(cur_hcrf,  "Hypercapnic RF"),
   ncol = 2
 ) +
  plot_annotation(
    title = expression(
      paste("MI‑pooled, propensity‑weighted predicted probability: ABG vs VBG CO"[2],
            " (restricted cubic splines, 2–98% range)")
    )
  ))
```

## **9) Save, export, and session info**

```{r mi-save-exports}
saveRDS(list(abg = abg_results, vbg = vbg_results), "mi_pooled_results.rds")
```

```{r mi-session}
sessionInfo()
```
